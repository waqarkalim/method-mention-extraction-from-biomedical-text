{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import codecs\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pycrfsuite\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.element import Tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "import re\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from stanza.utils.conll import CoNLL\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences_tok.pkl', 'rb') as f:\n",
    "    sentence_tok_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10974\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_tok_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen sections of various green fluorescent protein transgenic mouse heads were prepared using the film method developed by Kawamoto and Shimizu .\n",
      "{4: 'film method'}\n",
      "Rule 4: film method\n",
      "\n",
      "\n",
      "\n",
      "For example , the film method is useful for chasing donor cells that are labeled with GFP in an acceptor body .\n",
      "{4: 'film method'}\n",
      "Rule 4: film method\n",
      "\n",
      "\n",
      "\n",
      "We have previously reported on a rat lymph node method .\n",
      "{4: 'rat lymph node method'}\n",
      "Rule 4: rat lymph node method\n",
      "\n",
      "\n",
      "\n",
      "Sequence analysis of the 16S rRNA gene has proved extremely useful for evolutionary studies of prokaryotes .\n",
      "{4: 'Sequence analysis'}\n",
      "Rule 4: Sequence analysis\n",
      "\n",
      "\n",
      "\n",
      "The effect of different treatments on cell-mediated immune response was examined by the cutaneous basophilic hypersensitivity test .\n",
      "{2: 'cutaneous basophilic hypersensitivity test', 4: 'hypersensitivity test'}\n",
      "Rule 2: cutaneous basophilic hypersensitivity test\n",
      "\n",
      "\n",
      "\n",
      "The Principal Component Analysis technique was used to summarize and discover patterns of inter-correlations among the studied measures .\n",
      "{2: 'Principal Component Analysis technique', 4: 'Component Analysis technique'}\n",
      "Rule 2: Principal Component Analysis technique\n",
      "\n",
      "\n",
      "\n",
      "MLST analysis on Leptospira strains showed that the similar serovars and the serogroups of different species are not clustered together .\n",
      "{4: 'MLST analysis'}\n",
      "Rule 4: MLST analysis\n",
      "\n",
      "\n",
      "\n",
      "In the present study , 10 RTK-derived ASV were screened side by side in the high-throughput CIA model , using replication-incompetent adenoviruses as a delivery and in vivo expression system .\n",
      "{2: 'high-throughput CIA model', 4: 'CIA model'}\n",
      "Rule 2: high-throughput CIA model\n",
      "\n",
      "\n",
      "\n",
      "Whereas some other studies have corrected for the background racemization inherent in the sample preparation , this is the first study to use an entire range of age-matched control material to adjust for this background and provide the means to accurately determine protein turnover .\n",
      "{4: 'sample preparation'}\n",
      "Rule 4: sample preparation\n",
      "\n",
      "\n",
      "\n",
      "To develop a reproducible and accurate method of gene expression analysis on synovial biopsies , we evaluated and validated real-time quantitative PCR on very small synovial tissue samples using a novel cell-based standard curve technique .\n",
      "{2: 'novel cell-based standard curve technique', 4: 'curve technique'}\n",
      "Rule 2: novel cell-based standard curve technique\n",
      "\n",
      "\n",
      "\n",
      "Cycle-to-cycle fluorescence emission readings were monitored and quantified using the second derivative maximum method from the MX3000P Real Time software package .\n",
      "{2: 'second derivative maximum method', 4: 'maximum method'}\n",
      "Rule 2: second derivative maximum method\n",
      "\n",
      "\n",
      "\n",
      "To identify groups of cytokines that allow the distinction of potential outcomes in patients with early arthritis , we used a classification algorithm termed Random Forest .\n",
      "{4: 'classification algorithm'}\n",
      "Rule 4: classification algorithm\n",
      "\n",
      "\n",
      "\n",
      "A modified version of the radioimmunoassay method used for serum cortisol was employed for assaying salivary cortisol levels .\n",
      "{4: 'radioimmunoassay method'}\n",
      "Rule 4: radioimmunoassay method\n",
      "\n",
      "\n",
      "\n",
      "The Mankin grading method is a well known and proven method for the histological evaluation of OA cartilage .\n",
      "{4: 'Mankin grading method'}\n",
      "Rule 4: Mankin grading method\n",
      "\n",
      "\n",
      "\n",
      "This program was designed to infer haplotypes for each individual with using the maximum-likelihood method based on the expectation maximization algorithm , assuming Hardy-Weinberg equilibrium for the population .\n",
      "{4: 'expectation maximization algorithm'}\n",
      "Rule 4: expectation maximization algorithm\n",
      "\n",
      "\n",
      "\n",
      "Because the PCA analysis identified no significant difference between expression profiles from patients with early and late OA , we pooled data from these two cohorts and performed supervised Wilcoxon 's ranksum tests to identify unique proteins with differential abundance between the healthy and OA groups .\n",
      "{4: 'PCA analysis'}\n",
      "Rule 4: PCA analysis\n",
      "\n",
      "\n",
      "\n",
      "The heat pain thresholds were assessed by the ascending ramp method with a continuous stimulus , which increased intensity at a constant rate .\n",
      "{2: 'ascending ramp method', 4: 'ramp method'}\n",
      "Rule 2: ascending ramp method\n",
      "\n",
      "\n",
      "\n",
      "At baseline the PulseCO was calibrated using the lithium dilution technique as previously described and according to manufacturer 's instructions .\n",
      "{4: 'lithium dilution technique'}\n",
      "Rule 4: lithium dilution technique\n",
      "\n",
      "\n",
      "\n",
      "By capitalizing on the ease , sensitivity and reproducibility of SELDI-TOF-MS , a novel non-radioactive , mass spectrometry-based method has been developed to study phosphorylation events .\n",
      "{2: 'novel non-radioactive mass method', 4: 'mass method'}\n",
      "Rule 2: novel non-radioactive mass method\n",
      "\n",
      "\n",
      "\n",
      "The CCV method , although not requiring a process of defining orthologs , considers every possible string of length up to k for whole genome sequences .\n",
      "{4: 'CCV method'}\n",
      "Rule 4: CCV method\n",
      "\n",
      "\n",
      "\n",
      "To interpret such gene expression changes , gene set enrichment analysis has been proposed .\n",
      "{4: 'gene set enrichment analysis'}\n",
      "Rule 4: gene set enrichment analysis\n",
      "\n",
      "\n",
      "\n",
      "This paper proposes a new hybrid method named CGTS which combines the ideas of the clustering and the graph algorithms to select tagSNPs on genotype data .\n",
      "{2: 'new hybrid method', 4: 'hybrid method'}\n",
      "Rule 2: new hybrid method\n",
      "\n",
      "\n",
      "\n",
      "They developed a matrix decomposition method called network component analysis to determine transcription regulator activity .\n",
      "{4: 'matrix decomposition method'}\n",
      "Rule 4: matrix decomposition method\n",
      "\n",
      "\n",
      "\n",
      "We propose a multiple clustering method to perform the clustering .\n",
      "{2: 'multiple clustering method', 4: 'clustering method'}\n",
      "Rule 2: multiple clustering method\n",
      "\n",
      "\n",
      "\n",
      "We use the detection algorithm based on simulated annealing , which aims at maximizing the modularity of a partition , and which finds the number of modules automatically .\n",
      "{4: 'detection algorithm'}\n",
      "Rule 4: detection algorithm\n",
      "\n",
      "\n",
      "\n",
      "For the ' Closest Sense ' method , input was the UMLS semantic network and the article abstracts .\n",
      "{2: 'Closest Sense method', 4: 'Sense method'}\n",
      "Rule 2: Closest Sense method\n",
      "\n",
      "\n",
      "\n",
      "Automics implements a fuzzy wrapping method .\n",
      "{4: 'fuzzy wrapping method'}\n",
      "Rule 4: fuzzy wrapping method\n",
      "\n",
      "\n",
      "\n",
      "In addition to the above mentioned two methods , an intelligent adaptive binning method was also implemented in Automics .\n",
      "{2: 'intelligent adaptive binning method', 4: 'binning method'}\n",
      "Rule 2: intelligent adaptive binning method\n",
      "\n",
      "\n",
      "\n",
      "Statistical total correlation spectroscopy analysis method has also been implemented in Automics .\n",
      "{2: 'Statistical total correlation spectroscopy analysis method', 4: 'correlation spectroscopy analysis method'}\n",
      "Rule 2: Statistical total correlation spectroscopy analysis method\n",
      "\n",
      "\n",
      "\n",
      "Hallikas et al. propose the EEL algorithm for finding alignments of significant motif occurrences instead of the sequences themselves .\n",
      "{4: 'EEL algorithm'}\n",
      "Rule 4: EEL algorithm\n",
      "\n",
      "\n",
      "\n",
      "Picard et al. used a piecewise constant regression model , where the parameters are estimated maximizing a penalized likelihood .\n",
      "{2: 'piecewise constant regression model', 4: 'regression model'}\n",
      "Rule 2: piecewise constant regression model\n",
      "\n",
      "\n",
      "\n",
      "This article proposes a MANOVA-based scoring method to combine PPI data with expression data using a greedy search .\n",
      "{2: 'MANOVA-based scoring method', 4: 'scoring method'}\n",
      "Rule 2: MANOVA-based scoring method\n",
      "\n",
      "\n",
      "\n",
      "This profile matching clustering strategy is different from most unsupervised clustering where a representation of a cluster is often calculated only after the cluster is formed .\n",
      "{4: 'clustering strategy'}\n",
      "Rule 4: clustering strategy\n",
      "\n",
      "\n",
      "\n",
      "Since this work was completed , an extension to the OCTOPUS method which incorporates signal peptide prediction , SPOCTOPUS , has been released .\n",
      "{4: 'OCTOPUS method'}\n",
      "Rule 4: OCTOPUS method\n",
      "\n",
      "\n",
      "\n",
      "S3T allows the identification / selection of tags , considered more reliable for further gene expression analysis .\n",
      "{2: 'further gene expression analysis', 4: 'gene expression analysis'}\n",
      "Rule 2: further gene expression analysis\n",
      "\n",
      "\n",
      "\n",
      "However , the rigorous tableau searching method is too slow for a full database search , and so Konagurthu et al. introduce TableauSearch .\n",
      "{2: 'rigorous tableau searching method', 4: 'tableau searching method'}\n",
      "Rule 2: rigorous tableau searching method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 4, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'gene', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'compound', 'misc': 'start_char=4|end_char=8', 'children': []}\n",
      "{'id': 3, 'text': 'expression', 'lemma': 'expression', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'compound', 'misc': 'start_char=9|end_char=19', 'children': []}\n",
      "{'id': 4, 'text': 'levels', 'lemma': 'level', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 7, 'deprel': 'nsubj:pass', 'misc': 'start_char=20|end_char=26', 'children': [1, 2, 3]}\n",
      "{'id': 5, 'text': 'are', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBP', 'head': 7, 'deprel': 'aux:pass', 'misc': 'start_char=27|end_char=30', 'children': []}\n",
      "{'id': 6, 'text': 'typically', 'lemma': 'typically', 'upos': 'ADV', 'xpos': 'RB', 'head': 7, 'deprel': 'advmod', 'misc': 'start_char=31|end_char=40', 'children': []}\n",
      "{'id': 7, 'text': 'estimated', 'lemma': 'estimate', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=41|end_char=50', 'children': [4, 5, 6, 13, 14]}\n",
      "{'id': 8, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 13, 'deprel': 'case', 'misc': 'start_char=51|end_char=53', 'children': []}\n",
      "{'id': 9, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 13, 'deprel': 'det', 'misc': 'start_char=54|end_char=57', 'children': []}\n",
      "{'id': 10, 'text': 'Tukey', 'lemma': 'tukey', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'nmod:poss', 'misc': 'start_char=58|end_char=63', 'children': []}\n",
      "{'id': 11, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 13, 'deprel': 'case', 'misc': 'start_char=64|end_char=66', 'children': []}\n",
      "{'id': 12, 'text': 'biweight', 'lemma': 'biweight', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'compound', 'misc': 'start_char=67|end_char=75', 'children': []}\n",
      "{'id': 13, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'obl', 'misc': 'start_char=76|end_char=82', 'children': [8, 9, 10, 11, 12]}\n",
      "{'id': 14, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 7, 'deprel': 'punct', 'misc': 'start_char=83|end_char=84', 'children': []}\n",
      "The gene expression levels are typically estimated by the Tukey 's biweight method .\n",
      "{4: 'biweight method', 5: \"Tukey 's biweight method\"}\n",
      "Rule 5: Tukey 's biweight method\n",
      "\n",
      "\n",
      "\n",
      "We refer to this as the ratio method .\n",
      "{4: 'ratio method'}\n",
      "Rule 4: ratio method\n",
      "\n",
      "\n",
      "\n",
      "A further reduction in total within-group variance can be achieved by using the ratio method described in this report .\n",
      "{4: 'ratio method'}\n",
      "Rule 4: ratio method\n",
      "\n",
      "\n",
      "\n",
      "From this combined data set we selected genes classified as Present at least once and then clustered the log-transformed data with average linkage analysis .\n",
      "{2: 'average linkage analysis', 4: 'linkage analysis'}\n",
      "Rule 2: average linkage analysis\n",
      "\n",
      "\n",
      "\n",
      "To compare organism amino acid composition , we performed hierarchical clustering using the complete linkage method with distances computed using the Euclidean metric on a dataset that consisted of the mean percent amino acid composition from all predicted open-reading frames for each of the 100 organisms .\n",
      "{2: 'complete linkage method', 4: 'linkage method'}\n",
      "Rule 2: complete linkage method\n",
      "\n",
      "\n",
      "\n",
      "The 95 % -5 % cross-validation method requires more than 5000 train-test runs to reduce the variance of these estimates .\n",
      "{2: '% -5 % cross-validation method', 4: '% cross-validation method'}\n",
      "Rule 2: % -5 % cross-validation method\n",
      "\n",
      "\n",
      "\n",
      "The 95 % -5 % cross-validation method requires more than 5000 train-test runs to achieve the same .\n",
      "{2: '% -5 % cross-validation method', 4: '% cross-validation method'}\n",
      "Rule 2: % -5 % cross-validation method\n",
      "\n",
      "\n",
      "\n",
      "The HSM method iteratively divides the data set into samples of half the size as the original set and uses the half-sample with the minimum range , where range is defined as the difference between the maximum and the minimum value of the sample .\n",
      "{4: 'HSM method'}\n",
      "Rule 4: HSM method\n",
      "\n",
      "\n",
      "\n",
      "A conservative adjustment method is to divide the experiment-wise Type I error level by the number of hypotheses tested and use that as the cut-off for significant p-values .\n",
      "{2: 'conservative adjustment method', 4: 'adjustment method'}\n",
      "Rule 2: conservative adjustment method\n",
      "\n",
      "\n",
      "\n",
      "The traditional method to select a set of marker genes is as follows : 1 ) rank the genes according to their significance in gene expression differences between diseased and normal samples using a statistical test ; 2 ) use a classification method to evaluate the prediction error by using the top one gene , followed by the top two genes , the top three genes and so on until a pre-specified number of genes or a minimum prediction error is reached .\n",
      "{4: 'classification method'}\n",
      "Rule 4: classification method\n",
      "\n",
      "\n",
      "\n",
      "The iterative clustering method offers considerable improvement over clustering in all genes .\n",
      "{2: 'iterative clustering method', 4: 'clustering method'}\n",
      "Rule 2: iterative clustering method\n",
      "\n",
      "\n",
      "\n",
      "We describe here , in detail , a new analysis method that has been used to analyze the transcriptome in yeast .\n",
      "{2: 'new analysis method', 4: 'analysis method'}\n",
      "Rule 2: new analysis method\n",
      "\n",
      "\n",
      "\n",
      "In the first stage , the SVM-RFE technique was most efficient and robust in the presence of low number of samples and high input space dimension .\n",
      "{4: 'SVM-RFE technique'}\n",
      "Rule 4: SVM-RFE technique\n",
      "\n",
      "\n",
      "\n",
      "The second algorithm used was PAM , a shrunken centroid method of classification .\n",
      "{2: 'shrunken centroid method', 4: 'centroid method'}\n",
      "Rule 2: shrunken centroid method\n",
      "\n",
      "\n",
      "\n",
      "We then estimate this integral using a method we developed called the Uniform Distance Method .\n",
      "{2: 'Uniform Distance Method', 4: 'Distance Method'}\n",
      "Rule 2: Uniform Distance Method\n",
      "\n",
      "\n",
      "\n",
      "In literature of microarray processing , α = 0.01 is often used as the genome wide significant level , so the gene-specific significance level is : α* = α / Recently a new modification of the MMM algorithm , Mod2MMM hereafter , was introduced .\n",
      "{4: 'MMM algorithm'}\n",
      "Rule 4: MMM algorithm\n",
      "\n",
      "\n",
      "\n",
      "In order to assess the importance of different methods for total weight calculation , we implemented a version of the SAM \" bits saved \" method in the HMMER code .\n",
      "{4: 'method'}\n",
      "Rule 4: method\n",
      "\n",
      "\n",
      "\n",
      "We propose a quadratic regression method for identification of differentially expressed genes and classification of genes based on their temporal expression profiles for non-cyclic short time-course microarray data .\n",
      "{2: 'quadratic regression method', 4: 'regression method'}\n",
      "Rule 2: quadratic regression method\n",
      "\n",
      "\n",
      "\n",
      "The protein sequence Jukes-Cantor model assigns the same probability to each substitution and is hence a rather poor approximation .\n",
      "{4: 'protein sequence Jukes-Cantor model'}\n",
      "Rule 4: protein sequence Jukes-Cantor model\n",
      "\n",
      "\n",
      "\n",
      "The most widely accepted method employs the ' constant majority ' method , which assumes that the majority of reporters do not change in ratio .\n",
      "{2: 'constant majority method', 4: 'majority method'}\n",
      "Rule 2: constant majority method\n",
      "\n",
      "\n",
      "\n",
      "The TatP method is able to positively classify 91 % of 35 known Tat signal peptides and 84 % of the annotated cleavage sites of these Tat signal peptides were correctly predicted .\n",
      "{4: 'TatP method'}\n",
      "Rule 4: TatP method\n",
      "\n",
      "\n",
      "\n",
      "The toolbox currently implements a simple alignment method utilizing the master peak list .\n",
      "{2: 'simple alignment method', 4: 'alignment method'}\n",
      "Rule 2: simple alignment method\n",
      "\n",
      "\n",
      "\n",
      "A fast structural comparison algorithm allows the rapid scanning of one or more protein structures with the library looking for local structural similarities .\n",
      "{2: 'fast structural comparison algorithm', 4: 'comparison algorithm'}\n",
      "Rule 2: fast structural comparison algorithm\n",
      "\n",
      "\n",
      "\n",
      "Due to the spread of residues being more on the diametrical plane of these helices , the axis found using the eigenvector method lay closer to the plane of the diameter instead of being normal to it .\n",
      "{4: 'eigenvector method'}\n",
      "Rule 4: eigenvector method\n",
      "\n",
      "\n",
      "\n",
      "Mathematically , the measure is based on a log-likelihood ratio score used in the statistical G-test for goodness-of-fit .\n",
      "{2: 'log-likelihood ratio score', 4: 'ratio score'}\n",
      "Rule 2: log-likelihood ratio score\n",
      "\n",
      "\n",
      "\n",
      "In this study , we have developed a tandem machine learning approach for the identification of regulatory target genes based on these parameters and on the corresponding binding site information contents that measure the affinities of the factor for these cognate elements .\n",
      "{2: 'tandem machine learning approach', 4: 'machine learning approach'}\n",
      "Rule 2: tandem machine learning approach\n",
      "\n",
      "\n",
      "\n",
      "The two distance measures are converted to zscores based on the permutation method described in .\n",
      "{4: 'permutation method'}\n",
      "Rule 4: permutation method\n",
      "\n",
      "\n",
      "\n",
      "A recent publication described a supervised classification method for microarray data : Between Group Analysis .\n",
      "{2: 'supervised classification method', 4: 'classification method'}\n",
      "Rule 2: supervised classification method\n",
      "\n",
      "\n",
      "\n",
      "A recent publication described a supervised classification method for microarray data : Between Group Analysis .\n",
      "{4: 'Group Analysis'}\n",
      "Rule 4: Group Analysis\n",
      "\n",
      "\n",
      "\n",
      "We use the approximate normal modes calculation method developed by Hinsen .\n",
      "{2: 'approximate normal modes calculation method', 4: 'modes calculation method'}\n",
      "Rule 2: approximate normal modes calculation method\n",
      "\n",
      "\n",
      "\n",
      "We compared the gene lists generated by the RFE method to the result of a meta-analysis approach as described by Rhodes et al. .\n",
      "{4: 'RFE method'}\n",
      "Rule 4: RFE method\n",
      "\n",
      "\n",
      "\n",
      "They used the least squares method for estimating the normalization curves based on B-splines .\n",
      "{4: 'squares method'}\n",
      "Rule 4: squares method\n",
      "\n",
      "\n",
      "\n",
      "In summary , we examined the applicability of using Zipf 's law as the basis for a novel normalization technique , which is applicable to both one channel microarray data and two channel microarrays .\n",
      "{2: 'novel normalization technique', 4: 'normalization technique'}\n",
      "Rule 2: novel normalization technique\n",
      "\n",
      "\n",
      "\n",
      "As already mentioned , selection of a QSAR model that maximizes a K2-fold CV performance estimate is common in conventional chemometrics and is also applied in proteochemometrics .\n",
      "{4: 'QSAR model'}\n",
      "Rule 4: QSAR model\n",
      "\n",
      "\n",
      "\n",
      "Lander et al. introduced a Hidden Markov Model where the meiosis indicators are the unobserved variables .\n",
      "{2: 'Hidden Markov Model', 4: 'Markov Model'}\n",
      "Rule 2: Hidden Markov Model\n",
      "\n",
      "\n",
      "\n",
      "The Sum-Height greedy method , denoted by SH , selects a character that will result in the largest increase in the sum-height .\n",
      "{2: 'Sum-Height greedy method', 4: 'Sum-Height method'}\n",
      "Rule 2: Sum-Height greedy method\n",
      "\n",
      "\n",
      "\n",
      "The relative binding energies for dimer formation were computed using the MM-PBSA module of AMBER 8.0 , employing molecular mechanics and a continuum solvent model .\n",
      "{4: 'continuum solvent model'}\n",
      "Rule 4: continuum solvent model\n",
      "\n",
      "\n",
      "\n",
      "A more elaborate method built on PCA is explored in this study to utilize the directional information contained in the eigenvector corresponding to λ1 , named here as the PCC analysis as described in Section Methods .\n",
      "{4: 'PCC analysis'}\n",
      "Rule 4: PCC analysis\n",
      "\n",
      "\n",
      "\n",
      "Association rules discovery technique is a data mining method that has been extensively used in many applications to discover associations among subsets of items from large transaction databases .\n",
      "{4: 'rules discovery technique'}\n",
      "Rule 4: rules discovery technique\n",
      "\n",
      "\n",
      "\n",
      "More recently , other methods have become available , such as the \" Assumption-free analysis \" .\n",
      "{2: 'Assumption-free analysis', 4: 'analysis'}\n",
      "Rule 2: Assumption-free analysis\n",
      "\n",
      "\n",
      "\n",
      "In real-time PCR data analysis , the cycle threshold method is currently the gold standard .\n",
      "{2: 'real-time PCR data analysis', 4: 'PCR data analysis'}\n",
      "Rule 2: real-time PCR data analysis\n",
      "\n",
      "\n",
      "\n",
      "In real-time PCR data analysis , the cycle threshold method is currently the gold standard .\n",
      "{4: 'cycle threshold method'}\n",
      "Rule 4: cycle threshold method\n",
      "\n",
      "\n",
      "\n",
      "We developed a gene cluster classification method that circumvents these limitations and links biological function with gene expression patterns derived from microarray experiments .\n",
      "{4: 'gene cluster classification method'}\n",
      "Rule 4: gene cluster classification method\n",
      "\n",
      "\n",
      "\n",
      "Since we have proposed a new approximate inference algorithm , it is important to identify when this method works better than other approximate inference methods .\n",
      "{2: 'new approximate inference algorithm', 4: 'inference algorithm'}\n",
      "Rule 2: new approximate inference algorithm\n",
      "\n",
      "\n",
      "\n",
      "The TGDR approach was originally proposed for the linear regression .\n",
      "{4: 'TGDR approach'}\n",
      "Rule 4: TGDR approach\n",
      "\n",
      "\n",
      "\n",
      "In order to compute the distance between a matrix and a set of indices , our software uses the correlation method described by Tomii and Kanehisa .\n",
      "{4: 'correlation method'}\n",
      "Rule 4: correlation method\n",
      "\n",
      "\n",
      "\n",
      "The Ortholuge method reported here appears to significantly improve the specificity of high-throughput ortholog prediction for both bacterial and eukaryotic species .\n",
      "{4: 'Ortholuge method'}\n",
      "Rule 4: Ortholuge method\n",
      "\n",
      "\n",
      "\n",
      "The third method calculates a relevance score as described below .\n",
      "{4: 'relevance score'}\n",
      "Rule 4: relevance score\n",
      "\n",
      "\n",
      "\n",
      "The first true evolutionary model of indel evolution was introduced by Thorne , Kishino , and Felsenstein , the TKF91 model , and allows single-residue indel events .\n",
      "{4: 'TKF91 model'}\n",
      "Rule 4: TKF91 model\n",
      "\n",
      "\n",
      "\n",
      "They used a Monte Carlo hill-climbing algorithm to search for the most probable alignments .\n",
      "{2: 'Monte Carlo hill-climbing algorithm', 4: 'Monte Carlo algorithm'}\n",
      "Rule 2: Monte Carlo hill-climbing algorithm\n",
      "\n",
      "\n",
      "\n",
      "In the Bioinformatics field , a great deal of interest has been given to Non-negative matrix factorization technique , due to its capability of providing new insights and relevant information about the complex latent relationships in experimental data sets .\n",
      "{2: 'Non-negative matrix factorization technique', 4: 'matrix factorization technique'}\n",
      "Rule 2: Non-negative matrix factorization technique\n",
      "\n",
      "\n",
      "\n",
      "Having obtained the dissimilarity indexes , Ward 's clustering , a hierarchically agglomerative clustering method , is used to decompose the network .\n",
      "{2: 'agglomerative clustering method', 4: 'clustering method'}\n",
      "Rule 2: agglomerative clustering method\n",
      "\n",
      "\n",
      "\n",
      "The SW has been extensively used in DNA polymorphism studies for exploratory data analysis .\n",
      "{2: 'exploratory data analysis', 4: 'data analysis'}\n",
      "Rule 2: exploratory data analysis\n",
      "\n",
      "\n",
      "\n",
      "Another alignment algorithm assumes no knowledge of peaks in common .\n",
      "{4: 'alignment algorithm'}\n",
      "Rule 4: alignment algorithm\n",
      "\n",
      "\n",
      "\n",
      "We also proposed a submatrix imputation method to determine whether to use integrative imputation with a given collection of reference datasets .\n",
      "{2: 'submatrix imputation method', 4: 'imputation method'}\n",
      "Rule 2: submatrix imputation method\n",
      "\n",
      "\n",
      "\n",
      "The global lowess normalization is carried out first and takes dye biases into account .\n",
      "{2: 'global lowess normalization', 4: 'lowess normalization'}\n",
      "Rule 2: global lowess normalization\n",
      "\n",
      "\n",
      "\n",
      "The lookahead scoring technique is also employed in the suffix tree based method of .\n",
      "{4: 'lookahead scoring technique'}\n",
      "Rule 4: lookahead scoring technique\n",
      "\n",
      "\n",
      "\n",
      "Excluding non-core β-sheet residues from the β-sheet fraction makes sense in view of the large variety of dihedral angles assigned as β-sheet by the DSSP algorithm .\n",
      "{4: 'DSSP algorithm'}\n",
      "Rule 4: DSSP algorithm\n",
      "\n",
      "\n",
      "\n",
      "Enault and colleagues proposed an improved phylogenetic profile based on a normalized Blastp bit score .\n",
      "{2: 'normalized Blastp bit score', 4: 'Blastp bit score'}\n",
      "Rule 2: normalized Blastp bit score\n",
      "\n",
      "\n",
      "\n",
      "In this gene retrieval method , a query gene vector is one of column vectors of A .\n",
      "{4: 'gene retrieval method'}\n",
      "Rule 4: gene retrieval method\n",
      "\n",
      "\n",
      "\n",
      "Our in silico panning approach should become a useful tool for screening structure-based enzyme inhibitors .\n",
      "{2: 'in silico panning approach', 4: 'panning approach'}\n",
      "Rule 2: in silico panning approach\n",
      "\n",
      "\n",
      "\n",
      "To avoid training data sparseness and to structure the hypothesis space based on the entire protein distribution , we have proposed a prediction method that uses Joachims ' spectral graph transducer and is trained on both structure-known sequences and structure-unknown sequences .\n",
      "{4: 'prediction method'}\n",
      "Rule 4: prediction method\n",
      "\n",
      "\n",
      "\n",
      "To achieve this we used a Cox Proportional-Hazards model to study how the expression of each gene across patients is related to their survival times .\n",
      "{2: 'Cox Proportional-Hazards model', 4: 'Cox model'}\n",
      "Rule 2: Cox Proportional-Hazards model\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'To', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 2, 'deprel': 'mark', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'discard', 'lemma': 'discard', 'upos': 'VERB', 'xpos': 'VB', 'head': 16, 'deprel': 'advcl', 'misc': 'start_char=3|end_char=10', 'children': [1, 3]}\n",
      "{'id': 3, 'text': 'tags', 'lemma': 'tag', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 2, 'deprel': 'obj', 'misc': 'start_char=11|end_char=15', 'children': [6]}\n",
      "{'id': 4, 'text': 'that', 'lemma': 'that', 'upos': 'PRON', 'xpos': 'WDT', 'head': 6, 'deprel': 'nsubj', 'misc': 'start_char=16|end_char=20', 'children': []}\n",
      "{'id': 5, 'text': 'are', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBP', 'head': 6, 'deprel': 'cop', 'misc': 'start_char=21|end_char=24', 'children': []}\n",
      "{'id': 6, 'text': 'likely', 'lemma': 'likely', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 3, 'deprel': 'acl:relcl', 'misc': 'start_char=25|end_char=31', 'children': [4, 5, 10]}\n",
      "{'id': 7, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 10, 'deprel': 'mark', 'misc': 'start_char=32|end_char=34', 'children': []}\n",
      "{'id': 8, 'text': 'have', 'lemma': 'have', 'upos': 'AUX', 'xpos': 'VB', 'head': 10, 'deprel': 'aux', 'misc': 'start_char=35|end_char=39', 'children': []}\n",
      "{'id': 9, 'text': 'been', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBN', 'head': 10, 'deprel': 'aux:pass', 'misc': 'start_char=40|end_char=44', 'children': []}\n",
      "{'id': 10, 'text': 'generated', 'lemma': 'generate', 'upos': 'VERB', 'xpos': 'VBN', 'head': 6, 'deprel': 'xcomp', 'misc': 'start_char=45|end_char=54', 'children': [7, 8, 9, 13]}\n",
      "{'id': 11, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 13, 'deprel': 'case', 'misc': 'start_char=55|end_char=57', 'children': []}\n",
      "{'id': 12, 'text': 'sequencing', 'lemma': 'sequencing', 'upos': 'VERB', 'xpos': 'VBG', 'head': 13, 'deprel': 'amod', 'misc': 'start_char=58|end_char=68', 'children': []}\n",
      "{'id': 13, 'text': 'errors', 'lemma': 'error', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 10, 'deprel': 'obl', 'misc': 'start_char=69|end_char=75', 'children': [11, 12]}\n",
      "{'id': 14, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=76|end_char=77', 'children': []}\n",
      "{'id': 15, 'text': 'we', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP', 'head': 16, 'deprel': 'nsubj', 'misc': 'start_char=78|end_char=80', 'children': []}\n",
      "{'id': 16, 'text': 'implemented', 'lemma': 'implement', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=81|end_char=92', 'children': [2, 14, 15, 17, 22]}\n",
      "{'id': 17, 'text': 'Colinge', 'lemma': 'colinge', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'obj', 'misc': 'start_char=93|end_char=100', 'children': [21]}\n",
      "{'id': 18, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 19, 'deprel': 'cc', 'misc': 'start_char=101|end_char=104', 'children': []}\n",
      "{'id': 19, 'text': 'Feger', 'lemma': 'feger', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'nmod:poss', 'misc': 'start_char=105|end_char=110', 'children': [18, 20]}\n",
      "{'id': 20, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 19, 'deprel': 'case', 'misc': 'start_char=111|end_char=113', 'children': []}\n",
      "{'id': 21, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 17, 'deprel': 'conj', 'misc': 'start_char=114|end_char=120', 'children': [19]}\n",
      "{'id': 22, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=121|end_char=122', 'children': []}\n",
      "To discard tags that are likely to have been generated by sequencing errors , we implemented Colinge and Feger 's method .\n",
      "{5: \"Feger 's method\"}\n",
      "Rule 5: Feger 's method\n",
      "\n",
      "\n",
      "\n",
      "Here , the neural gas clustering method is used with Pearson correlation similarity measure for computing cluster centroids .\n",
      "{2: 'neural gas clustering method', 4: 'gas clustering method'}\n",
      "Rule 2: neural gas clustering method\n",
      "\n",
      "\n",
      "\n",
      "By varying the search strategy according to a priori defined transition probabilities , this approach leads to an algorithm that sacrifices an exact relationship with the canonical ensemble for search efficiency .\n",
      "{4: 'search strategy'}\n",
      "Rule 4: search strategy\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we propose the AT excursion method , which is a score-based approach , to quantify local AT abundance in genomic sequences and use the identified high scoring segments for predicting replication origins .\n",
      "{4: 'excursion method'}\n",
      "Rule 4: excursion method\n",
      "\n",
      "\n",
      "\n",
      "Furthermore , our normalization strategy also yields insight into the question of differential enrichment of histone occupancy in genic and intergenic regions .\n",
      "{4: 'normalization strategy'}\n",
      "Rule 4: normalization strategy\n",
      "\n",
      "\n",
      "\n",
      "We introduce a novel multi-chip normalization method for Affymetrix-based aCGH data .\n",
      "{2: 'novel multi-chip normalization method', 4: 'normalization method'}\n",
      "Rule 2: novel multi-chip normalization method\n",
      "\n",
      "\n",
      "\n",
      "Another approach is to employ comparative sequence analysis .\n",
      "{2: 'comparative sequence analysis', 4: 'sequence analysis'}\n",
      "Rule 2: comparative sequence analysis\n",
      "\n",
      "\n",
      "\n",
      "The minimum covariance determinant regression method is a well performing robust regression method that can also handle cases where both X and y are multivariate .\n",
      "{2: 'minimum covariance determinant regression method', 4: 'covariance determinant regression method'}\n",
      "Rule 2: minimum covariance determinant regression method\n",
      "\n",
      "\n",
      "\n",
      "Note that caution should be taking when evaluating the predictive performance of the ARB method .\n",
      "{4: 'ARB method'}\n",
      "Rule 4: ARB method\n",
      "\n",
      "\n",
      "\n",
      "Note that caution should also here be taking when evaluating the predictive performance of the ARB method .\n",
      "{4: 'ARB method'}\n",
      "Rule 4: ARB method\n",
      "\n",
      "\n",
      "\n",
      "We use the approximate normal modes calculation method developed by Hinsen .\n",
      "{2: 'approximate normal modes calculation method', 4: 'modes calculation method'}\n",
      "Rule 2: approximate normal modes calculation method\n",
      "\n",
      "\n",
      "\n",
      "In summary , the control method is essentially a restriction to STEPS 1 and 2 of our identification method .\n",
      "{4: 'identification method'}\n",
      "Rule 4: identification method\n",
      "\n",
      "\n",
      "\n",
      "The SBL algorithm is a general Bayesian framework to obtain sparse solutions utilizing linear models .\n",
      "{4: 'SBL algorithm'}\n",
      "Rule 4: SBL algorithm\n",
      "\n",
      "\n",
      "\n",
      "Using a force-directed optimisation method , we were able to produce tree layouts in three-dimensions upon which the protein interactions could be projected .\n",
      "{2: 'force-directed optimisation method', 4: 'optimisation method'}\n",
      "Rule 2: force-directed optimisation method\n",
      "\n",
      "\n",
      "\n",
      "Other attempts at the problem use local search methods on complete conformations , including the GTabu algorithm .\n",
      "{4: 'GTabu algorithm'}\n",
      "Rule 4: GTabu algorithm\n",
      "\n",
      "\n",
      "\n",
      "Here we demonstrate the effectiveness of a Markov model , named the Linear Dynamical System , to simulate the dynamics of a transcript or metabolite time series , and propose a probabilistic index that enables detection of time-sensitive changes .\n",
      "{4: 'Markov model'}\n",
      "Rule 4: Markov model\n",
      "\n",
      "\n",
      "\n",
      "We have developed a drug target prediction method based solely on protein sequence information without the knowledge of family / domain annotation , or the protein 3D structure .\n",
      "{4: 'drug target prediction method'}\n",
      "Rule 4: drug target prediction method\n",
      "\n",
      "\n",
      "\n",
      "Described in this paper is a framework for identifying subsystems from a Boolean network model .\n",
      "{4: 'Boolean network model'}\n",
      "Rule 4: Boolean network model\n",
      "\n",
      "\n",
      "\n",
      "Furthermore , our retention time prediction model is based on a new kernel function in conjunction with support vector regression , which allows us to predict peptide retention times very accurately , requiring only a very small amount of training data .\n",
      "{4: 'retention time prediction model'}\n",
      "Rule 4: retention time prediction model\n",
      "\n",
      "\n",
      "\n",
      "We used the results of these studies to show that mutual information analysis is highly effective for identifying systematic differences between sets of sequences .\n",
      "{2: 'mutual information analysis', 4: 'information analysis'}\n",
      "Rule 2: mutual information analysis\n",
      "\n",
      "\n",
      "\n",
      "More recently , Rajapakse et al. proposed a complex splice site detection method by combining mostly second order Markov models with backpropagation neural networks .\n",
      "{2: 'complex splice site detection method', 4: 'splice site detection method'}\n",
      "Rule 2: complex splice site detection method\n",
      "\n",
      "\n",
      "\n",
      "Shiraishi et al. published a variable-order , variable-step Taylor-series method that can be used as an ODE solver providing a highly accurate calculation to compute dynamic sensitivities .\n",
      "{2: 'variable-order variable-step Taylor-series method', 4: 'Taylor-series method'}\n",
      "Rule 2: variable-order variable-step Taylor-series method\n",
      "\n",
      "\n",
      "\n",
      "In order to separate the effect of the method from the procedure to impute the missing values , we repeated the analysis both by filtering out all the genes with missing observations and by using the KNN method to impute them .\n",
      "{4: 'KNN method'}\n",
      "Rule 4: KNN method\n",
      "\n",
      "\n",
      "\n",
      "The method to analyze all ConsWH or CombWH in any window sizes are called exhaustive window haplotype analysis .\n",
      "{2: 'exhaustive window haplotype analysis', 4: 'window haplotype analysis'}\n",
      "Rule 2: exhaustive window haplotype analysis\n",
      "\n",
      "\n",
      "\n",
      "In another work , Bunescu et al restricted feature classes to those within dependency paths , but simply calculated the number of co-occurring features as the kernel score .\n",
      "{4: 'kernel score'}\n",
      "Rule 4: kernel score\n",
      "\n",
      "\n",
      "\n",
      "The individual-observation log odds ratios are themselves constructed from positionally defined Markov Models , so what results is a pMM / SVM sensor method .\n",
      "{4: 'pMM / SVM sensor method'}\n",
      "Rule 4: pMM / SVM sensor method\n",
      "\n",
      "\n",
      "\n",
      "We evaluate the performances of a footprint discovery approach based on the detection of over-represented spaced motifs .\n",
      "{4: 'footprint discovery approach'}\n",
      "Rule 4: footprint discovery approach\n",
      "\n",
      "\n",
      "\n",
      "A prediction method ProLoc-GO based on GOmining was implemented using the feature set of informative GO terms .\n",
      "{4: 'prediction method'}\n",
      "Rule 4: prediction method\n",
      "\n",
      "\n",
      "\n",
      "We have developed a new Monte Carlo based method to predict the mapping between two interacting protein families .\n",
      "{2: 'new Monte Carlo based method', 4: 'Monte Carlo method'}\n",
      "Rule 2: new Monte Carlo based method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Most', 'lemma': 'most', 'upos': 'ADJ', 'xpos': 'JJS', 'head': 2, 'deprel': 'amod', 'misc': 'start_char=0|end_char=4', 'children': []}\n",
      "{'id': 2, 'text': 'analyses', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 6, 'deprel': 'nsubj', 'misc': 'start_char=5|end_char=13', 'children': [1, 5]}\n",
      "{'id': 3, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 5, 'deprel': 'case', 'misc': 'start_char=14|end_char=16', 'children': []}\n",
      "{'id': 4, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 5, 'deprel': 'det', 'misc': 'start_char=17|end_char=21', 'children': []}\n",
      "{'id': 5, 'text': 'paper', 'lemma': 'paper', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=22|end_char=27', 'children': [3, 4]}\n",
      "{'id': 6, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=28|end_char=32', 'children': [2, 8, 22, 30]}\n",
      "{'id': 7, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 8, 'deprel': 'det', 'misc': 'start_char=33|end_char=36', 'children': []}\n",
      "{'id': 8, 'text': 'background', 'lemma': 'background', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'obj', 'misc': 'start_char=37|end_char=47', 'children': [7, 9]}\n",
      "{'id': 9, 'text': 'adjusted', 'lemma': 'adjust', 'upos': 'VERB', 'xpos': 'VBN', 'head': 8, 'deprel': 'acl', 'misc': 'start_char=48|end_char=56', 'children': [10, 13]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 9, 'deprel': 'punct', 'misc': 'start_char=57|end_char=58', 'children': []}\n",
      "{'id': 11, 'text': 'log2', 'lemma': 'log2', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 13, 'deprel': 'amod', 'misc': 'start_char=59|end_char=63', 'children': []}\n",
      "{'id': 12, 'text': 'transformed', 'lemma': 'transform', 'upos': 'VERB', 'xpos': 'VBN', 'head': 13, 'deprel': 'amod', 'misc': 'start_char=64|end_char=75', 'children': []}\n",
      "{'id': 13, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 9, 'deprel': 'obj', 'misc': 'start_char=76|end_char=80', 'children': [11, 12, 15]}\n",
      "{'id': 14, 'text': 'from', 'lemma': 'from', 'upos': 'ADP', 'xpos': 'IN', 'head': 15, 'deprel': 'mark', 'misc': 'start_char=81|end_char=85', 'children': []}\n",
      "{'id': 15, 'text': 'replicate', 'lemma': 'replicate', 'upos': 'VERB', 'xpos': 'VB', 'head': 13, 'deprel': 'acl', 'misc': 'start_char=86|end_char=95', 'children': [14, 16, 20]}\n",
      "{'id': 16, 'text': 'beads', 'lemma': 'bead', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'obj', 'misc': 'start_char=96|end_char=101', 'children': []}\n",
      "{'id': 17, 'text': 'on', 'lemma': 'on', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'misc': 'start_char=102|end_char=104', 'children': []}\n",
      "{'id': 18, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 20, 'deprel': 'det', 'misc': 'start_char=105|end_char=106', 'children': []}\n",
      "{'id': 19, 'text': 'given', 'lemma': 'given', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 20, 'deprel': 'amod', 'misc': 'start_char=107|end_char=112', 'children': []}\n",
      "{'id': 20, 'text': 'array', 'lemma': 'array', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=113|end_char=118', 'children': [17, 18, 19]}\n",
      "{'id': 21, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 22, 'deprel': 'cc', 'misc': 'start_char=119|end_char=122', 'children': []}\n",
      "{'id': 22, 'text': 'summarised', 'lemma': 'summarise', 'upos': 'VERB', 'xpos': 'VBD', 'head': 6, 'deprel': 'conj', 'misc': 'start_char=123|end_char=133', 'children': [21, 24, 25]}\n",
      "{'id': 23, 'text': 'these', 'lemma': 'these', 'upos': 'DET', 'xpos': 'DT', 'head': 24, 'deprel': 'det', 'misc': 'start_char=134|end_char=139', 'children': []}\n",
      "{'id': 24, 'text': 'values', 'lemma': 'value', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=140|end_char=146', 'children': [23]}\n",
      "{'id': 25, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 22, 'deprel': 'xcomp', 'misc': 'start_char=147|end_char=152', 'children': [29]}\n",
      "{'id': 26, 'text': 'Illumina', 'lemma': 'illumina', 'upos': 'NOUN', 'xpos': 'NN', 'head': 29, 'deprel': 'nmod:poss', 'misc': 'start_char=153|end_char=161', 'children': [27]}\n",
      "{'id': 27, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 26, 'deprel': 'case', 'misc': 'start_char=162|end_char=164', 'children': []}\n",
      "{'id': 28, 'text': 'default', 'lemma': 'default', 'upos': 'NOUN', 'xpos': 'NN', 'head': 29, 'deprel': 'compound', 'misc': 'start_char=165|end_char=172', 'children': []}\n",
      "{'id': 29, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 25, 'deprel': 'obj', 'misc': 'start_char=173|end_char=179', 'children': [26, 28]}\n",
      "{'id': 30, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=180|end_char=181', 'children': []}\n",
      "Most analyses in this paper used the background adjusted , log2 transformed data from replicate beads on a given array and summarised these values using Illumina 's default method .\n",
      "{4: 'default method', 5: \"Illumina 's default method\"}\n",
      "Rule 5: Illumina 's default method\n",
      "\n",
      "\n",
      "\n",
      "To compare different partitions of the genes , we compute the posterior probability of different clustering models so that , given the observed gene expression profiles , the best clustering model is the one with maximum posterior probability .\n",
      "{2: 'best clustering model', 4: 'clustering model'}\n",
      "Rule 2: best clustering model\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we present a computational improvement to a sequence clustering method that we introduced previously to analyze large microbial metagenomic datasets , and that was used in the GOS study .\n",
      "{4: 'sequence clustering method'}\n",
      "Rule 4: sequence clustering method\n",
      "\n",
      "\n",
      "\n",
      "Bisecting K Means : The initial centroids are calculated using a variation of the Bisecting K Means algorithm .\n",
      "{2: 'Bisecting K Means algorithm', 4: 'K Means algorithm'}\n",
      "Rule 2: Bisecting K Means algorithm\n",
      "\n",
      "\n",
      "\n",
      "The next worst performing method on the measurement level was kNN .\n",
      "{2: 'next worst performing method', 4: 'performing method'}\n",
      "Rule 2: next worst performing method\n",
      "\n",
      "\n",
      "\n",
      "Recently , a conservation score for ranking predicted motif instances has been proposed .\n",
      "{4: 'conservation score'}\n",
      "Rule 4: conservation score\n",
      "\n",
      "\n",
      "\n",
      "Here we present the design and implementation of a novel and robust online phenotype discovery method with broad applicability that can be used in diverse experimental contexts , especially high-throughput RNAi screens .\n",
      "{2: 'novel and robust online phenotype discovery method', 4: 'online phenotype discovery method'}\n",
      "Rule 2: novel and robust online phenotype discovery method\n",
      "\n",
      "\n",
      "\n",
      "A Gaussian Mixture Model is employed to estimate the distribution of each existing phenotype , and then used as reference distribution in gap statistics .\n",
      "{2: 'Gaussian Mixture Model', 4: 'Mixture Model'}\n",
      "Rule 2: Gaussian Mixture Model\n",
      "\n",
      "\n",
      "\n",
      "We propose an online phenotype discovery method for high-throughput RNAi screen , which can be used in the course of many image-based screens .\n",
      "{2: 'online phenotype discovery method', 4: 'phenotype discovery method'}\n",
      "Rule 2: online phenotype discovery method\n",
      "\n",
      "\n",
      "\n",
      "We thus are considering all possible sequence alignments and weighing them appropriately , according to our indel model .\n",
      "{4: 'indel model'}\n",
      "Rule 4: indel model\n",
      "\n",
      "\n",
      "\n",
      "The kernel machine method , with the support vector machine as a most popular example , has emerged in the last decade as a powerful machine learning technique in high-dimensional settings .\n",
      "{4: 'kernel machine method'}\n",
      "Rule 4: kernel machine method\n",
      "\n",
      "\n",
      "\n",
      "The kernel machine method , with the support vector machine as a most popular example , has emerged in the last decade as a powerful machine learning technique in high-dimensional settings .\n",
      "{2: 'powerful machine learning technique', 4: 'machine learning technique'}\n",
      "Rule 2: powerful machine learning technique\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we developed a logistic kernel machine regression model for binary outcomes , where the covariate effects are modeled parametrically and the genetic pathway effect is modeled nonparametrically using the kernel machine method .\n",
      "{2: 'logistic kernel machine regression model', 4: 'kernel machine regression model'}\n",
      "Rule 2: logistic kernel machine regression model\n",
      "\n",
      "\n",
      "\n",
      "One such Fst method is described in ) and is implemented in the fdist program and can be used for any codominant genetic molecular markers including microsatellites , Single Nucleotide Polymorphisms and allozymes .\n",
      "{2: 'such Fst method', 4: 'Fst method'}\n",
      "Rule 2: such Fst method\n",
      "\n",
      "\n",
      "\n",
      "As an alternative to the existing noise detection and interpolation approaches , we developed a new baseline correction method based on a penalized parametric smoothing model .\n",
      "{2: 'new baseline correction method', 4: 'baseline correction method'}\n",
      "Rule 2: new baseline correction method\n",
      "\n",
      "\n",
      "\n",
      "As an alternative to the existing noise detection and interpolation approaches , we developed a new baseline correction method based on a penalized parametric smoothing model .\n",
      "{2: 'penalized parametric smoothing model', 4: 'smoothing model'}\n",
      "Rule 2: penalized parametric smoothing model\n",
      "\n",
      "\n",
      "\n",
      "We propose an alternative baseline correction method based on a penalized smoothing model .\n",
      "{2: 'alternative baseline correction method', 4: 'baseline correction method'}\n",
      "Rule 2: alternative baseline correction method\n",
      "\n",
      "\n",
      "\n",
      "We propose an alternative baseline correction method based on a penalized smoothing model .\n",
      "{2: 'penalized smoothing model', 4: 'smoothing model'}\n",
      "Rule 2: penalized smoothing model\n",
      "\n",
      "\n",
      "\n",
      "In this study , we proposed a scoring method that combined the predicted variance information to compare two spectra under total ion current normalization .\n",
      "{4: 'scoring method'}\n",
      "Rule 4: scoring method\n",
      "\n",
      "\n",
      "\n",
      "We used the Sammon projection method as the embedding procedure .\n",
      "{4: 'Sammon projection method'}\n",
      "Rule 4: Sammon projection method\n",
      "\n",
      "\n",
      "\n",
      "A faster model-fitting procedure can be devised by replacing the first phase of the Baum-Welch algorithm with a maximisation step .\n",
      "{4: 'Baum-Welch algorithm'}\n",
      "Rule 4: Baum-Welch algorithm\n",
      "\n",
      "\n",
      "\n",
      "This paper presents a Population Proportion Ranking Method to qualitatively rank differentially expressed genes .\n",
      "{4: 'Population Proportion Ranking Method'}\n",
      "Rule 4: Population Proportion Ranking Method\n",
      "\n",
      "\n",
      "\n",
      "The acceptor photobleaching fluorescence resonance energy transfer method is widely used for monitoring molecular interactions in cells .\n",
      "{4: 'acceptor photobleaching fluorescence resonance energy transfer method'}\n",
      "Rule 4: acceptor photobleaching fluorescence resonance energy transfer method\n",
      "\n",
      "\n",
      "\n",
      "We have developed a Bayesian network approach to find regulatory rules enriched in a foreground sequences , for example the promoters of a set of co-regulated genes , compared with the background sequences .\n",
      "{2: 'Bayesian network approach', 4: 'network approach'}\n",
      "Rule 2: Bayesian network approach\n",
      "\n",
      "\n",
      "\n",
      "To select a few features out of hundreds , we apply a simple greedy selection method as follows : a forward stepwise selection as described in was applied twenty times to the aa and seq feature set of dataset A .\n",
      "{2: 'simple greedy selection method', 4: 'selection method'}\n",
      "Rule 2: simple greedy selection method\n",
      "\n",
      "\n",
      "\n",
      "Like the Globaltest approach , the PCOT2 methodology generates a statistic for each gene set without the use of per-gene summaries .\n",
      "{4: 'Globaltest approach'}\n",
      "Rule 4: Globaltest approach\n",
      "\n",
      "\n",
      "\n",
      "In order to remove any variability introduced through the use of different multiple comparisons corrections , the False Discovery Rate controlling method of Benjamini and Yekutieli was used to provide control of Type I errors when testing for changes in multiple gene sets .\n",
      "{4: 'False Discovery Rate controlling method'}\n",
      "Rule 4: False Discovery Rate controlling method\n",
      "\n",
      "\n",
      "\n",
      "To meet the needs of clinical proteomics of comparing large sets of 2D gels , we have developed Sili2Dgel an automatic gel alignment method based on graph theory to find SAP after a recursive alignment procedure .\n",
      "{2: 'automatic gel alignment method', 4: 'gel alignment method'}\n",
      "Rule 2: automatic gel alignment method\n",
      "\n",
      "\n",
      "\n",
      "Another method , which we refer to as the ' Lake ' method , uses Markov triple analysis as a different approach to finding the P^U matrices for rooted triples of sequences .\n",
      "{4: 'Markov triple analysis'}\n",
      "Rule 4: Markov triple analysis\n",
      "\n",
      "\n",
      "\n",
      "Identification of overrepresented DNA binding sites in genes of the same cluster is performed by the SCOPE method .\n",
      "{4: 'SCOPE method'}\n",
      "Rule 4: SCOPE method\n",
      "\n",
      "\n",
      "\n",
      "We estimated the recombination rate at each TE insertion site method using a method previously developed for the D. melanogaster genome .\n",
      "{4: 'TE insertion site method'}\n",
      "Rule 4: TE insertion site method\n",
      "\n",
      "\n",
      "\n",
      "The haplotype resolution employs a phasing method that uses imperfect phylogeny .\n",
      "{4: 'phasing method'}\n",
      "Rule 4: phasing method\n",
      "\n",
      "\n",
      "\n",
      "As an alternative to the standard curve method , relative quantification can also be achieved with the method named \" comparative CT \" or \" delta-deltaCT \" .\n",
      "{2: 'standard curve method', 4: 'curve method'}\n",
      "Rule 2: standard curve method\n",
      "\n",
      "\n",
      "\n",
      "Leaves from plants in the late rosette stage were extracted with the Ariel method for DNA extraction for quantitative PCR and cloning of chromosomal sequences .\n",
      "{4: 'Ariel method'}\n",
      "Rule 4: Ariel method\n",
      "\n",
      "\n",
      "\n",
      "In this study , we presented a simple and specific nucleic acid detection method onto solid support which does not require labelling of the analyte prior to hybridization .\n",
      "{2: 'simple and specific nucleic acid detection method', 4: 'acid detection method'}\n",
      "Rule 2: simple and specific nucleic acid detection method\n",
      "\n",
      "\n",
      "\n",
      "That led us to develop the staggered reannealing method .\n",
      "{2: 'staggered reannealing method', 4: 'reannealing method'}\n",
      "Rule 2: staggered reannealing method\n",
      "\n",
      "\n",
      "\n",
      "The YIU method allows rapid conversion of cDNAs into shRNA templates .\n",
      "{4: 'YIU method'}\n",
      "Rule 4: YIU method\n",
      "\n",
      "\n",
      "\n",
      "For gene deletions , the Red / RecET recombination method developed by several groups is considered as the most useful now .\n",
      "{2: 'Red / RecET recombination method', 4: 'RecET recombination method'}\n",
      "Rule 2: Red / RecET recombination method\n",
      "\n",
      "\n",
      "\n",
      "The most frequently employed large-scale caspase-3 preparation method includes separate expression of the two insoluble domains in E. coli and subsequent refolding of the two combined domains for the active enzyme .\n",
      "{2: 'employed large-scale caspase-3 preparation method', 4: 'caspase-3 preparation method'}\n",
      "Rule 2: employed large-scale caspase-3 preparation method\n",
      "\n",
      "\n",
      "\n",
      "The classical optimization method is not only time-consuming and tedious but also does not depict the complete effects of the parameters in the process and ignores the combined interactions between physicochemical parameters .\n",
      "{2: 'classical optimization method', 4: 'optimization method'}\n",
      "Rule 2: classical optimization method\n",
      "\n",
      "\n",
      "\n",
      "The key to the success of this method is a very high diversity V-gene repertoire template that was obtained from 140 non-immunized donors in combination with optimized primer set and cloning technique .\n",
      "{4: 'cloning technique'}\n",
      "Rule 4: cloning technique\n",
      "\n",
      "\n",
      "\n",
      "Thirteen transcripts met this selection criterion ; six were further tested by quantitative RT-PCR analysis of 62 additional samples from this trial and a second SU5416 Phase III trial of similar design .\n",
      "{2: 'quantitative RT-PCR analysis', 4: 'RT-PCR analysis'}\n",
      "Rule 2: quantitative RT-PCR analysis\n",
      "\n",
      "\n",
      "\n",
      "For statistical analysis , we used the Significance Analysis of Microarray software package from Stanford University .\n",
      "{4: 'Significance Analysis'}\n",
      "Rule 4: Significance Analysis\n",
      "\n",
      "\n",
      "\n",
      "Haplotypes with a frequency of at least 0.01 were analyzed using a two-step PCA method .\n",
      "{2: 'two-step PCA method', 4: 'PCA method'}\n",
      "Rule 2: two-step PCA method\n",
      "\n",
      "\n",
      "\n",
      "In conclusion , BsaXI RFLP analysis is a simple and rapid approach for the single step determination of D310 polymorphism of mitochondrial DNA .\n",
      "{4: 'BsaXI RFLP analysis'}\n",
      "Rule 4: BsaXI RFLP analysis\n",
      "\n",
      "\n",
      "\n",
      "We describe a tissue culture method combined with a novel read out system for both tissue cultivation and rapid assessment of drug efficacy together with the simultaneous identification of different cell types within non-fixed breast cancer tissues .\n",
      "{4: 'tissue culture method'}\n",
      "Rule 4: tissue culture method\n",
      "\n",
      "\n",
      "\n",
      "Together with well established models such as 3D culture systems and animal tumor xenografts , this tissue slice model will be helpful to enhance the understanding of anti-tumor drug activity .\n",
      "{4: 'tissue slice model'}\n",
      "Rule 4: tissue slice model\n",
      "\n",
      "\n",
      "\n",
      "In this work , we present a new microarray-based high-throughput screening method to identifying candidate marker mRNAs for the early detection of epithelial cells diluted in peripheral blood cells .\n",
      "{2: 'new microarray-based high-throughput screening method', 4: 'screening method'}\n",
      "Rule 2: new microarray-based high-throughput screening method\n",
      "\n",
      "\n",
      "\n",
      "In this work , we present a new microarray-based high-throughput screening approach to identifying candidate marker mRNAs for early detection of epithelial cells diluted in peripheral blood cells .\n",
      "{2: 'new microarray-based high-throughput screening approach', 4: 'screening approach'}\n",
      "Rule 2: new microarray-based high-throughput screening approach\n",
      "\n",
      "\n",
      "\n",
      "Breiman et al. developed a decision tree model , which uses a variant of the classification and regression tree method .\n",
      "{4: 'decision tree model'}\n",
      "Rule 4: decision tree model\n",
      "\n",
      "\n",
      "\n",
      "Our method of analysis employed the adjusted indirect comparisons meta-analysis method .\n",
      "{2: 'adjusted indirect comparisons meta-analysis method', 4: 'comparisons method'}\n",
      "Rule 2: adjusted indirect comparisons meta-analysis method\n",
      "\n",
      "\n",
      "\n",
      "Fibrillation intervals have been used as an index of local refractoriness and shown to correlate well with the local atrial and ventricular refractoriness determined using extrastimulus technique in animal in serval previous studies .\n",
      "{4: 'extrastimulus technique'}\n",
      "Rule 4: extrastimulus technique\n",
      "\n",
      "\n",
      "\n",
      "We accounted for correlations within medical practices using the generalized estimation equation method .\n",
      "{2: 'generalized estimation equation method', 4: 'estimation equation method'}\n",
      "Rule 2: generalized estimation equation method\n",
      "\n",
      "\n",
      "\n",
      "Relative changes in gene expression were calculated using the ΔΔCt method .\n",
      "{4: 'ΔΔCt method'}\n",
      "Rule 4: ΔΔCt method\n",
      "\n",
      "\n",
      "\n",
      "We demonstrated a pretreatment method to collect well-characterized , viable , single cells without using fluorescent labels and without significant damage to the cells .\n",
      "{4: 'pretreatment method'}\n",
      "Rule 4: pretreatment method\n",
      "\n",
      "\n",
      "\n",
      "The technique uses a probabilistic ensemble approach to group the measured multivariate features into a set of consensus clusters .\n",
      "{2: 'probabilistic ensemble approach', 4: 'ensemble approach'}\n",
      "Rule 2: probabilistic ensemble approach\n",
      "\n",
      "\n",
      "\n",
      "We report here a reliable automated microscopy method for quantitative measurement of myosin light chain phosphorylation in adherent cells .\n",
      "{2: 'reliable automated microscopy method', 4: 'microscopy method'}\n",
      "Rule 2: reliable automated microscopy method\n",
      "\n",
      "\n",
      "\n",
      "We adopted the complete linkage method , where the distance between two clusters is computed as the distance between the two farthest objects in the two clusters .\n",
      "{2: 'complete linkage method', 4: 'linkage method'}\n",
      "Rule 2: complete linkage method\n",
      "\n",
      "\n",
      "\n",
      "In the present work we present an automated assay for the estimation of blood total antioxidant capacity , based on the crocin bleaching method .\n",
      "{4: 'crocin bleaching method'}\n",
      "Rule 4: crocin bleaching method\n",
      "\n",
      "\n",
      "\n",
      "This approach is used in the freely distributed program PCDCON written by Gillespie and is the most widely used experimental deconvolution technique .\n",
      "{2: 'used experimental deconvolution technique', 4: 'deconvolution technique'}\n",
      "Rule 2: used experimental deconvolution technique\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four electrode technique used in this study is considered the standard in biophysical sciences and is widely employed to measure electrical conductance / impedance of biological tissue .\n",
      "{4: 'electrode technique'}\n",
      "Rule 4: electrode technique\n",
      "\n",
      "\n",
      "\n",
      "In consultation with the executive members of these associations , all 4,045 names of the members of the associations were obtained through stratified sampling and a probability sampling method was used to select 600 respondents for the questionnaire survey .\n",
      "{4: 'probability sampling method'}\n",
      "Rule 4: probability sampling method\n",
      "\n",
      "\n",
      "\n",
      "Treatment GroupControl GroupTreatment Effect SizeControl Effect SizeComparison Effect SizeR2Effect Size f2Sample SizeVickersBadger1.020.001.020.210.2740VickersSMLGC-W.AVG0.800.160.640.090.10101Vickers90 % C-W.AVG0.620.160.460.050.05187A-W.AVGC-W.AVG0.560.160.400.040.04235Vickers90 % Carpenter0.620.370.250.020.02476A-W.AVGCarpenter0.560.370.190.010.01957A final method we employ is to compare the two weighted averages .\n",
      "{2: 'Effect SizeComparison Effect SizeR2Effect Size f2Sample SizeVickersBadger1.020.001.020.210.2740VickersSMLGC-W.AVG0.800.160.640.090.10101Vickers90 % C-W.AVG0.620.160.460.050.05187A-W.AVGC-W.AVG0.560.160.400.040.04235Vickers90 % Carpenter0.620.370.250.020.02476A-W.AVGCarpenter0.560.370.190.010.01957A final method', 4: 'Effect SizeComparison Effect SizeR2Effect Size f2Sample SizeVickersBadger1.020.001.020.210.2740VickersSMLGC-W.AVG0.800.160.640.090.10101Vickers90 % C-W.AVG0.620.160.460.050.05187A-W.AVGC-W.AVG0.560.160.400.040.04235Vickers90 % Carpenter0.620.370.250.020.02476A-W.AVGCarpenter0.560.370.190.010.01957A method'}\n",
      "Rule 2: Effect SizeComparison Effect SizeR2Effect Size f2Sample SizeVickersBadger1.020.001.020.210.2740VickersSMLGC-W.AVG0.800.160.640.090.10101Vickers90 % C-W.AVG0.620.160.460.050.05187A-W.AVGC-W.AVG0.560.160.400.040.04235Vickers90 % Carpenter0.620.370.250.020.02476A-W.AVGCarpenter0.560.370.190.010.01957A final method\n",
      "\n",
      "\n",
      "\n",
      "Because stem cells are targeted by the amniotic fluid , in utero delivery method , the specific inhibition of C-MYC in a relative small population of cells has a highly significant effect on the histology of the rapidly developing lungs and intestines .\n",
      "{2: 'utero delivery method', 4: 'delivery method'}\n",
      "Rule 2: utero delivery method\n",
      "\n",
      "\n",
      "\n",
      "Raw probe intensities from each oligonucleotide array were processed by the RMA algorithm .\n",
      "{4: 'RMA algorithm'}\n",
      "Rule 4: RMA algorithm\n",
      "\n",
      "\n",
      "\n",
      "To generate sufficient material for profiling by microarray , a global amplification method was designed to overcome the detrimental effects of high-cycle-number PCR amplification on transcript representation , and to alleviate inefficient amplification by in vitro transcription in the nanogram range .\n",
      "{2: 'global amplification method', 4: 'amplification method'}\n",
      "Rule 2: global amplification method\n",
      "\n",
      "\n",
      "\n",
      "Longer mitochondrial gene encoding primers are likely to increase the reproducibility and specificity when compared to RAPD technique .\n",
      "{4: 'RAPD technique'}\n",
      "Rule 4: RAPD technique\n",
      "\n",
      "\n",
      "\n",
      "We investigated the relationship between mutation rate and extra-pair paternity using a maximum likelihood test analysing the relationship between two continuous characters .\n",
      "{2: 'maximum likelihood test', 4: 'likelihood test'}\n",
      "Rule 2: maximum likelihood test\n",
      "\n",
      "\n",
      "\n",
      "We recently developed an informatics method to provide an estimate for the orderliness of synonymous codon usage and the amount of synonymous codon usage bias .\n",
      "{4: 'informatics method'}\n",
      "Rule 4: informatics method\n",
      "\n",
      "\n",
      "\n",
      "Pybus et al. presented the \" skyline plot \" method that uses a step-function to approximate the population history obtained from an estimated genealogy .\n",
      "{2: 'skyline plot method', 4: 'skyline plot method'}\n",
      "Rule 2: skyline plot method\n",
      "\n",
      "\n",
      "\n",
      "As an alternative approach to recovering gene cassettes , the cassette PCR technique has been developed .\n",
      "{4: 'cassette PCR technique'}\n",
      "Rule 4: cassette PCR technique\n",
      "\n",
      "\n",
      "\n",
      "Here a culture-independent , environmental PCR survey approach was used to examine Cyanidiales species composition in nature .\n",
      "{2: 'culture-independent environmental PCR survey approach', 4: 'PCR survey approach'}\n",
      "Rule 2: culture-independent environmental PCR survey approach\n",
      "\n",
      "\n",
      "\n",
      "Here we adapted a mating model developed by Oddou-Muratorio et al. .\n",
      "{4: 'mating model'}\n",
      "Rule 4: mating model\n",
      "\n",
      "\n",
      "\n",
      "Given variation in squirrel and capuchin monkey size and , consequently , in allometric shape variation associated with those size differences , a normalization technique to scale data and remove allometric effects was applied .\n",
      "{4: 'normalization technique'}\n",
      "Rule 4: normalization technique\n",
      "\n",
      "\n",
      "\n",
      "The Gu method uses a maximum-likelihood procedure to test whether there has been a significant change in the rate of evolution after gene duplication leading to the two paralogs .\n",
      "{4: 'Gu method'}\n",
      "Rule 4: Gu method\n",
      "\n",
      "\n",
      "\n",
      "For example , consider the evaluation method of generating synthetic data using computer simulation techniques .\n",
      "{4: 'evaluation method'}\n",
      "Rule 4: evaluation method\n",
      "\n",
      "\n",
      "\n",
      "First , net among clade divergence ± standard error corrected with a TN model .\n",
      "{4: 'TN model'}\n",
      "Rule 4: TN model\n",
      "\n",
      "\n",
      "\n",
      "This was done by the split decomposition method in SplitsTree , version 2.4 .\n",
      "{2: 'split decomposition method', 4: 'decomposition method'}\n",
      "Rule 2: split decomposition method\n",
      "\n",
      "\n",
      "\n",
      "We therefore used a codon by codon maximum likelihood test , to ask if we could detect any codons that have been under repeated , strong positive selection .\n",
      "{4: 'codon maximum likelihood test'}\n",
      "Rule 4: codon maximum likelihood test\n",
      "\n",
      "\n",
      "\n",
      "We used the ' fossil cross-validation ' method to measure the agreement between these different calibration points .\n",
      "{4: 'fossil method'}\n",
      "Rule 4: fossil method\n",
      "\n",
      "\n",
      "\n",
      "In addition , we used the rarefaction method of Petit et al. to correct for the difference in the number of genes sampled in the two species .\n",
      "{4: 'rarefaction method'}\n",
      "Rule 4: rarefaction method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'To', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 2, 'deprel': 'mark', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'control', 'lemma': 'control', 'upos': 'VERB', 'xpos': 'VB', 'head': 13, 'deprel': 'advcl', 'misc': 'start_char=3|end_char=10', 'children': [1, 6, 30]}\n",
      "{'id': 3, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 6, 'deprel': 'case', 'misc': 'start_char=11|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 6, 'deprel': 'det', 'misc': 'start_char=15|end_char=18', 'children': []}\n",
      "{'id': 5, 'text': 'possible', 'lemma': 'possible', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 6, 'deprel': 'amod', 'misc': 'start_char=19|end_char=27', 'children': []}\n",
      "{'id': 6, 'text': 'effect', 'lemma': 'effect', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'obl', 'misc': 'start_char=28|end_char=34', 'children': [3, 4, 5, 10]}\n",
      "{'id': 7, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 10, 'deprel': 'case', 'misc': 'start_char=35|end_char=37', 'children': []}\n",
      "{'id': 8, 'text': 'common', 'lemma': 'common', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 10, 'deprel': 'amod', 'misc': 'start_char=38|end_char=44', 'children': []}\n",
      "{'id': 9, 'text': 'phylogenetic', 'lemma': 'phylogenetic', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 10, 'deprel': 'amod', 'misc': 'start_char=45|end_char=57', 'children': []}\n",
      "{'id': 10, 'text': 'descent', 'lemma': 'descent', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'nmod', 'misc': 'start_char=58|end_char=65', 'children': [7, 8, 9]}\n",
      "{'id': 11, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 13, 'deprel': 'punct', 'misc': 'start_char=66|end_char=67', 'children': []}\n",
      "{'id': 12, 'text': 'we', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP', 'head': 13, 'deprel': 'nsubj', 'misc': 'start_char=68|end_char=70', 'children': []}\n",
      "{'id': 13, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=71|end_char=75', 'children': [2, 11, 12, 18, 20]}\n",
      "{'id': 14, 'text': 'Felsenstein', 'lemma': 'felsenstein', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'nmod:poss', 'misc': 'start_char=76|end_char=87', 'children': [15]}\n",
      "{'id': 15, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 14, 'deprel': 'case', 'misc': 'start_char=88|end_char=90', 'children': []}\n",
      "{'id': 16, 'text': 'independent', 'lemma': 'independent', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 18, 'deprel': 'amod', 'misc': 'start_char=91|end_char=102', 'children': []}\n",
      "{'id': 17, 'text': 'comparison', 'lemma': 'comparison', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'compound', 'misc': 'start_char=103|end_char=113', 'children': []}\n",
      "{'id': 18, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'obj', 'misc': 'start_char=114|end_char=120', 'children': [14, 16, 17]}\n",
      "{'id': 19, 'text': 'as', 'lemma': 'as', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 20, 'deprel': 'mark', 'misc': 'start_char=121|end_char=123', 'children': []}\n",
      "{'id': 20, 'text': 'implemented', 'lemma': 'implement', 'upos': 'VERB', 'xpos': 'VBN', 'head': 13, 'deprel': 'advcl', 'misc': 'start_char=124|end_char=135', 'children': [19, 24, 27]}\n",
      "{'id': 21, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 24, 'deprel': 'case', 'misc': 'start_char=136|end_char=138', 'children': []}\n",
      "{'id': 22, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 24, 'deprel': 'det', 'misc': 'start_char=139|end_char=142', 'children': []}\n",
      "{'id': 23, 'text': 'computer', 'lemma': 'computer', 'upos': 'NOUN', 'xpos': 'NN', 'head': 24, 'deprel': 'compound', 'misc': 'start_char=143|end_char=151', 'children': []}\n",
      "{'id': 24, 'text': 'program', 'lemma': 'program', 'upos': 'NOUN', 'xpos': 'NN', 'head': 20, 'deprel': 'obl', 'misc': 'start_char=152|end_char=159', 'children': [21, 22, 23, 25]}\n",
      "{'id': 25, 'text': 'PDAP', 'lemma': 'pdap', 'upos': 'NOUN', 'xpos': 'NN', 'head': 24, 'deprel': 'dep', 'misc': 'start_char=160|end_char=164', 'children': []}\n",
      "{'id': 26, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 27, 'deprel': 'case', 'misc': 'start_char=165|end_char=167', 'children': []}\n",
      "{'id': 27, 'text': 'Garland', 'lemma': 'garland', 'upos': 'NOUN', 'xpos': 'NN', 'head': 20, 'deprel': 'obl', 'misc': 'start_char=168|end_char=175', 'children': [26, 29]}\n",
      "{'id': 28, 'text': 'et', 'lemma': 'et', 'upos': 'X', 'xpos': 'FW', 'head': 29, 'deprel': 'compound', 'misc': 'start_char=176|end_char=178', 'children': []}\n",
      "{'id': 29, 'text': 'al.', 'lemma': 'al.', 'upos': 'X', 'xpos': 'FW', 'head': 27, 'deprel': 'advmod', 'misc': 'start_char=179|end_char=182', 'children': [28]}\n",
      "{'id': 30, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 2, 'deprel': 'punct', 'misc': 'start_char=183|end_char=184', 'children': []}\n",
      "To control for the possible effect of common phylogenetic descent , we used Felsenstein 's independent comparison method as implemented in the computer program PDAP by Garland et al. .\n",
      "{2: 'independent comparison method', 4: 'comparison method', 5: \"Felsenstein 's independent comparison method\"}\n",
      "Rule 5: Felsenstein 's independent comparison method\n",
      "\n",
      "\n",
      "\n",
      "To classify our sequences into families , we used a nucleotide sequence identity matrix built using pairwise deletion method .\n",
      "{2: 'pairwise deletion method', 4: 'deletion method'}\n",
      "Rule 2: pairwise deletion method\n",
      "\n",
      "\n",
      "\n",
      "Analysis of the interviews was undertaken using the framework approach outlined by Pope et al and Ritchie and Spencer .\n",
      "{4: 'framework approach'}\n",
      "Rule 4: framework approach\n",
      "\n",
      "\n",
      "\n",
      "A multiple logistic regression model with backward selection was used to estimate the simultaneous effect of several determinants of neuropathy and peripheral vascular disease among the sample population .\n",
      "{2: 'multiple logistic regression model', 4: 'regression model'}\n",
      "Rule 2: multiple logistic regression model\n",
      "\n",
      "\n",
      "\n",
      "These results give an idea of the \" normal \" working method of the GP .\n",
      "{2: 'normal working method', 4: 'working method'}\n",
      "Rule 2: normal working method\n",
      "\n",
      "\n",
      "\n",
      "Linkage analyses were conducted using the variance components analysis method as implemented in the SOLAR program .\n",
      "{4: 'variance components analysis method'}\n",
      "Rule 4: variance components analysis method\n",
      "\n",
      "\n",
      "\n",
      "Liang et al. developed a multipoint linkage mapping approach for estimating the location of a trait locus using affected sibling pairs .\n",
      "{2: 'multipoint linkage mapping approach', 4: 'linkage mapping approach'}\n",
      "Rule 2: multipoint linkage mapping approach\n",
      "\n",
      "\n",
      "\n",
      "Variance-component univariate linkage analysis implemented in SOLAR was used for heritability estimation , and two-point and multipoint linkage analyses .\n",
      "{2: 'Variance-component univariate linkage analysis', 4: 'linkage analysis'}\n",
      "Rule 2: Variance-component univariate linkage analysis\n",
      "\n",
      "\n",
      "\n",
      "The survival analysis residual method attempts to detect a genetic effect on the age of onset of obesity / overweight .\n",
      "{2: 'survival analysis residual method', 4: 'survival analysis method'}\n",
      "Rule 2: survival analysis residual method\n",
      "\n",
      "\n",
      "\n",
      "Since the vast majority of our multiplex families were nuclear families with two or more affected siblings , but no other affected relative pairs , we used the nonparametric MLS method for affected sibling pair data to compute family-specific lod scores .\n",
      "{2: 'nonparametric MLS method', 4: 'MLS method'}\n",
      "Rule 2: nonparametric MLS method\n",
      "\n",
      "\n",
      "\n",
      "Linkage analysis with microsatellite markers was performed using a nonparametric allele-sharing method in each of the 10 replicates and also in the pooled data .\n",
      "{4: 'Linkage analysis'}\n",
      "Rule 4: Linkage analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'We', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP', 'head': 3, 'deprel': 'nsubj', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'then', 'lemma': 'then', 'upos': 'ADV', 'xpos': 'RB', 'head': 3, 'deprel': 'advmod', 'misc': 'start_char=3|end_char=7', 'children': []}\n",
      "{'id': 3, 'text': 'combined', 'lemma': 'combine', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=8|end_char=16', 'children': [1, 2, 5, 12, 19]}\n",
      "{'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 5, 'deprel': 'det', 'misc': 'start_char=17|end_char=20', 'children': []}\n",
      "{'id': 5, 'text': 'results', 'lemma': 'result', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 3, 'deprel': 'obj', 'misc': 'start_char=21|end_char=28', 'children': [4, 11]}\n",
      "{'id': 6, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 11, 'deprel': 'case', 'misc': 'start_char=29|end_char=31', 'children': []}\n",
      "{'id': 7, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 11, 'deprel': 'det', 'misc': 'start_char=32|end_char=35', 'children': []}\n",
      "{'id': 8, 'text': '10', 'lemma': '10', 'upos': 'NUM', 'xpos': 'CD', 'head': 11, 'deprel': 'nummod', 'misc': 'start_char=36|end_char=38', 'children': []}\n",
      "{'id': 9, 'text': 'primary', 'lemma': 'primary', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 11, 'deprel': 'amod', 'misc': 'start_char=39|end_char=46', 'children': []}\n",
      "{'id': 10, 'text': 'genome', 'lemma': 'genome', 'upos': 'NOUN', 'xpos': 'NN', 'head': 11, 'deprel': 'compound', 'misc': 'start_char=47|end_char=53', 'children': []}\n",
      "{'id': 11, 'text': 'scans', 'lemma': 'scan', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=54|end_char=59', 'children': [6, 7, 8, 9, 10]}\n",
      "{'id': 12, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 3, 'deprel': 'xcomp', 'misc': 'start_char=60|end_char=65', 'children': [15, 17]}\n",
      "{'id': 13, 'text': 'Fisher', 'lemma': 'fisher', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'nmod:poss', 'misc': 'start_char=66|end_char=72', 'children': [14]}\n",
      "{'id': 14, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 13, 'deprel': 'case', 'misc': 'start_char=73|end_char=75', 'children': []}\n",
      "{'id': 15, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=76|end_char=82', 'children': [13]}\n",
      "{'id': 16, 'text': 'of', 'lemma': 'of', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 17, 'deprel': 'mark', 'misc': 'start_char=83|end_char=85', 'children': []}\n",
      "{'id': 17, 'text': 'combining', 'lemma': 'combine', 'upos': 'VERB', 'xpos': 'VBG', 'head': 12, 'deprel': 'advcl', 'misc': 'start_char=86|end_char=95', 'children': [16, 18]}\n",
      "{'id': 18, 'text': 'p-values', 'lemma': 'p-value', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 17, 'deprel': 'obj', 'misc': 'start_char=96|end_char=104', 'children': []}\n",
      "{'id': 19, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=105|end_char=106', 'children': []}\n",
      "We then combined the results of the 10 primary genome scans using Fisher 's method of combining p-values .\n",
      "{5: \"Fisher 's method\"}\n",
      "Rule 5: Fisher 's method\n",
      "\n",
      "\n",
      "\n",
      "To account for the non-independence between these SNPs , a spectral decomposition method was used to obtain the effective number of independent SNPs .\n",
      "{2: 'spectral decomposition method', 4: 'decomposition method'}\n",
      "Rule 2: spectral decomposition method\n",
      "\n",
      "\n",
      "\n",
      "We also expected that CIs based on the GEE estimator of location would be narrower than the Zlr-bootstrap CIs because the GEE method jointly models the IBD sharing pattern at all markers .\n",
      "{4: 'GEE method'}\n",
      "Rule 4: GEE method\n",
      "\n",
      "\n",
      "\n",
      "This nonparametric approach is based on the difference of LOD score of the likelihood under the null and alternative hypothesis , where likelihoods are computed under a multivariate normality assumption of the trait under study .\n",
      "{4: 'LOD score'}\n",
      "Rule 4: LOD score\n",
      "\n",
      "\n",
      "\n",
      "Heritability estimates and evidence for linkage were obtained using the variance components approach implemented in SOLAR version 2.1.2 .\n",
      "{4: 'variance components approach'}\n",
      "Rule 4: variance components approach\n",
      "\n",
      "\n",
      "\n",
      "In any case , when the inter-SNP distance is small , one can employ the MILC method to take care of recombination , and then single-point linkage analysis has more power .\n",
      "{4: 'MILC method'}\n",
      "Rule 4: MILC method\n",
      "\n",
      "\n",
      "\n",
      "In any case , when the inter-SNP distance is small , one can employ the MILC method to take care of recombination , and then single-point linkage analysis has more power .\n",
      "{2: 'single-point linkage analysis', 4: 'linkage analysis'}\n",
      "Rule 2: single-point linkage analysis\n",
      "\n",
      "\n",
      "\n",
      "The multifactor-dimensionality reduction method was developed specifically to detect higher-order interactions among polymorphisms even when the marginal effects are very small .\n",
      "{4: 'multifactor-dimensionality reduction method'}\n",
      "Rule 4: multifactor-dimensionality reduction method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Efron', 'lemma': 'efron', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=5', 'children': [2]}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 1, 'deprel': 'case', 'misc': 'start_char=6|end_char=8', 'children': []}\n",
      "{'id': 3, 'text': 'local', 'lemma': 'local', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 7, 'deprel': 'amod', 'misc': 'start_char=9|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'false', 'lemma': 'false', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 7, 'deprel': 'amod', 'misc': 'start_char=15|end_char=20', 'children': []}\n",
      "{'id': 5, 'text': 'discovery', 'lemma': 'discovery', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'compound', 'misc': 'start_char=21|end_char=30', 'children': []}\n",
      "{'id': 6, 'text': 'rate', 'lemma': 'rate', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'compound', 'misc': 'start_char=31|end_char=35', 'children': []}\n",
      "{'id': 7, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'nsubj:pass', 'misc': 'start_char=36|end_char=42', 'children': [1, 3, 4, 5, 6]}\n",
      "{'id': 8, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 9, 'deprel': 'aux:pass', 'misc': 'start_char=43|end_char=46', 'children': []}\n",
      "{'id': 9, 'text': 'applied', 'lemma': 'apply', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=47|end_char=54', 'children': [7, 8, 13, 15, 22]}\n",
      "{'id': 10, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'TO', 'head': 13, 'deprel': 'case', 'misc': 'start_char=55|end_char=57', 'children': []}\n",
      "{'id': 11, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 13, 'deprel': 'det', 'misc': 'start_char=58|end_char=61', 'children': []}\n",
      "{'id': 12, 'text': 'FBAT', 'lemma': 'fbat', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'compound', 'misc': 'start_char=62|end_char=66', 'children': []}\n",
      "{'id': 13, 'text': 'results', 'lemma': 'result', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 9, 'deprel': 'obl', 'misc': 'start_char=67|end_char=74', 'children': [10, 11, 12]}\n",
      "{'id': 14, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 15, 'deprel': 'mark', 'misc': 'start_char=75|end_char=77', 'children': []}\n",
      "{'id': 15, 'text': 'identify', 'lemma': 'identify', 'upos': 'VERB', 'xpos': 'VB', 'head': 9, 'deprel': 'xcomp', 'misc': 'start_char=78|end_char=86', 'children': [14, 17, 21]}\n",
      "{'id': 16, 'text': 'significant', 'lemma': 'significant', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 17, 'deprel': 'amod', 'misc': 'start_char=87|end_char=98', 'children': []}\n",
      "{'id': 17, 'text': 'markers', 'lemma': 'marker', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'obj', 'misc': 'start_char=99|end_char=106', 'children': [16]}\n",
      "{'id': 18, 'text': 'after', 'lemma': 'after', 'upos': 'ADP', 'xpos': 'IN', 'head': 21, 'deprel': 'case', 'misc': 'start_char=107|end_char=112', 'children': []}\n",
      "{'id': 19, 'text': 'multiple', 'lemma': 'multiple', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 21, 'deprel': 'amod', 'misc': 'start_char=113|end_char=121', 'children': []}\n",
      "{'id': 20, 'text': 'comparison', 'lemma': 'comparison', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'compound', 'misc': 'start_char=122|end_char=132', 'children': []}\n",
      "{'id': 21, 'text': 'adjustments', 'lemma': 'adjustment', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=133|end_char=144', 'children': [18, 19, 20]}\n",
      "{'id': 22, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 9, 'deprel': 'punct', 'misc': 'start_char=145|end_char=146', 'children': []}\n",
      "Efron 's local false discovery rate method was applied to the FBAT results to identify significant markers after multiple comparison adjustments .\n",
      "{2: 'local false discovery rate method', 4: 'discovery rate method', 5: \"Efron 's local false discovery rate method\"}\n",
      "Rule 5: Efron 's local false discovery rate method\n",
      "\n",
      "\n",
      "\n",
      "Slager and Schaid extended the original CA trend test to case-control studies with family data , in which they modeled the correlations among related cases or controls as functions of the probability of their marker alleles shared identically by descent .\n",
      "{2: 'original CA trend test', 4: 'CA trend test'}\n",
      "Rule 2: original CA trend test\n",
      "\n",
      "\n",
      "\n",
      "The set association approach manages the dimensionality problem by reducing the number of markers to a smaller number of important markers .\n",
      "{4: 'set association approach'}\n",
      "Rule 4: set association approach\n",
      "\n",
      "\n",
      "\n",
      "The authors have developed a field sampling method for obtaining high quality DNA from bluegill sunfish .\n",
      "{4: 'field sampling method'}\n",
      "Rule 4: field sampling method\n",
      "\n",
      "\n",
      "\n",
      "Here we describe a novel PCR method that combined hemi-nested PCR with touchdown PCR for primer-template mismatches .\n",
      "{2: 'novel PCR method', 4: 'PCR method'}\n",
      "Rule 2: novel PCR method\n",
      "\n",
      "\n",
      "\n",
      "The likelihood ratio test was calculated as above .\n",
      "{4: 'likelihood ratio test'}\n",
      "Rule 4: likelihood ratio test\n",
      "\n",
      "\n",
      "\n",
      "Other methods that have been implemented are to adjust the lipid levels for medication by using medications as covariates in a linear regression model .\n",
      "{2: 'linear regression model', 4: 'regression model'}\n",
      "Rule 2: linear regression model\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we propose a one degree of freedom test for association between a candidate gene and a binary trait .\n",
      "{4: 'freedom test'}\n",
      "Rule 4: freedom test\n",
      "\n",
      "\n",
      "\n",
      "Model fitting is based on the EM algorithm , and iterative proportional fitting , with parameter starting values defined via a random number seed .\n",
      "{4: 'EM algorithm'}\n",
      "Rule 4: EM algorithm\n",
      "\n",
      "\n",
      "\n",
      "In order to compare U133A and U133 Plus 2.0 data , we further normalized the data with a rank-based normalization method .\n",
      "{2: 'rank-based normalization method', 4: 'normalization method'}\n",
      "Rule 2: rank-based normalization method\n",
      "\n",
      "\n",
      "\n",
      "We designed a multiplex short-read DNA sequencing method to perform efficient ChIP-Seq in yeast and other small genome model organisms .\n",
      "{2: 'multiplex short-read DNA sequencing method', 4: 'DNA sequencing method'}\n",
      "Rule 2: multiplex short-read DNA sequencing method\n",
      "\n",
      "\n",
      "\n",
      "Recently , an isothermal WGA method was introduced using bacteriophage Φ29 DNA polymerase and random hexamer primers .\n",
      "{2: 'isothermal WGA method', 4: 'WGA method'}\n",
      "Rule 2: isothermal WGA method\n",
      "\n",
      "\n",
      "\n",
      "To evaluate the genetic diversity of R. africae , we used the multi-spacer typing method as previously described .\n",
      "{2: 'multi-spacer typing method', 4: 'typing method'}\n",
      "Rule 2: multi-spacer typing method\n",
      "\n",
      "\n",
      "\n",
      "They used an iterative linear regression algorithm based on intensity data from several scans for correcting spot intensities both above and below the usable range .\n",
      "{2: 'iterative linear regression algorithm', 4: 'regression algorithm'}\n",
      "Rule 2: iterative linear regression algorithm\n",
      "\n",
      "\n",
      "\n",
      "The Negative Subtraction Hybridization method described here has several practical benefits .\n",
      "{2: 'Negative Subtraction Hybridization method', 4: 'Subtraction Hybridization method'}\n",
      "Rule 2: Negative Subtraction Hybridization method\n",
      "\n",
      "\n",
      "\n",
      "To facilitate automated SNP discovery or typing , the SearchSnps method will generate output as shown in Figure 2 .\n",
      "{4: 'SearchSnps method'}\n",
      "Rule 4: SearchSnps method\n",
      "\n",
      "\n",
      "\n",
      "The fidelity of the amplification methods was determined using the ΔΔCt relative quantification method for qPCR .\n",
      "{2: 'ΔΔCt relative quantification method', 4: 'ΔΔCt relative quantification method'}\n",
      "Rule 2: ΔΔCt relative quantification method\n",
      "\n",
      "\n",
      "\n",
      "Whenever there is homology between species , there is an opportunity for identification probes with detectable hybridization signal using probe level analysis described here .\n",
      "{4: 'probe level analysis'}\n",
      "Rule 4: probe level analysis\n",
      "\n",
      "\n",
      "\n",
      "This is in contrast to a recently described protein trapping method .\n",
      "{2: 'described protein trapping method', 4: 'protein trapping method'}\n",
      "Rule 2: described protein trapping method\n",
      "\n",
      "\n",
      "\n",
      "ASAP method may be the only practical approach to obtain chloroplast DNA sequence from rare or small plant samples .\n",
      "{4: 'ASAP method'}\n",
      "Rule 4: ASAP method\n",
      "\n",
      "\n",
      "\n",
      "The qPCR technique provides a quantitative measurement of DNA copy number and accurately characterizing chromosomal breakpoints .\n",
      "{4: 'qPCR technique'}\n",
      "Rule 4: qPCR technique\n",
      "\n",
      "\n",
      "\n",
      "These are obtained using a model-based likelihood method devised for reconstructing ancestral sequences , and implemented in PAML , for our test case .\n",
      "{2: 'model-based likelihood method', 4: 'likelihood method'}\n",
      "Rule 2: model-based likelihood method\n",
      "\n",
      "\n",
      "\n",
      "Linear & LOWESS , which is the default normalization method in the Agilent Feature Extraction Software A.7.5.1 , were applied for normalizing Agilent microarrays .\n",
      "{2: 'default normalization method', 4: 'normalization method'}\n",
      "Rule 2: default normalization method\n",
      "\n",
      "\n",
      "\n",
      "Second , probabilistic divergence measures were used to compare different tree topologies in adjacent sequence windows using a Markov chain Monte-Carlo approach to estimate marginal posterior probabilities for each topology .\n",
      "{2: 'Markov chain Monte-Carlo approach', 4: 'Markov chain approach'}\n",
      "Rule 2: Markov chain Monte-Carlo approach\n",
      "\n",
      "\n",
      "\n",
      "High accuracy predictions of essential genes have also been made using flux balance analysis .\n",
      "{4: 'flux balance analysis'}\n",
      "Rule 4: flux balance analysis\n",
      "\n",
      "\n",
      "\n",
      "Correspondence analysis is a powerful method for the multivariate exploration of large-scale data .\n",
      "{4: 'Correspondence analysis'}\n",
      "Rule 4: Correspondence analysis\n",
      "\n",
      "\n",
      "\n",
      "Indeed , the SAGE method can be performed to accurately measure the abundance of both known and novel transcripts on global scale .\n",
      "{4: 'SAGE method'}\n",
      "Rule 4: SAGE method\n",
      "\n",
      "\n",
      "\n",
      "To prioritize the potential internal controls for Q-RT-PCR analyses and to study the possibility of general utilization of these potential internal controls , we first applied the block bootstrapping technique to rank genes with variance and IQR .\n",
      "{4: 'block bootstrapping technique'}\n",
      "Rule 4: block bootstrapping technique\n",
      "\n",
      "\n",
      "\n",
      "A direct analysis of translational control can be achieved by fractionation of cytoplasmic extracts in sucrose gradients , based on the methods described for polysome analysis , which involves size separation of large cellular components and monitoring the A254 across the gradient .\n",
      "{4: 'polysome analysis'}\n",
      "Rule 4: polysome analysis\n",
      "\n",
      "\n",
      "\n",
      "Redundant probe sets representing the same tentative consensus sequences or Unigene were removed and the 2,947 genes with significant differential expression patterns of 2-fold or greater were grouped into 12 clusters by hierarchical clustering using the complete agglomeration method and Euclidean distance metric according to mRNA expression within each tissue in comparison with the other two .\n",
      "{2: 'complete agglomeration method', 4: 'agglomeration method'}\n",
      "Rule 2: complete agglomeration method\n",
      "\n",
      "\n",
      "\n",
      "The normalized and filtered data sets were clustered via hierarchical clustering with the complete agglomeration method and Euclidean distance metric .\n",
      "{2: 'complete agglomeration method', 4: 'agglomeration method'}\n",
      "Rule 2: complete agglomeration method\n",
      "\n",
      "\n",
      "\n",
      "To estimate the deletion rate , we used the maximum likelihood approach proposed by Petrov et al. .\n",
      "{4: 'maximum likelihood approach'}\n",
      "Rule 4: maximum likelihood approach\n",
      "\n",
      "\n",
      "\n",
      "Detailed information of the confirmed protein characterization are elaborated in Table 1 with respect to the precursor mass , m / z error , PEAKS and SPIDER score for confidence interval for the PEAKS de novo generated peptide sequences and their corresponding homology searches .\n",
      "{4: 'SPIDER score'}\n",
      "Rule 4: SPIDER score\n",
      "\n",
      "\n",
      "\n",
      "The detailed information of the confirmed protein characterization are elaborated in Table 1 with respect to the precursor mass , m / z error , PEAKS and SPIDER score for confidence interval for the PEAKS de novo generated peptide sequences and their corresponding homology searches .\n",
      "{4: 'SPIDER score'}\n",
      "Rule 4: SPIDER score\n",
      "\n",
      "\n",
      "\n",
      "An initial guess for these 20 parameters was obtained from Mobs and then the values that maximized the total likelihood were obtained using the simplex algorithm .\n",
      "{4: 'simplex algorithm'}\n",
      "Rule 4: simplex algorithm\n",
      "\n",
      "\n",
      "\n",
      "An alternative method for predicting protein function is the Phylogenetic profile method , also known as the Co-Conservation method , which rests on the premise that functionally related proteins are gained or lost together over the course of evolution .\n",
      "{4: 'Co-Conservation method'}\n",
      "Rule 4: Co-Conservation method\n",
      "\n",
      "\n",
      "\n",
      "This RT-PCR data was also statistically analyzed by the amplification plot method using the Data Analysis for Real Time PCR approach .\n",
      "{4: 'amplification plot method'}\n",
      "Rule 4: amplification plot method\n",
      "\n",
      "\n",
      "\n",
      "This RT-PCR data was also statistically analyzed by the amplification plot method using the Data Analysis for Real Time PCR approach .\n",
      "{4: 'Data Analysis'}\n",
      "Rule 4: Data Analysis\n",
      "\n",
      "\n",
      "\n",
      "An Integer Linear Programming method has been proposed in to reduce the number of probes in the greedy design .\n",
      "{2: 'Integer Linear Programming method', 4: 'Integer Linear Programming method'}\n",
      "Rule 2: Integer Linear Programming method\n",
      "\n",
      "\n",
      "\n",
      "The RP score was used in ESPERR to capture information in sequence alignments over seven vertebrate species .\n",
      "{4: 'RP score'}\n",
      "Rule 4: RP score\n",
      "\n",
      "\n",
      "\n",
      "We have developed a feature selection method named Supervised Recursive Feature Addition .\n",
      "{4: 'feature selection method'}\n",
      "Rule 4: feature selection method\n",
      "\n",
      "\n",
      "\n",
      "For genes that could not be grouped into coordinately perturbed functional classes , a further statistical assessment was performed through significance analysis of time-series data using EDGE .\n",
      "{4: 'significance analysis'}\n",
      "Rule 4: significance analysis\n",
      "\n",
      "\n",
      "\n",
      "Here we outline an analysis strategy based on fitting regression splines with step basis functions to time course data .\n",
      "{4: 'analysis strategy'}\n",
      "Rule 4: analysis strategy\n",
      "\n",
      "\n",
      "\n",
      "For this purpose , and because of concerns related to the available genotyping techniques mentioned above , we developed a novel analysis method based on classical detection of genetic variants by dideoxy fingerprinting .\n",
      "{2: 'novel analysis method', 4: 'analysis method'}\n",
      "Rule 2: novel analysis method\n",
      "\n",
      "\n",
      "\n",
      "In addition , a straightforward Bayes factor approach to test differences between two within-gene residual variances is developed , taking Verdinelli and Wasserman as starting point .\n",
      "{2: 'straightforward Bayes factor approach', 4: 'Bayes factor approach'}\n",
      "Rule 2: straightforward Bayes factor approach\n",
      "\n",
      "\n",
      "\n",
      "The Bayes factor approach here presented provides a straightforward comparison between within-gene group-specific residual variances with minimal computing requirements .\n",
      "{4: 'Bayes factor approach'}\n",
      "Rule 4: Bayes factor approach\n",
      "\n",
      "\n",
      "\n",
      "Phylogenetic relationships among proteins were estimated using a maximum likelihood analysis of amino acid sequences with the Jones-Taylor-Thornton probability model of amino acid changes .\n",
      "{4: 'maximum likelihood analysis'}\n",
      "Rule 4: maximum likelihood analysis\n",
      "\n",
      "\n",
      "\n",
      "Phylogenetic relationships among proteins were estimated using a maximum likelihood analysis of amino acid sequences with the Jones-Taylor-Thornton probability model of amino acid changes .\n",
      "{2: 'Jones-Taylor-Thornton probability model', 4: 'probability model'}\n",
      "Rule 2: Jones-Taylor-Thornton probability model\n",
      "\n",
      "\n",
      "\n",
      "To do so , we defined differential gene expression using the RankProducts method .\n",
      "{4: 'RankProducts method'}\n",
      "Rule 4: RankProducts method\n",
      "\n",
      "\n",
      "\n",
      "The comparisons were analyzed for differential gene expression using the RankProducts method .\n",
      "{4: 'RankProducts method'}\n",
      "Rule 4: RankProducts method\n",
      "\n",
      "\n",
      "\n",
      "The performance of different annotation sources was investigated by comparing AUC results for real and random data using a two-sample Kolmogorov-Smirnov test .\n",
      "{2: 'two-sample Kolmogorov-Smirnov test', 4: 'Kolmogorov-Smirnov test'}\n",
      "Rule 2: two-sample Kolmogorov-Smirnov test\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this work , we have developed a theoretical approach to estimate allele frequency in pooled DNA samples , based on the physical principles of DNA immobilization and hybridization on solid surface using the Langmuir kinetic model and quantitative analysis of the allelic signals .\n",
      "{2: 'Langmuir kinetic model', 4: 'Langmuir model'}\n",
      "Rule 2: Langmuir kinetic model\n",
      "\n",
      "\n",
      "\n",
      "The MCL algorithm was applied to find clusters in this graph .\n",
      "{4: 'MCL algorithm'}\n",
      "Rule 4: MCL algorithm\n",
      "\n",
      "\n",
      "\n",
      "This study examined the patterns of change in ADL for those residents with moderate to severe cognitive impairment therefore the CPS was used to identify residents in two groups : those with a CPS score of 3 and classified as moderate impairment and those with a CPS score of 4 or 5 and classified as severe impairment .\n",
      "{4: 'CPS score'}\n",
      "Rule 4: CPS score\n",
      "\n",
      "\n",
      "\n",
      "This study examined the patterns of change in ADL for those residents with moderate to severe cognitive impairment therefore the CPS was used to identify residents in two groups : those with a CPS score of 3 and classified as moderate impairment and those with a CPS score of 4 or 5 and classified as severe impairment .\n",
      "{4: 'CPS score'}\n",
      "Rule 4: CPS score\n",
      "\n",
      "\n",
      "\n",
      "It uses models of skin and towel color combined with a Bayesian sequential estimation technique .\n",
      "{2: 'Bayesian sequential estimation technique', 4: 'estimation technique'}\n",
      "Rule 2: Bayesian sequential estimation technique\n",
      "\n",
      "\n",
      "\n",
      "The deterministic record linkage approach generates links on the basis of a full agreement of a unique identifier or a set of common identifiers .\n",
      "{2: 'deterministic record linkage approach', 4: 'record linkage approach'}\n",
      "Rule 2: deterministic record linkage approach\n",
      "\n",
      "\n",
      "\n",
      "It has been established , however , the Kaplan-Meier method is not appropriate for describing the probabilities of competing events since its complement overestimates the proportion of events .\n",
      "{4: 'Kaplan-Meier method'}\n",
      "Rule 4: Kaplan-Meier method\n",
      "\n",
      "\n",
      "\n",
      "Otherwise , the case was discussed in a meeting , using the Delphi technique , with all the participants of the panel .\n",
      "{4: 'Delphi technique'}\n",
      "Rule 4: Delphi technique\n",
      "\n",
      "\n",
      "\n",
      "The validation process followed a slightly modified version of the RAND® UCLA appropriateness method .\n",
      "{4: 'RAND® UCLA appropriateness method'}\n",
      "Rule 4: RAND® UCLA appropriateness method\n",
      "\n",
      "\n",
      "\n",
      "In the same way as in New Zealand and Canada , we used correlation analysis to assess the prioritisation instruments construct validity .\n",
      "{4: 'correlation analysis'}\n",
      "Rule 4: correlation analysis\n",
      "\n",
      "\n",
      "\n",
      "In this study we determine the current spatial accessibility of palliative care services in BC using a proven vector GIS catchment method .\n",
      "{2: 'proven vector GIS catchment method', 4: 'vector GIS catchment method'}\n",
      "Rule 2: proven vector GIS catchment method\n",
      "\n",
      "\n",
      "\n",
      "Doxorubicin and vinorelbine were loaded at the drug / phospholipid ratio of 150 mg / mmol using an ammonium sulfate gradient-based remote-loading method .\n",
      "{2: 'ammonium sulfate gradient-based remote-loading method', 4: 'ammonium sulfate method'}\n",
      "Rule 2: ammonium sulfate gradient-based remote-loading method\n",
      "\n",
      "\n",
      "\n",
      "In this study we propose a flow cytometric method to study peritoneal canine macrophage-Leishmania chagasi interaction by a binding assay using the stable intra-cytoplasmic fluorocrome , 5 , 6-carboxyfluorescein diacetate succinimidyl ester .\n",
      "{2: 'flow cytometric method', 4: 'flow method'}\n",
      "Rule 2: flow cytometric method\n",
      "\n",
      "\n",
      "\n",
      "One objective measure of adherence is a biochemical test called the Arkansas method , where a chemical reaction with urinary INH metabolites produces a visible blue colour change .\n",
      "{4: 'Arkansas method'}\n",
      "Rule 4: Arkansas method\n",
      "\n",
      "\n",
      "\n",
      "Overall heterogeneity and individual secretor haplotype frequencies , adjusted for covariates , were estimated by the expectation-maximization progressive insertion algorithm , as previously described .\n",
      "{2: 'expectation-maximization progressive insertion algorithm', 4: 'insertion algorithm'}\n",
      "Rule 2: expectation-maximization progressive insertion algorithm\n",
      "\n",
      "\n",
      "\n",
      "The SSCP technique developed and evaluated in our laboratory provides us with a rapid tool for detecting mutations in Entamoeba .\n",
      "{4: 'SSCP technique'}\n",
      "Rule 4: SSCP technique\n",
      "\n",
      "\n",
      "\n",
      "During the recent few decades , however , an alternative methodology to the stochastic frontier approach has been developed and its application has grown rapidly over the years .\n",
      "{2: 'stochastic frontier approach', 4: 'frontier approach'}\n",
      "Rule 2: stochastic frontier approach\n",
      "\n",
      "\n",
      "\n",
      "An alternative approach to correct for multiple testing could be to use permutation testing and assess the distribution of a maximum test statistic or minimum P-value after repeating the entire two-stage procedure n times .\n",
      "{4: 'maximum test statistic'}\n",
      "Rule 4: maximum test statistic\n",
      "\n",
      "\n",
      "\n",
      "We used decision curve analysis to explore the clinical effects of our models .\n",
      "{4: 'decision curve analysis'}\n",
      "Rule 4: decision curve analysis\n",
      "\n",
      "\n",
      "\n",
      "This study applied Q methodology , an established sorting method , to quantify subjective views on motivation .\n",
      "{2: 'established sorting method', 4: 'sorting method'}\n",
      "Rule 2: established sorting method\n",
      "\n",
      "\n",
      "\n",
      "The scoring process is derived from the aggregate scoring method .\n",
      "{2: 'aggregate scoring method', 4: 'scoring method'}\n",
      "Rule 2: aggregate scoring method\n",
      "\n",
      "\n",
      "\n",
      "An education method for law and ethics in which a small group of intern doctors and teachers of ethics , maintain smooth communication and foster mutual understanding from the standpoints of doctors and patients , corresponds to the traditional custom of Asian countries including Japan , where ethical sensitivity is established in families and communities .\n",
      "{4: 'education method'}\n",
      "Rule 4: education method\n",
      "\n",
      "\n",
      "\n",
      "The SNaPshot technique is particularly well-suited for the screening of mitochondrial DNA variants for the following reasons : i ) the short intron-less mitochondrial genes means that the entire gene can be PCR-amplified and screened in a single PCR fragment and ii ) homoplasmic mutations are represented as a single peak at each locus which simplifies the analysis .\n",
      "{4: 'SNaPshot technique'}\n",
      "Rule 4: SNaPshot technique\n",
      "\n",
      "\n",
      "\n",
      "Single-stranded conformational polymorphism analysis has been widely applied to detect SNPs , including point mutations in cancer and congenital diseases .\n",
      "{2: 'Single-stranded conformational polymorphism analysis', 4: 'polymorphism analysis'}\n",
      "Rule 2: Single-stranded conformational polymorphism analysis\n",
      "\n",
      "\n",
      "\n",
      "The nested-PCR fragments from PKD1 cDNA showing no abnormality in size were further screened for mutation by a multiple restriction fragment-single strand conformation polymorphism method .\n",
      "{2: 'multiple restriction fragment-single strand conformation polymorphism method', 4: 'restriction fragment-single strand conformation polymorphism method'}\n",
      "Rule 2: multiple restriction fragment-single strand conformation polymorphism method\n",
      "\n",
      "\n",
      "\n",
      "The MRF-SSCP technique has been developed and preliminarily used for screening other types of mutations .\n",
      "{4: 'MRF-SSCP technique'}\n",
      "Rule 4: MRF-SSCP technique\n",
      "\n",
      "\n",
      "\n",
      "The human NAT2*4 , NAT2*5A , NAT2*5B , NAT2*5C , NAT2*6A and NAT2*7B alleles were identified by genotyping using the PCR-RFLP method of Hickman & Sim .\n",
      "{4: 'PCR-RFLP method'}\n",
      "Rule 4: PCR-RFLP method\n",
      "\n",
      "\n",
      "\n",
      "The algorithm uses Markov Chain Monte Carlo methods to select at random a value from the distribution of the possible values predicted by the missing value model .\n",
      "{2: 'missing value model', 4: 'value model'}\n",
      "Rule 2: missing value model\n",
      "\n",
      "\n",
      "\n",
      "For the evaluation of gene-gene and gene-environment interactions , we used the MDR method .\n",
      "{4: 'MDR method'}\n",
      "Rule 4: MDR method\n",
      "\n",
      "\n",
      "\n",
      "The DNA cards method has been used to collect DNA samples in several clinical studies focusing on infective pathogens , such as malaria .\n",
      "{4: 'DNA cards method'}\n",
      "Rule 4: DNA cards method\n",
      "\n",
      "\n",
      "\n",
      "Linkage disequilibrium and haplotype analysis was performed using THESIAS software based on the SEM algorithm .\n",
      "{4: 'haplotype analysis'}\n",
      "Rule 4: haplotype analysis\n",
      "\n",
      "\n",
      "\n",
      "Linkage disequilibrium and haplotype analysis was performed using THESIAS software based on the SEM algorithm .\n",
      "{4: 'SEM algorithm'}\n",
      "Rule 4: SEM algorithm\n",
      "\n",
      "\n",
      "\n",
      "The 4C model is often used as a criterion method to compare the accuracy of other methods for assessing body fat .\n",
      "{4: '4C model'}\n",
      "Rule 4: 4C model\n",
      "\n",
      "\n",
      "\n",
      "The 4C model is often used as a criterion method to compare the accuracy of other methods for assessing body fat .\n",
      "{4: 'criterion method'}\n",
      "Rule 4: criterion method\n",
      "\n",
      "\n",
      "\n",
      "The automated image analysis and classification presented in this study demonstrate the feasibility of developing clinically relevant classification of histology images based on micro- texture .\n",
      "{2: 'automated image analysis', 4: 'image analysis'}\n",
      "Rule 2: automated image analysis\n",
      "\n",
      "\n",
      "\n",
      "The Greylevel Cooccurrence Matrix method is one of the most promising methods used in Texture Analysis of Magnetic Resonance Images .\n",
      "{4: 'Greylevel Cooccurrence Matrix method'}\n",
      "Rule 4: Greylevel Cooccurrence Matrix method\n",
      "\n",
      "\n",
      "\n",
      "The Greylevel Cooccurrence Matrix method is one of the most promising methods used in Texture Analysis of Magnetic Resonance Images .\n",
      "{4: 'Texture Analysis'}\n",
      "Rule 4: Texture Analysis\n",
      "\n",
      "\n",
      "\n",
      "Classification and regression tree analysis is a nonparametric method of statistical analysis used to classify observations based on a large number of possible predictive variables , and is well-suited for identifying complex interactions among variables .\n",
      "{4: 'tree analysis'}\n",
      "Rule 4: tree analysis\n",
      "\n",
      "\n",
      "\n",
      "We determined the rate ratios of those failing to respond for each pair of adjacent Pager / PDA periods and pooled the results using a fixed effects model to produce an overall rate ratio for failure to respond .\n",
      "{2: 'fixed effects model', 4: 'effects model'}\n",
      "Rule 2: fixed effects model\n",
      "\n",
      "\n",
      "\n",
      "The results of the sensitivity analysis and the ROC curves for the ANN were compared to those obtained using logistic regression .\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "Yet another straightforward and popular method is to select a classification that maximizes a measure of difference between the two groups , such as the p-value of a chi square statistic .\n",
      "{4: 'chi square statistic'}\n",
      "Rule 4: chi square statistic\n",
      "\n",
      "\n",
      "\n",
      "At the political level , critical incidents analysis is being used .\n",
      "{2: 'critical incidents analysis', 4: 'incidents analysis'}\n",
      "Rule 2: critical incidents analysis\n",
      "\n",
      "\n",
      "\n",
      "A critical incidents analysis will be conducted to identify key decisions that have influenced the implementation of telehealth and EHR in the Quebec health care system .\n",
      "{2: 'critical incidents analysis', 4: 'incidents analysis'}\n",
      "Rule 2: critical incidents analysis\n",
      "\n",
      "\n",
      "\n",
      "Inferential statistics were calculated by conducting mixed model analysis .\n",
      "{2: 'mixed model analysis', 4: 'model analysis'}\n",
      "Rule 2: mixed model analysis\n",
      "\n",
      "\n",
      "\n",
      "For the analysis of military clinical surveillance data , a weekly statistical non automated analysis is performed by IMTSSA in Marseilles , using the Current Past Experienced Graph .\n",
      "{2: 'weekly statistical non automated analysis', 4: 'non analysis'}\n",
      "Rule 2: weekly statistical non automated analysis\n",
      "\n",
      "\n",
      "\n",
      "The information derived from these analyses is also limited by the use of the summary ROC approach to pool studies .\n",
      "{4: 'summary ROC approach'}\n",
      "Rule 4: summary ROC approach\n",
      "\n",
      "\n",
      "\n",
      "We describe how a step function model fitted by isotonic regression can be used to estimate threshold limit values .\n",
      "{4: 'step function model'}\n",
      "Rule 4: step function model\n",
      "\n",
      "\n",
      "\n",
      "The Delphi method facilitates communication between and among a panel of experts , so that the process is effective and the group as a whole can deal with a complex problem .\n",
      "{4: 'Delphi method'}\n",
      "Rule 4: Delphi method\n",
      "\n",
      "\n",
      "\n",
      "Randomisation took place using stratified randomisation , in particular the minimisation method described by Pocock .\n",
      "{4: 'minimisation method'}\n",
      "Rule 4: minimisation method\n",
      "\n",
      "\n",
      "\n",
      "Lee and others recommended using the Cox proportional hazard model to estimate the prevalence ratio .\n",
      "{2: 'Cox proportional hazard model', 4: 'Cox proportional hazard model'}\n",
      "Rule 2: Cox proportional hazard model\n",
      "\n",
      "\n",
      "\n",
      "An illness severity score was derived as the predicted probability of 30-day mortality using age , gender and the 9 risk factors and comorbidities comprising the Ontario AMI mortality prediction rule .\n",
      "{4: 'illness severity score'}\n",
      "Rule 4: illness severity score\n",
      "\n",
      "\n",
      "\n",
      "The approach we focus on in this paper is a straightforward method developed by Mee and Chua based on classical t-test statistics and a linear regression model .\n",
      "{2: 'linear regression model', 4: 'regression model'}\n",
      "Rule 2: linear regression model\n",
      "\n",
      "\n",
      "\n",
      "Hunink et al have reported a method of correcting for verification bias when some participants receive the gold standard test based on variables other than the diagnostic test result , for example , if patients were sent to biopsy as a result of clinical findings .\n",
      "{2: 'gold standard test', 4: 'gold test'}\n",
      "Rule 2: gold standard test\n",
      "\n",
      "\n",
      "\n",
      "A random effects logistic regression model can be used to predict binary outcomes when observations are correlated or come from clustered data .\n",
      "{2: 'logistic regression model', 4: 'regression model'}\n",
      "Rule 2: logistic regression model\n",
      "\n",
      "\n",
      "\n",
      "Accordingly , we continued to examine the interaction domain using a mutagenesis strategy described by Francis , et al. termed ' radical ' site-directed mutagenesis .\n",
      "{4: 'mutagenesis strategy'}\n",
      "Rule 4: mutagenesis strategy\n",
      "\n",
      "\n",
      "\n",
      "PCR with product differentiation by melting curve analysis offers a cost-effective means of qualitative analysis for the presence of F. culmorum and F. graminearum in plant material .\n",
      "{2: 'melting curve analysis', 4: 'curve analysis'}\n",
      "Rule 2: melting curve analysis\n",
      "\n",
      "\n",
      "\n",
      "As all proteases described so far are cysteine proteases and nearly all proteolytic activity of cell extracts can be inhibited by cysteine protease specific inhibitors we chose a straightforward one-step purification approach described by Greenbaum et al .\n",
      "{2: 'straightforward one-step purification approach', 4: 'purification approach'}\n",
      "Rule 2: straightforward one-step purification approach\n",
      "\n",
      "\n",
      "\n",
      "The parameter values determined at convergence of the distance function were then seeded into a subsequent quasi-Newton minimization method with box constraints .\n",
      "{2: 'subsequent quasi-Newton minimization method', 4: 'minimization method'}\n",
      "Rule 2: subsequent quasi-Newton minimization method\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recently , we described a new high throughput AFLP approach for the identification of DNA polymorphism in Mycobacterium tuberculosis .\n",
      "{2: 'new high throughput AFLP approach', 4: 'throughput AFLP approach'}\n",
      "Rule 2: new high throughput AFLP approach\n",
      "\n",
      "\n",
      "\n",
      "Out of 41 naturally contaminated infant formulae and environmental samples analysed for the presence of E. sakazakii , 23 were positive by real-time PCR and 22 by the conventional culture method , giving 97.5 % concordance with the ISO-IDF reference method .\n",
      "{2: 'conventional culture method', 4: 'culture method'}\n",
      "Rule 2: conventional culture method\n",
      "\n",
      "\n",
      "\n",
      "Out of 41 naturally contaminated infant formulae and environmental samples analysed for the presence of E. sakazakii , 23 were positive by real-time PCR and 22 by the conventional culture method , giving 97.5 % concordance with the ISO-IDF reference method .\n",
      "{4: 'ISO-IDF reference method'}\n",
      "Rule 4: ISO-IDF reference method\n",
      "\n",
      "\n",
      "\n",
      "The ARDRA method demonstrated to be useful for intraspecific analysis .\n",
      "{4: 'ARDRA method'}\n",
      "Rule 4: ARDRA method\n",
      "\n",
      "\n",
      "\n",
      "The evolutionary relationships among α-proteobacteria were also examined using the character compatibility approach .\n",
      "{4: 'character compatibility approach'}\n",
      "Rule 4: character compatibility approach\n",
      "\n",
      "\n",
      "\n",
      "In this paper we describe a fieldable genotyping method for B. anthracis and Y. pestis .\n",
      "{2: 'fieldable genotyping method', 4: 'genotyping method'}\n",
      "Rule 2: fieldable genotyping method\n",
      "\n",
      "\n",
      "\n",
      "An in vitro tooth model , Saliva-coated hydroxylapatite was used to test the effects of gap3 mutagenesis to S. parasanguinis adhesion ability .\n",
      "{2: 'in vitro tooth model', 4: 'tooth model'}\n",
      "Rule 2: in vitro tooth model\n",
      "\n",
      "\n",
      "\n",
      "It is a new approach to subtype bacteria which involve amplification and fragment size analysis of polymorphic regions of DNA containing variable numbers of tandem repeat sequences .\n",
      "{4: 'fragment size analysis'}\n",
      "Rule 4: fragment size analysis\n",
      "\n",
      "\n",
      "\n",
      "Here we demonstrate the usefulness of this promoter as reference in the qRT-PCR analysis of cultures of M. fortuitum during oxidative stress .\n",
      "{4: 'qRT-PCR analysis'}\n",
      "Rule 4: qRT-PCR analysis\n",
      "\n",
      "\n",
      "\n",
      "Final alignment among aa sequences within each group was generated with PROALIGN V0.4 , a program implementing a method for multiple sequence alignment that combines an HMM approach , a progressive alignment algorithm , and a probabilistic evolution model describing the character substitution process .\n",
      "{4: 'HMM approach'}\n",
      "Rule 4: HMM approach\n",
      "\n",
      "\n",
      "\n",
      "Final alignment among aa sequences within each group was generated with PROALIGN V0.4 , a program implementing a method for multiple sequence alignment that combines an HMM approach , a progressive alignment algorithm , and a probabilistic evolution model describing the character substitution process .\n",
      "{2: 'probabilistic evolution model', 4: 'evolution model'}\n",
      "Rule 2: probabilistic evolution model\n",
      "\n",
      "\n",
      "\n",
      "Kokotovic et al. , were the first to describe a typing method for M. genitalium , which is based on whole-genome fingerprinting involving selective amplification of restriction fragments .\n",
      "{4: 'typing method'}\n",
      "Rule 4: typing method\n",
      "\n",
      "\n",
      "\n",
      "In microarray analysis the labelling of genomic DNA by random priming and the incorporation of nucleotides tagged with fluorophores is accomplished using the Klenow fragment of the DNA polymerase .\n",
      "{4: 'microarray analysis'}\n",
      "Rule 4: microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "Using the Multisite Gateway strategy , we have rapidly produced constructs that successfully produce specific gene deletions in epimastigotes of T. cruzi .\n",
      "{2: 'Multisite Gateway strategy', 4: 'Gateway strategy'}\n",
      "Rule 2: Multisite Gateway strategy\n",
      "\n",
      "\n",
      "\n",
      "With the long-term aim of setting up a screening method to identify novel regulatory cis-acting sequence elements and the associated multimeric complexes , we have evaluated the use of uv-crosslinking .\n",
      "{4: 'screening method'}\n",
      "Rule 4: screening method\n",
      "\n",
      "\n",
      "\n",
      "A second method we used was to look for common regulatory elements was oligonucleotide analysis which has been used in yeast to identify regulatory sites .\n",
      "{4: 'oligonucleotide analysis'}\n",
      "Rule 4: oligonucleotide analysis\n",
      "\n",
      "\n",
      "\n",
      "The 2-ΔCt formula is a modification of the arithmetic comparative 2ΔΔCt method that was developed to enable normalization to a measurement external to the PCR experiment , for measuring the expression of ' housekeeping ' genes following different treatments .\n",
      "{2: 'arithmetic comparative 2ΔΔCt method', 4: '2ΔΔCt method'}\n",
      "Rule 2: arithmetic comparative 2ΔΔCt method\n",
      "\n",
      "\n",
      "\n",
      "Initial miRNA expression studies were performed by means of Northern blot analysis .\n",
      "{4: 'Northern blot analysis'}\n",
      "Rule 4: Northern blot analysis\n",
      "\n",
      "\n",
      "\n",
      "The intervention mapping approach used in this study enabled the design of a RTW program tailored to the Ontario setting .\n",
      "{4: 'intervention mapping approach'}\n",
      "Rule 4: intervention mapping approach\n",
      "\n",
      "\n",
      "\n",
      "Pulse wave analysis will be used to derive a central pressure waveform via applanation tonometry .\n",
      "{4: 'Pulse wave analysis'}\n",
      "Rule 4: Pulse wave analysis\n",
      "\n",
      "\n",
      "\n",
      "Stepwise Cox proportional hazards analysis was used to assess the association between baseline factors and HIVAN , independent of other factors .\n",
      "{2: 'Stepwise Cox proportional hazards analysis', 4: 'Cox proportional hazards analysis'}\n",
      "Rule 2: Stepwise Cox proportional hazards analysis\n",
      "\n",
      "\n",
      "\n",
      "Pulse wave analysis will be used to derive a central pressure waveform via applanation tonometry at the radial artery to determine central pulse pressure and AIx as a composite measure of arterial stiffness .\n",
      "{4: 'Pulse wave analysis'}\n",
      "Rule 4: Pulse wave analysis\n",
      "\n",
      "\n",
      "\n",
      "Therefore , time period or conditional requirements for indicator eligibility and adherence are calculated by post hoc data analysis , rather than asking reviewers to assess eligibility or adherence across different notes and time periods .\n",
      "{2: 'post hoc data analysis', 4: 'hoc data analysis'}\n",
      "Rule 2: post hoc data analysis\n",
      "\n",
      "\n",
      "\n",
      "SNP genotyping was performed by the Taqman method .\n",
      "{4: 'Taqman method'}\n",
      "Rule 4: Taqman method\n",
      "\n",
      "\n",
      "\n",
      "Based on the above results , the line method was the best way to select the structure or region of interest as it was not subject to floor-effects , had a low coefficient of variation , and low within-sample variability .\n",
      "{4: 'line method'}\n",
      "Rule 4: line method\n",
      "\n",
      "\n",
      "\n",
      "A second drawback is that the need for hand-eye-mouse coordination can introduce some additional variability , although this was relatively mild with the present data as both the line and outline method had similar coefficients of variation and within-sample variability .\n",
      "{4: 'outline method'}\n",
      "Rule 4: outline method\n",
      "\n",
      "\n",
      "\n",
      "Maximum Entropy Spectral Analysis was employed to estimate the period of a rhythm , i.e. , for a given time-course previously determined to be significantly periodic by correlogram .\n",
      "{2: 'Maximum Entropy Spectral Analysis', 4: 'Maximum Entropy Analysis'}\n",
      "Rule 2: Maximum Entropy Spectral Analysis\n",
      "\n",
      "\n",
      "\n",
      "It is called Fast Fourier Transform - Non Linear Least Squares analysis .\n",
      "{2: 'Linear Least Squares analysis', 4: 'Squares analysis'}\n",
      "Rule 2: Linear Least Squares analysis\n",
      "\n",
      "\n",
      "\n",
      "We have recently reported on an alternative transcriptome amplification method that minimises differences in transcript length in the amplification step .\n",
      "{2: 'alternative transcriptome amplification method', 4: 'transcriptome amplification method'}\n",
      "Rule 2: alternative transcriptome amplification method\n",
      "\n",
      "\n",
      "\n",
      "We believe our study is likely to have yielded a higher quality set of predicted binding sites based on the fact that we have access to more recent genome annotations , search in a more tightly focused region , search relative to transcription rather than translation start , and use a prediction algorithm that would screen out some possible spurious predictions likely with a hidden Markov model approach .\n",
      "{4: 'prediction algorithm'}\n",
      "Rule 4: prediction algorithm\n",
      "\n",
      "\n",
      "\n",
      "We analyzed trends in the proportion of home deaths by region , age , and causes of deaths using Joinpoint regression analysis .\n",
      "{4: 'Joinpoint regression analysis'}\n",
      "Rule 4: Joinpoint regression analysis\n",
      "\n",
      "\n",
      "\n",
      "For this epidemiological study we have chosen a standardized observation method : the Dysphagia Disorder Survey / Dysphagia Management Staging Scale .\n",
      "{2: 'standardized observation method', 4: 'observation method'}\n",
      "Rule 2: standardized observation method\n",
      "\n",
      "\n",
      "\n",
      "Comparisons between glucose measurements were done using the Passing-Bablok regression method .\n",
      "{2: 'Passing-Bablok regression method', 4: 'regression method'}\n",
      "Rule 2: Passing-Bablok regression method\n",
      "\n",
      "\n",
      "\n",
      "Microarray results for selected genes were confirmed by real-time RT-PCR analysis .\n",
      "{2: 'real-time RT-PCR analysis', 4: 'RT-PCR analysis'}\n",
      "Rule 2: real-time RT-PCR analysis\n",
      "\n",
      "\n",
      "\n",
      "Recently , Ashkenazy and Kantelhardt and coworkers investigated binary coded variations of heart rate , which were called sign series of heart rate increments , by means of detrended fluctuation analysis .\n",
      "{2: 'detrended fluctuation analysis', 4: 'fluctuation analysis'}\n",
      "Rule 2: detrended fluctuation analysis\n",
      "\n",
      "\n",
      "\n",
      "The results of amplification were analyzed by the comparative threshold cycle method , also known as the 2-ΔΔCt method .\n",
      "{2: 'comparative threshold cycle method', 4: 'threshold cycle method'}\n",
      "Rule 2: comparative threshold cycle method\n",
      "\n",
      "\n",
      "\n",
      "Since 1999 , the Misgav Ladach method for caesarean section is used .\n",
      "{4: 'Misgav Ladach method'}\n",
      "Rule 4: Misgav Ladach method\n",
      "\n",
      "\n",
      "\n",
      "It is not possible to show all of these plots , but the respected concerning the total MDI score is shown in figures 2 and 3 .\n",
      "{2: 'total MDI score', 4: 'MDI score'}\n",
      "Rule 2: total MDI score\n",
      "\n",
      "\n",
      "\n",
      "It is not possible to show all of these plots , but the respected concerning the total BDI-I-21 score is shown in figure 1 .\n",
      "{2: 'total BDI-I-21 score', 4: 'BDI-I-21 score'}\n",
      "Rule 2: total BDI-I-21 score\n",
      "\n",
      "\n",
      "\n",
      "Additionally , a cut-off score of 6+ for the BSRS-5 was determined for psychiatric disorders using receiver operating characteristic analysis .\n",
      "{2: 'receiver operating characteristic analysis', 4: 'receiver operating analysis'}\n",
      "Rule 2: receiver operating characteristic analysis\n",
      "\n",
      "\n",
      "\n",
      "The propensity score-adjusted bootstrapping method was also used to test the mean differences of costs for the 2 high level crisis event groups : patients with 2 or more crisis-event variables and patients with 3 or more crisis-event variables .\n",
      "{2: 'propensity score-adjusted bootstrapping method', 4: 'propensity score-adjusted bootstrapping method'}\n",
      "Rule 2: propensity score-adjusted bootstrapping method\n",
      "\n",
      "\n",
      "\n",
      "In order to adjust for this lack of independence , a permutation method was used to identify a correction factor that adjusts the naïve df for the calculated p-value to a lower value at the point where the percentage of differentially expressed genes is equal to the selected alpha level based on random data .\n",
      "{4: 'permutation method'}\n",
      "Rule 4: permutation method\n",
      "\n",
      "\n",
      "\n",
      "The association method tests whether variation in a gene is correlated with an outcome .\n",
      "{4: 'association method'}\n",
      "Rule 4: association method\n",
      "\n",
      "\n",
      "\n",
      "The study analysis , based in grounded theory , was an exhaustive process that maximized the data obtained from the session .\n",
      "{4: 'study analysis'}\n",
      "Rule 4: study analysis\n",
      "\n",
      "\n",
      "\n",
      "We used a previously described match-merge method within SAS statistical software to merge the data sets on the basis of non-unique identifiers available in both datasets .\n",
      "{2: 'described match-merge method', 4: 'match-merge method'}\n",
      "Rule 2: described match-merge method\n",
      "\n",
      "\n",
      "\n",
      "Recent publications have analyzed the PMR of multiple births by alternative fetuses with a risk approach , where twin births had consistently higher mortality rates than singletons at all gestational ages .\n",
      "{4: 'risk approach'}\n",
      "Rule 4: risk approach\n",
      "\n",
      "\n",
      "\n",
      "Their Bayesian approach to parameter estimation led to convergence problems in our data , and therefore we used an alternative procedure within the empirical-Bayes framework to tackle this problem : the EM estimation algorithm in the presence of incomplete data .\n",
      "{4: 'EM estimation algorithm'}\n",
      "Rule 4: EM estimation algorithm\n",
      "\n",
      "\n",
      "\n",
      "We conducted a case study based on the \" success case method \" described by Brinkerhoff .\n",
      "{4: 'success case method'}\n",
      "Rule 4: success case method\n",
      "\n",
      "\n",
      "\n",
      "To randomly allocate participants to one of the three intervention groups the bias coin method of allocation , using a computer-based random number-producing algorithm , is used .\n",
      "{4: 'bias coin method'}\n",
      "Rule 4: bias coin method\n",
      "\n",
      "\n",
      "\n",
      "The Holt-Winters forecasting method was used to predict the mortality rate per 100,000 person-years during and after the SARS outbreak .\n",
      "{2: 'Holt-Winters forecasting method', 4: 'Holt-Winters method'}\n",
      "Rule 2: Holt-Winters forecasting method\n",
      "\n",
      "\n",
      "\n",
      "According to Strauss and Corbin , the grounded theory approach is used because little is known about autonomy and self-management of people with type 2 diabetes in a nurse-led , shared-care setting .\n",
      "{2: 'grounded theory approach', 4: 'theory approach'}\n",
      "Rule 2: grounded theory approach\n",
      "\n",
      "\n",
      "\n",
      "A specific evaluation method adapted to military syndromic surveillance objectives and conditions of engagement in the field was developed .\n",
      "{2: 'specific evaluation method', 4: 'evaluation method'}\n",
      "Rule 2: specific evaluation method\n",
      "\n",
      "\n",
      "\n",
      "For the adjusted analysis we will perform regression analysis of individual level data using methods for clustered data , multilevel , hierarchical or random effects models .\n",
      "{4: 'regression analysis'}\n",
      "Rule 4: regression analysis\n",
      "\n",
      "\n",
      "\n",
      "Household wealth was assessed by constructing an index using principal components analysis .\n",
      "{2: 'principal components analysis', 4: 'components analysis'}\n",
      "Rule 2: principal components analysis\n",
      "\n",
      "\n",
      "\n",
      "The \" human capital \" method was used to compute the indirect costs .\n",
      "{2: 'human capital method', 4: 'capital method'}\n",
      "Rule 2: human capital method\n",
      "\n",
      "\n",
      "\n",
      "During a fold simulation , we need a scoring method to evaluate the quality of newly simulated conformations relative to those already generated .\n",
      "{4: 'scoring method'}\n",
      "Rule 4: scoring method\n",
      "\n",
      "\n",
      "\n",
      "It is clear that HWPM method works only if the initial low resolution model of the particle is already known .\n",
      "{4: 'HWPM method'}\n",
      "Rule 4: HWPM method\n",
      "\n",
      "\n",
      "\n",
      "It is clear that HWPM method works only if the initial low resolution model of the particle is already known .\n",
      "{2: 'initial low resolution model', 4: 'resolution model'}\n",
      "Rule 2: initial low resolution model\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Boden', 'lemma': 'boden', 'upos': 'NOUN', 'xpos': 'NN', 'head': 3, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=5', 'children': []}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 3, 'deprel': 'case', 'misc': 'start_char=6|end_char=8', 'children': []}\n",
      "{'id': 3, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'nsubj', 'misc': 'start_char=9|end_char=15', 'children': [1, 2]}\n",
      "{'id': 4, 'text': 'captures', 'lemma': 'capture', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=16|end_char=24', 'children': [3, 5, 11, 15, 24]}\n",
      "{'id': 5, 'text': 'flexibility', 'lemma': 'flexibility', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'obj', 'misc': 'start_char=25|end_char=36', 'children': [10]}\n",
      "{'id': 6, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 10, 'deprel': 'case', 'misc': 'start_char=37|end_char=39', 'children': []}\n",
      "{'id': 7, 'text': 'all', 'lemma': 'all', 'upos': 'DET', 'xpos': 'DT', 'head': 10, 'deprel': 'det', 'misc': 'start_char=40|end_char=43', 'children': []}\n",
      "{'id': 8, 'text': 'three', 'lemma': 'three', 'upos': 'NUM', 'xpos': 'CD', 'head': 10, 'deprel': 'nummod', 'misc': 'start_char=44|end_char=49', 'children': []}\n",
      "{'id': 9, 'text': 'flexible', 'lemma': 'flexible', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 10, 'deprel': 'amod', 'misc': 'start_char=50|end_char=58', 'children': []}\n",
      "{'id': 10, 'text': 'regions', 'lemma': 'region', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=59|end_char=66', 'children': [6, 7, 8, 9]}\n",
      "{'id': 11, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 4, 'deprel': 'punct', 'misc': 'start_char=67|end_char=68', 'children': []}\n",
      "{'id': 12, 'text': 'but', 'lemma': 'but', 'upos': 'CONJ', 'xpos': 'CC', 'head': 15, 'deprel': 'cc', 'misc': 'start_char=69|end_char=72', 'children': []}\n",
      "{'id': 13, 'text': 'it', 'lemma': 'it', 'upos': 'PRON', 'xpos': 'PRP', 'head': 15, 'deprel': 'nsubj', 'misc': 'start_char=73|end_char=75', 'children': []}\n",
      "{'id': 14, 'text': 'also', 'lemma': 'also', 'upos': 'ADV', 'xpos': 'RB', 'head': 15, 'deprel': 'advmod', 'misc': 'start_char=76|end_char=80', 'children': []}\n",
      "{'id': 15, 'text': 'predicts', 'lemma': 'predict', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 4, 'deprel': 'conj', 'misc': 'start_char=81|end_char=89', 'children': [12, 13, 14, 18, 23]}\n",
      "{'id': 16, 'text': 'over', 'lemma': 'over', 'upos': 'ADP', 'xpos': 'IN', 'head': 18, 'deprel': 'case', 'misc': 'start_char=90|end_char=94', 'children': []}\n",
      "{'id': 17, 'text': '50', 'lemma': '50', 'upos': 'NUM', 'xpos': 'CD', 'head': 18, 'deprel': 'nummod', 'misc': 'start_char=95|end_char=97', 'children': []}\n",
      "{'id': 18, 'text': '%', 'lemma': '%', 'upos': 'SYM', 'xpos': 'NN', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=98|end_char=99', 'children': [16, 17, 21]}\n",
      "{'id': 19, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 21, 'deprel': 'case', 'misc': 'start_char=100|end_char=102', 'children': []}\n",
      "{'id': 20, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 21, 'deprel': 'det', 'misc': 'start_char=103|end_char=107', 'children': []}\n",
      "{'id': 21, 'text': 'sequence', 'lemma': 'sequence', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'nmod', 'misc': 'start_char=108|end_char=116', 'children': [19, 20]}\n",
      "{'id': 22, 'text': 'as', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 23, 'deprel': 'case', 'misc': 'start_char=117|end_char=119', 'children': []}\n",
      "{'id': 23, 'text': 'flexible', 'lemma': 'flexible', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=120|end_char=128', 'children': [22]}\n",
      "{'id': 24, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 4, 'deprel': 'punct', 'misc': 'start_char=129|end_char=130', 'children': []}\n",
      "Boden 's method captures flexibility in all three flexible regions , but it also predicts over 50 % of this sequence as flexible .\n",
      "{5: \"Boden 's method\"}\n",
      "Rule 5: Boden 's method\n",
      "\n",
      "\n",
      "\n",
      "We use an optimised version of our recently published composite scoring function QMEAN in order to define an ensemble of reference models which is used to calculate the structural consensus score .\n",
      "{2: 'structural consensus score', 4: 'consensus score'}\n",
      "Rule 2: structural consensus score\n",
      "\n",
      "\n",
      "\n",
      "Here we present the Sparse Vector Autoregressive model to approach these problems .\n",
      "{2: 'Sparse Vector Autoregressive model', 4: 'Vector model'}\n",
      "Rule 2: Sparse Vector Autoregressive model\n",
      "\n",
      "\n",
      "\n",
      "A well known simulation algorithm due to Gillespie performs an exact simulation of the Chemical Master Equation for a well mixed system .\n",
      "{2: 'known simulation algorithm', 4: 'simulation algorithm'}\n",
      "Rule 2: known simulation algorithm\n",
      "\n",
      "\n",
      "\n",
      "To investigate the functional relationship between individual modules and stress response , we used the singular value decomposition method as developed by Alter et al. .\n",
      "{2: 'singular value decomposition method', 4: 'value decomposition method'}\n",
      "Rule 2: singular value decomposition method\n",
      "\n",
      "\n",
      "\n",
      "Instead of solving the master equation , a widely used method is to carry out Monte Carlo simulations using the Gillespie algorithm .\n",
      "{4: 'Gillespie algorithm'}\n",
      "Rule 4: Gillespie algorithm\n",
      "\n",
      "\n",
      "\n",
      "This exact reduced order modeling technique is used to generate a reduced model of EGF and insulin receptor crosstalk .\n",
      "{2: 'exact reduced order modeling technique', 4: 'order modeling technique'}\n",
      "Rule 2: exact reduced order modeling technique\n",
      "\n",
      "\n",
      "\n",
      "To gain further insight into the transcriptional response to the deletion of SDH3 , we integrated the transcriptome data with the genome-scale yeast metabolic model .\n",
      "{2: 'genome-scale yeast metabolic model', 4: 'yeast model'}\n",
      "Rule 2: genome-scale yeast metabolic model\n",
      "\n",
      "\n",
      "\n",
      "A modified FBA method with minimization of the 1-norm objective function between two optimal flux distributions was used to determine optimal intracellular fluxes based on the EM-constrained metabolic models .\n",
      "{2: 'modified FBA method', 4: 'FBA method'}\n",
      "Rule 2: modified FBA method\n",
      "\n",
      "\n",
      "\n",
      "For the objective of estimating the heritability of Addison 's disease in the Portuguese Water Dog , a threshold model for the liability to disease was used .\n",
      "{4: 'threshold model'}\n",
      "Rule 4: threshold model\n",
      "\n",
      "\n",
      "\n",
      "The Prionics-Check Western blot method for active monitoring of BSE in cattle was used for routine scrapie diagnosis on brain stem at the obex region .\n",
      "{2: 'Prionics-Check Western blot method', 4: 'Western blot method'}\n",
      "Rule 2: Prionics-Check Western blot method\n",
      "\n",
      "\n",
      "\n",
      "The MLVA method can be applied to S. uberis genotyping and constitutes an interesting complement to existing typing methods .\n",
      "{4: 'MLVA method'}\n",
      "Rule 4: MLVA method\n",
      "\n",
      "\n",
      "\n",
      "' Framework ' content analysis , an analytical process involving a number of distinct yet highly interconnected stages , was used to categorise themes for discussion .\n",
      "{4: 'Framework content analysis'}\n",
      "Rule 4: Framework content analysis\n",
      "\n",
      "\n",
      "\n",
      "The questionnaire technique proposed is a discrete choice experiment using best / worst scaling .\n",
      "{4: 'questionnaire technique'}\n",
      "Rule 4: questionnaire technique\n",
      "\n",
      "\n",
      "\n",
      "This study used discriminant function analysis , a relatively uncommon method of defining cognitive phenotype .\n",
      "{2: 'discriminant function analysis', 4: 'function analysis'}\n",
      "Rule 2: discriminant function analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Erel', 'lemma': 'erel', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=4', 'children': []}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 5, 'deprel': 'case', 'misc': 'start_char=5|end_char=7', 'children': []}\n",
      "{'id': 3, 'text': 'ceruloplasmin', 'lemma': 'ceruloplasmin', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=8|end_char=21', 'children': []}\n",
      "{'id': 4, 'text': 'measurement', 'lemma': 'measurement', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=22|end_char=33', 'children': []}\n",
      "{'id': 5, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'nsubj:pass', 'misc': 'start_char=34|end_char=40', 'children': [1, 2, 3, 4]}\n",
      "{'id': 6, 'text': 'is', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBZ', 'head': 7, 'deprel': 'aux:pass', 'misc': 'start_char=41|end_char=43', 'children': []}\n",
      "{'id': 7, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=44|end_char=48', 'children': [5, 6, 8]}\n",
      "{'id': 8, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 7, 'deprel': 'punct', 'misc': 'start_char=49|end_char=50', 'children': []}\n",
      "Erel 's ceruloplasmin measurement method is used .\n",
      "{4: 'ceruloplasmin measurement method', 5: \"Erel 's ceruloplasmin measurement method\"}\n",
      "Rule 5: Erel 's ceruloplasmin measurement method\n",
      "\n",
      "\n",
      "\n",
      "The evolutionary trace analysis is developed by Olivier Lichtarge in 1996 .\n",
      "{2: 'evolutionary trace analysis', 4: 'trace analysis'}\n",
      "Rule 2: evolutionary trace analysis\n",
      "\n",
      "\n",
      "\n",
      "We utilized the nearest neighbour method to determine that AUF1 siRNA lead to a significant increase in CpG methylation .\n",
      "{2: 'nearest neighbour method', 4: 'neighbour method'}\n",
      "Rule 2: nearest neighbour method\n",
      "\n",
      "\n",
      "\n",
      "In our laboratory we have successfully utilized a semi-quantitative PCR method employing Aldolase A as an internal control in a number of systems and different types of samples .\n",
      "{2: 'semi-quantitative PCR method', 4: 'PCR method'}\n",
      "Rule 2: semi-quantitative PCR method\n",
      "\n",
      "\n",
      "\n",
      "We have established an immunocytochemical and image analysis method by which the intracellular levels of the enzyme PGHS-1 can be monitored throughout the differentiation of megakaryoblastic cells into platelet-like structures .\n",
      "{2: 'immunocytochemical and image analysis method', 4: 'analysis method'}\n",
      "Rule 2: immunocytochemical and image analysis method\n",
      "\n",
      "\n",
      "\n",
      "Primer extension analysis is routinely used for expression profiling .\n",
      "{4: 'Primer extension analysis'}\n",
      "Rule 4: Primer extension analysis\n",
      "\n",
      "\n",
      "\n",
      "We developed a puromycin-linker ligation method , using the Y-ligation .\n",
      "{2: 'puromycin-linker ligation method', 4: 'ligation method'}\n",
      "Rule 2: puromycin-linker ligation method\n",
      "\n",
      "\n",
      "\n",
      "The Y-ligation method is an easy process because any after-treatments such as removal of the splint DNA are not necessary .\n",
      "{4: 'Y-ligation method'}\n",
      "Rule 4: Y-ligation method\n",
      "\n",
      "\n",
      "\n",
      "To measure the effect of long term feeding of CLA on porcine muscle gene expression , a semi-quantitative RT-PCR method was developed using cDNA normalized against the housekeeping genes cyclophilin and β-actin .\n",
      "{2: 'semi-quantitative RT-PCR method', 4: 'RT-PCR method'}\n",
      "Rule 2: semi-quantitative RT-PCR method\n",
      "\n",
      "\n",
      "\n",
      "We have used FACS Analysis to measure Granzyme B release as a function of cell mediated cytotoxicity .\n",
      "{4: 'FACS Analysis'}\n",
      "Rule 4: FACS Analysis\n",
      "\n",
      "\n",
      "\n",
      "An automatic tracking algorithm was developed to reduce human error .\n",
      "{2: 'automatic tracking algorithm', 4: 'tracking algorithm'}\n",
      "Rule 2: automatic tracking algorithm\n",
      "\n",
      "\n",
      "\n",
      "The average time required to carry out the Lig-PCR method would be about 2-3 hours and can depend on the length and number of PCR cycles , followed by gel electrophoresis .\n",
      "{4: 'Lig-PCR method'}\n",
      "Rule 4: Lig-PCR method\n",
      "\n",
      "\n",
      "\n",
      "The first visualization method used was isosurface rendering , whereby biofilm biomass was illustrated as a hollow shell that corresponded to the interconnected boundary voxels of the fluorescent , 3D volume data set .\n",
      "{2: 'first visualization method', 4: 'visualization method'}\n",
      "Rule 2: first visualization method\n",
      "\n",
      "\n",
      "\n",
      "The MMPF analysis implemented the Hilbert-Huang transformation technique to measure the coupling between two nonstationary signals .\n",
      "{4: 'MMPF analysis'}\n",
      "Rule 4: MMPF analysis\n",
      "\n",
      "\n",
      "\n",
      "The MMPF analysis implemented the Hilbert-Huang transformation technique to measure the coupling between two nonstationary signals .\n",
      "{2: 'Hilbert-Huang transformation technique', 4: 'transformation technique'}\n",
      "Rule 2: Hilbert-Huang transformation technique\n",
      "\n",
      "\n",
      "\n",
      "The MMPF method provides high time and frequency resolution and permits construction of instantaneous phase diagrams on a beat-to-beat basis .\n",
      "{4: 'MMPF method'}\n",
      "Rule 4: MMPF method\n",
      "\n",
      "\n",
      "\n",
      "Here we show that a transport lattice approach can solve bioheat problems .\n",
      "{2: 'transport lattice approach', 4: 'transport approach'}\n",
      "Rule 2: transport lattice approach\n",
      "\n",
      "\n",
      "\n",
      "Here we show that the transport lattice approach can be used to model transport of heat by conduction and temperature-dependent blood perfusion .\n",
      "{2: 'transport lattice approach', 4: 'transport approach'}\n",
      "Rule 2: transport lattice approach\n",
      "\n",
      "\n",
      "\n",
      "The lumen boundaries were segmented automatically by the region growing method .\n",
      "{2: 'region growing method', 4: 'region method'}\n",
      "Rule 2: region growing method\n",
      "\n",
      "\n",
      "\n",
      "The first of these , the finite-difference time-domain method , is based on the Yee algorithm and uses finite difference approximations of the time and space derivatives of Maxwell 's curl equations to create a discrete three-dimensional representation of the electric and magnetic fields .\n",
      "{4: 'Yee algorithm'}\n",
      "Rule 4: Yee algorithm\n",
      "\n",
      "\n",
      "\n",
      "Modeling of ultrasound wave propagation in inhomogeneous three-dimensional structure or medium over large length scales has become feasible using the k-space computational method .\n",
      "{2: 'k-space computational method', 4: 'k-space method'}\n",
      "Rule 2: k-space computational method\n",
      "\n",
      "\n",
      "\n",
      "The 3D aneurysm model was then reconstructed using a CAD program and subsequently imported into a commercial finite element software for mesh generation and stress analysis .\n",
      "{4: '3D aneurysm model'}\n",
      "Rule 4: 3D aneurysm model\n",
      "\n",
      "\n",
      "\n",
      "The 3D aneurysm model was then reconstructed using a CAD program and subsequently imported into a commercial finite element software for mesh generation and stress analysis .\n",
      "{4: 'stress analysis'}\n",
      "Rule 4: stress analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Then', 'lemma': 'then', 'upos': 'ADV', 'xpos': 'RB', 'head': 10, 'deprel': 'advmod', 'misc': 'start_char=0|end_char=4', 'children': []}\n",
      "{'id': 2, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 10, 'deprel': 'punct', 'misc': 'start_char=5|end_char=6', 'children': []}\n",
      "{'id': 3, 'text': 'Lobregt', 'lemma': 'lobregt', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'nmod:poss', 'misc': 'start_char=7|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 8, 'deprel': 'case', 'misc': 'start_char=15|end_char=17', 'children': []}\n",
      "{'id': 5, 'text': 'discrete', 'lemma': 'discrete', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 8, 'deprel': 'amod', 'misc': 'start_char=18|end_char=26', 'children': []}\n",
      "{'id': 6, 'text': 'dynamic', 'lemma': 'dynamic', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 8, 'deprel': 'amod', 'misc': 'start_char=27|end_char=34', 'children': []}\n",
      "{'id': 7, 'text': 'contour', 'lemma': 'contour', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'compound', 'misc': 'start_char=35|end_char=42', 'children': []}\n",
      "{'id': 8, 'text': 'model', 'lemma': 'model', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'nsubj:pass', 'misc': 'start_char=43|end_char=48', 'children': [3, 4, 5, 6, 7]}\n",
      "{'id': 9, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 10, 'deprel': 'aux:pass', 'misc': 'start_char=49|end_char=52', 'children': []}\n",
      "{'id': 10, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=53|end_char=57', 'children': [1, 2, 8, 9, 12, 15]}\n",
      "{'id': 11, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 12, 'deprel': 'mark', 'misc': 'start_char=58|end_char=60', 'children': []}\n",
      "{'id': 12, 'text': 'refine', 'lemma': 'refine', 'upos': 'VERB', 'xpos': 'VB', 'head': 10, 'deprel': 'xcomp', 'misc': 'start_char=61|end_char=67', 'children': [11, 14]}\n",
      "{'id': 13, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 14, 'deprel': 'det', 'misc': 'start_char=68|end_char=71', 'children': []}\n",
      "{'id': 14, 'text': 'boundary', 'lemma': 'boundary', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=72|end_char=80', 'children': [13]}\n",
      "{'id': 15, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 10, 'deprel': 'punct', 'misc': 'start_char=81|end_char=82', 'children': []}\n",
      "Then , Lobregt 's discrete dynamic contour model was used to refine the boundary .\n",
      "{2: 'discrete dynamic contour model', 4: 'contour model', 5: \"Lobregt 's discrete dynamic contour model\"}\n",
      "Rule 5: Lobregt 's discrete dynamic contour model\n",
      "\n",
      "\n",
      "\n",
      "MurmurS1S2HESSTFTHESSTFTHESSTFTHalf-bandwidth HB , Hz2010136802884Low frequency LF , Hz800320480High frequency HF , Hz120201104161105169Tovar-Corona et al. described similarly appearing contour graphs obtained using the continuous wavelet based method .\n",
      "{2: 'continuous wavelet based method', 4: 'wavelet method'}\n",
      "Rule 2: continuous wavelet based method\n",
      "\n",
      "\n",
      "\n",
      "In order to specify the number of rules in fuzzy system we utilize subtractive clustering approach .\n",
      "{2: 'subtractive clustering approach', 4: 'clustering approach'}\n",
      "Rule 2: subtractive clustering approach\n",
      "\n",
      "\n",
      "\n",
      "In , a multi-resolution wavelet analysis of SEP was proposed and it decomposed the signals into a series of coarse and detailed t-f components with the help of scaling and wavelet functions .\n",
      "{2: 'multi-resolution wavelet analysis', 4: 'wavelet analysis'}\n",
      "Rule 2: multi-resolution wavelet analysis\n",
      "\n",
      "\n",
      "\n",
      "In addition , HRV power spectral analysis lightens the burden imposed on subjects during an experiment , unlike invasive measurements , i.e. , plasma catecholamine concentration and muscle sympathetic nerve activity .\n",
      "{2: 'HRV power spectral analysis', 4: 'HRV power analysis'}\n",
      "Rule 2: HRV power spectral analysis\n",
      "\n",
      "\n",
      "\n",
      "We assessed genome-wide changes in methylation patterns using a unique methylation profiling technique called amplification of intermethylated sites .\n",
      "{2: 'unique methylation profiling technique', 4: 'methylation profiling technique'}\n",
      "Rule 2: unique methylation profiling technique\n",
      "\n",
      "\n",
      "\n",
      "To perform a comparative SAGE analysis of normal , preinvasive and invasive lesions , we used a modified t test that we have recently developed .\n",
      "{2: 'comparative SAGE analysis', 4: 'SAGE analysis'}\n",
      "Rule 2: comparative SAGE analysis\n",
      "\n",
      "\n",
      "\n",
      "To perform a comparative SAGE analysis of normal , preinvasive and invasive lesions , we used a modified t test that we have recently developed .\n",
      "{2: 'modified t test', 4: 't test'}\n",
      "Rule 2: modified t test\n",
      "\n",
      "\n",
      "\n",
      "The intracardiac injection model is used to generate widespread arterial dissemination of tumor cells by bypassing the lungs in order to seed cells to various organs .\n",
      "{2: 'intracardiac injection model', 4: 'injection model'}\n",
      "Rule 2: intracardiac injection model\n",
      "\n",
      "\n",
      "\n",
      "To address common difficulties associated with the AI analysis of primary tumors , we have recently developed a technique called ' counting alleles ' that is specifically designed for the analysis of archived clinical specimens .\n",
      "{4: 'AI analysis'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 4: AI analysis\n",
      "\n",
      "\n",
      "\n",
      "The echocardiographic quantification method recommended by the European Society of Cardiology is the biplane method of discs .\n",
      "{2: 'echocardiographic quantification method', 4: 'quantification method'}\n",
      "Rule 2: echocardiographic quantification method\n",
      "\n",
      "\n",
      "\n",
      "Several residues throughout the polypeptide chain have been postulated as Akt1 targets , based mainly on deletion and mutation analysis using purified proteins and commercial recombinant Akt1 .\n",
      "{4: 'deletion analysis'}\n",
      "Rule 4: deletion analysis\n",
      "\n",
      "\n",
      "\n",
      "Cerebrum samples were also taken for capillary depletion analysis by dextran density centrifugation as previously reported .\n",
      "{2: 'capillary depletion analysis', 4: 'depletion analysis'}\n",
      "Rule 2: capillary depletion analysis\n",
      "\n",
      "\n",
      "\n",
      "Knook and his group in Leiden developed the cell separation method of stellate cells .\n",
      "{4: 'cell separation method'}\n",
      "Rule 4: cell separation method\n",
      "\n",
      "\n",
      "\n",
      "The most prevalent top-down costing approach is the ratio of cost to charge method .\n",
      "{4: 'charge method'}\n",
      "Rule 4: charge method\n",
      "\n",
      "\n",
      "\n",
      "Consequently , the user may choose to use another allocation algorithm such as the reciprocal allocation method .\n",
      "{4: 'allocation algorithm'}\n",
      "Rule 4: allocation algorithm\n",
      "\n",
      "\n",
      "\n",
      "Costs from productivity loss at paid work were calculated according to the friction cost method .\n",
      "{4: 'friction cost method'}\n",
      "Rule 4: friction cost method\n",
      "\n",
      "\n",
      "\n",
      "The aim of this report is to describe our research method for detecting delirium in the ICU .\n",
      "{4: 'research method'}\n",
      "Rule 4: research method\n",
      "\n",
      "\n",
      "\n",
      "We present a useful research algorithm for detecting delirium in an ICU setting .\n",
      "{2: 'useful research algorithm', 4: 'research algorithm'}\n",
      "Rule 2: useful research algorithm\n",
      "\n",
      "\n",
      "\n",
      "We measured beat-to-beat blood pressure by a finger plethysmographic method , which is calibrated by the oscillometric measurement of blood pressure .\n",
      "{2: 'finger plethysmographic method', 4: 'finger method'}\n",
      "Rule 2: finger plethysmographic method\n",
      "\n",
      "\n",
      "\n",
      "More than one virus was detected in one third of the patients , but only by using the RT-PCR technique .\n",
      "{4: 'RT-PCR technique'}\n",
      "Rule 4: RT-PCR technique\n",
      "\n",
      "\n",
      "\n",
      "To our knowledge , this study is the first to measure FRC by using the automated procedure available on the Engstrom Care Station ventilator in a porcine model of ARDS .\n",
      "{4: 'porcine model'}\n",
      "Rule 4: porcine model\n",
      "\n",
      "\n",
      "\n",
      "For RNA quantification , 2.5 ml whole blood was collected using blood RNA tubes and stored at -80°C until extraction .\n",
      "{4: 'RNA quantification'}\n",
      "Rule 4: RNA quantification\n",
      "\n",
      "\n",
      "\n",
      "Given the significant mortality associated with repair of congenital abdominal wall defects , pediatric surgeons developed the prosthetic silo technique for gradual reduction of abdominal viscera .\n",
      "{2: 'prosthetic silo technique', 4: 'silo technique'}\n",
      "Rule 2: prosthetic silo technique\n",
      "\n",
      "\n",
      "\n",
      "An alternative bedside technique has been described in which intragastric pressure measurements are taken from an indwelling nasogastric tube .\n",
      "{2: 'alternative bedside technique', 4: 'bedside technique'}\n",
      "Rule 2: alternative bedside technique\n",
      "\n",
      "\n",
      "\n",
      "The easiest way to obtain a complete inspiratory V-P curve during one slow insufflation and without disconnecting the patient from the ventilator is to use the low flow inflation technique .\n",
      "{2: 'low flow inflation technique', 4: 'flow inflation technique'}\n",
      "Rule 2: low flow inflation technique\n",
      "\n",
      "\n",
      "\n",
      "According to the multiple pressure-volume curve technique discussed earlier , this ventilator is the first to directly assess PEEP-related recruitment by simply calculating the volume difference between the first point of the PEEP pressure-volume curve and the volume read on the zero end-expiratory pressure-volume curve at the corresponding pressure .\n",
      "{2: 'multiple pressure-volume curve technique', 4: 'curve technique'}\n",
      "Rule 2: multiple pressure-volume curve technique\n",
      "\n",
      "\n",
      "\n",
      "This new interest has led to a renovation of the quantitative assessment of physiological acid-base balance , with increasing use of the Stewart model to calculate acid-base balance in the critically ill .\n",
      "{4: 'Stewart model'}\n",
      "Rule 4: Stewart model\n",
      "\n",
      "\n",
      "\n",
      "Exercise capacity , assessed by a symptom-limited treadmill exercise stress test with continuous 12-lead ECG monitoring , is reported as the maximal metabolic equivalents attained during the test .\n",
      "{2: 'symptom-limited treadmill exercise stress test', 4: 'treadmill exercise stress test'}\n",
      "Rule 2: symptom-limited treadmill exercise stress test\n",
      "\n",
      "\n",
      "\n",
      "The International Consensus Endpoints take into account both pain score and analgesic consumption24 .\n",
      "{4: 'pain score'}\n",
      "Rule 4: pain score\n",
      "\n",
      "\n",
      "\n",
      "During the last several years , there has been a surge in liquid-based cytology slide preparation such as Thin-Prep monolayer slide method in non-gyn cytology specimens .\n",
      "{2: 'liquid-based cytology slide preparation', 4: 'cytology slide preparation'}\n",
      "Rule 2: liquid-based cytology slide preparation\n",
      "\n",
      "\n",
      "\n",
      "Body composition was assessed by impedance using a standard bioimpedance technique according to the manufacturer’s instructions .\n",
      "{2: 'standard bioimpedance technique', 4: 'bioimpedance technique'}\n",
      "Rule 2: standard bioimpedance technique\n",
      "\n",
      "\n",
      "\n",
      "The computer simulation technique has been developed by Smith in late 80s at Stanford University .\n",
      "{4: 'computer simulation technique'}\n",
      "Rule 4: computer simulation technique\n",
      "\n",
      "\n",
      "\n",
      "The modeling of wave propagation in cylindrical tubes may be easily performed using the waveguide method , as described further on in this paper .\n",
      "{4: 'waveguide method'}\n",
      "Rule 4: waveguide method\n",
      "\n",
      "\n",
      "\n",
      "Thus , this study demonstrated that immediate blood flow responses after a modified tilt table test are attainable .\n",
      "{2: 'modified tilt table test', 4: 'tilt table test'}\n",
      "Rule 2: modified tilt table test\n",
      "\n",
      "\n",
      "\n",
      "We introduce a novel blood flow measurement method for non-invasive and continuous regional blood flow monitoring through the NIRS signal .\n",
      "{2: 'novel blood flow measurement method', 4: 'blood flow measurement method'}\n",
      "Rule 2: novel blood flow measurement method\n",
      "\n",
      "\n",
      "\n",
      "J. Bailey also formed a framework using a chain binomial model , which is useful for household transmission data .\n",
      "{2: 'chain binomial model', 4: 'chain model'}\n",
      "Rule 2: chain binomial model\n",
      "\n",
      "\n",
      "\n",
      "Spatial clustering not apparent in administrative areas was evaluated using a scan statistic .\n",
      "{4: 'scan statistic'}\n",
      "Rule 4: scan statistic\n",
      "\n",
      "\n",
      "\n",
      "Instead , a weighted least squares estimation method suggested by Muthén may be used .\n",
      "{2: 'weighted least squares estimation method', 4: 'squares estimation method'}\n",
      "Rule 2: weighted least squares estimation method\n",
      "\n",
      "\n",
      "\n",
      "We have refined and modified the original biomarker method by i ) introducing solid-phase extraction of the serum sample with a newly developed SPE-polymeric sorbent that exhibits both hydrophilic and lipophilic retention characteristics , thereby ensuring extraction of a wider range of compounds according to polarity , ii ) using a modified high-performance liquid chromatography gradient that covers the mid-polar area for collection of the early lipophilic fraction before elution of endogenous estrogens , oral contraceptives and metabolites , and iii ) applying a modified E-Screen bioassay that requires smaller amounts of serum extract and exhibits an increased ability to detect low-potency estrogenic compounds .\n",
      "{2: 'original biomarker method', 4: 'biomarker method'}\n",
      "Rule 2: original biomarker method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'This', 'lemma': 'this', 'upos': 'PRON', 'xpos': 'DT', 'head': 3, 'deprel': 'nsubj:pass', 'misc': 'start_char=0|end_char=4', 'children': []}\n",
      "{'id': 2, 'text': 'is', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBZ', 'head': 3, 'deprel': 'aux:pass', 'misc': 'start_char=5|end_char=7', 'children': []}\n",
      "{'id': 3, 'text': 'computed', 'lemma': 'compute', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=8|end_char=16', 'children': [1, 2, 4, 27]}\n",
      "{'id': 4, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 3, 'deprel': 'xcomp', 'misc': 'start_char=17|end_char=22', 'children': [10, 12]}\n",
      "{'id': 5, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 10, 'deprel': 'det', 'misc': 'start_char=23|end_char=24', 'children': []}\n",
      "{'id': 6, 'text': 'one-step', 'lemma': 'one-step', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 10, 'deprel': 'amod', 'misc': 'start_char=25|end_char=33', 'children': []}\n",
      "{'id': 7, 'text': 'Tukey', 'lemma': 'tukey', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'nmod:poss', 'misc': 'start_char=34|end_char=39', 'children': [8]}\n",
      "{'id': 8, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 7, 'deprel': 'case', 'misc': 'start_char=40|end_char=42', 'children': []}\n",
      "{'id': 9, 'text': 'Biweight', 'lemma': 'biweight', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'compound', 'misc': 'start_char=43|end_char=51', 'children': []}\n",
      "{'id': 10, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'obj', 'misc': 'start_char=52|end_char=58', 'children': [5, 6, 7, 9]}\n",
      "{'id': 11, 'text': 'by', 'lemma': 'by', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 12, 'deprel': 'mark', 'misc': 'start_char=59|end_char=61', 'children': []}\n",
      "{'id': 12, 'text': 'taking', 'lemma': 'take', 'upos': 'VERB', 'xpos': 'VBG', 'head': 4, 'deprel': 'advcl', 'misc': 'start_char=62|end_char=68', 'children': [11, 14]}\n",
      "{'id': 13, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 14, 'deprel': 'det', 'misc': 'start_char=69|end_char=70', 'children': []}\n",
      "{'id': 14, 'text': 'mean', 'lemma': 'mean', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=71|end_char=75', 'children': [13, 18]}\n",
      "{'id': 15, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 18, 'deprel': 'case', 'misc': 'start_char=76|end_char=78', 'children': []}\n",
      "{'id': 16, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 18, 'deprel': 'det', 'misc': 'start_char=79|end_char=82', 'children': []}\n",
      "{'id': 17, 'text': 'log', 'lemma': 'log', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'compound', 'misc': 'start_char=83|end_char=86', 'children': []}\n",
      "{'id': 18, 'text': 'ratios', 'lemma': 'ratio', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 14, 'deprel': 'nmod', 'misc': 'start_char=87|end_char=93', 'children': [15, 16, 17, 22]}\n",
      "{'id': 19, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 22, 'deprel': 'case', 'misc': 'start_char=94|end_char=96', 'children': []}\n",
      "{'id': 20, 'text': 'probe', 'lemma': 'probe', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'compound', 'misc': 'start_char=97|end_char=102', 'children': []}\n",
      "{'id': 21, 'text': 'pair', 'lemma': 'pair', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'compound', 'misc': 'start_char=103|end_char=107', 'children': []}\n",
      "{'id': 22, 'text': 'intensities', 'lemma': 'intensity', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 18, 'deprel': 'nmod', 'misc': 'start_char=108|end_char=119', 'children': [19, 20, 21, 26]}\n",
      "{'id': 23, 'text': 'across', 'lemma': 'across', 'upos': 'ADP', 'xpos': 'IN', 'head': 26, 'deprel': 'case', 'misc': 'start_char=120|end_char=126', 'children': []}\n",
      "{'id': 24, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 26, 'deprel': 'det', 'misc': 'start_char=127|end_char=130', 'children': []}\n",
      "{'id': 25, 'text': 'two', 'lemma': 'two', 'upos': 'NUM', 'xpos': 'CD', 'head': 26, 'deprel': 'nummod', 'misc': 'start_char=131|end_char=134', 'children': []}\n",
      "{'id': 26, 'text': 'arrays', 'lemma': 'array', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'nmod', 'misc': 'start_char=135|end_char=141', 'children': [23, 24, 25]}\n",
      "{'id': 27, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=142|end_char=143', 'children': []}\n",
      "This is computed using a one-step Tukey 's Biweight method by taking a mean of the log ratios of probe pair intensities across the two arrays .\n",
      "{2: \"one-step Tukey 's Biweight method\", 4: 'Biweight method', 5: \"Tukey 's Biweight method\"}\n",
      "Rule 2: one-step Tukey 's Biweight method\n",
      "\n",
      "\n",
      "\n",
      "The QALY approach attempts to account for the quality of life lost by adjusting for time \" lost \" from disease or death .\n",
      "{4: 'QALY approach'}\n",
      "Rule 4: QALY approach\n",
      "\n",
      "\n",
      "\n",
      "According to an established morphometric method , we evaluated dendritic length and the degree of dendritic complexity using the Sholl analysis .\n",
      "{4: 'Sholl analysis'}\n",
      "Rule 4: Sholl analysis\n",
      "\n",
      "\n",
      "\n",
      "In this article , we present an entirely new approach to this problem , namely , the application of Ki-energy , which can be enhanced through the practice of the Nishino Breathing Method .\n",
      "{4: 'Nishino Breathing Method'}\n",
      "Rule 4: Nishino Breathing Method\n",
      "\n",
      "\n",
      "\n",
      "First , a canonical correspondence analysis was performed using CANOCO 4.0 .\n",
      "{2: 'canonical correspondence analysis', 4: 'correspondence analysis'}\n",
      "Rule 2: canonical correspondence analysis\n",
      "\n",
      "\n",
      "\n",
      "Geometric morphometric methods of capturing information about curves or outlines of organismal structures may be used in conjunction with canonical variates analysis to assign specimens to groups or populations based on their shapes .\n",
      "{2: 'canonical variates analysis', 4: 'variates analysis'}\n",
      "Rule 2: canonical variates analysis\n",
      "\n",
      "\n",
      "\n",
      "As a first step towards understanding the immune defense reactions of both model organisms we used the suppression subtractive hybridization technique .\n",
      "{2: 'suppression subtractive hybridization technique', 4: 'suppression subtractive hybridization technique'}\n",
      "Rule 2: suppression subtractive hybridization technique\n",
      "\n",
      "\n",
      "\n",
      "To assess estimates of the present effective population size , we applied the linkage disequilibrium method proposed by Hill to account for a bias correction when sample size is much smaller than effective population size .\n",
      "{4: 'linkage disequilibrium method'}\n",
      "Rule 4: linkage disequilibrium method\n",
      "\n",
      "\n",
      "\n",
      "Another transfection method , electroporation , is an experimental technique involving the application of brief electric pulses to cells or tissues in order to increase cellular permeability to macromolecules .\n",
      "{4: 'transfection method'}\n",
      "Rule 4: transfection method\n",
      "\n",
      "\n",
      "\n",
      "The filtered data sets for the gene expression experiments were analyzed using rank products analysis via the RankProd package in R .\n",
      "{4: 'rank products analysis'}\n",
      "Rule 4: rank products analysis\n",
      "\n",
      "\n",
      "\n",
      "We propose a new clustering method for analysis of the repeat data captured in suffix trees .\n",
      "{2: 'new clustering method', 4: 'clustering method'}\n",
      "Rule 2: new clustering method\n",
      "\n",
      "\n",
      "\n",
      "Secondary-structure predictions were performed with the consensus method of the Jpred2 server .\n",
      "{4: 'consensus method'}\n",
      "Rule 4: consensus method\n",
      "\n",
      "\n",
      "\n",
      "A direct significance analysis to select genes from microarray data was proposed by Tusher et al. .\n",
      "{2: 'direct significance analysis', 4: 'significance analysis'}\n",
      "Rule 2: direct significance analysis\n",
      "\n",
      "\n",
      "\n",
      "Of the 169 cDNA elements , 161 met with the minimal requirements of the cluster program and were subjected to hierarchical cluster analysis .\n",
      "{2: 'hierarchical cluster analysis', 4: 'cluster analysis'}\n",
      "Rule 2: hierarchical cluster analysis\n",
      "\n",
      "\n",
      "\n",
      "A partitioning method is applied to bootstrap learning sets and the resulting partitions are combined by performing hierarchical clustering of the cluster centers .\n",
      "{4: 'partitioning method'}\n",
      "Rule 4: partitioning method\n",
      "\n",
      "\n",
      "\n",
      "Correction for multiple testing involved control of the proportion of false positives using an FDR method .\n",
      "{4: 'FDR method'}\n",
      "Rule 4: FDR method\n",
      "\n",
      "\n",
      "\n",
      "If we assume the profile depicted in Figure 5a represents the profile for true operon members in M. tuberculosis , we infer that functional linkages based on the Operon method at a distance of 50 bp may have a coverage of more than 80 % , while functional linkages established at the 100 bp cutoff may allow inclusion of more than 90 % of true operon pairs .\n",
      "{4: 'Operon method'}\n",
      "Rule 4: Operon method\n",
      "\n",
      "\n",
      "\n",
      "We have developed a DNA microarray-based method for measuring transcript length on a genomic scale .\n",
      "{2: 'DNA microarray-based method', 4: 'DNA method'}\n",
      "Rule 2: DNA microarray-based method\n",
      "\n",
      "\n",
      "\n",
      "To validate the results , we performed some representative comparisons by studying the distribution of the ratio of bit score to the maximal bit score .\n",
      "{4: 'bit score'}\n",
      "Rule 4: bit score\n",
      "\n",
      "\n",
      "\n",
      "To validate the results , we performed some representative comparisons by studying the distribution of the ratio of bit score to the maximal bit score .\n",
      "{2: 'maximal bit score', 4: 'bit score'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 2: maximal bit score\n",
      "\n",
      "\n",
      "\n",
      "Concurrent with the textbook-based identification of terms was the continuing effort to expand the vocabulary using a research data-driven approach .\n",
      "{2: 'research data-driven approach', 4: 'research approach'}\n",
      "Rule 2: research data-driven approach\n",
      "\n",
      "\n",
      "\n",
      "To combine these diverse sources they adopt the so-called random forest technique , which uses a set of decision trees with random subsets of attributes .\n",
      "{2: 'so-called random forest technique', 4: 'forest technique'}\n",
      "Rule 2: so-called random forest technique\n",
      "\n",
      "\n",
      "\n",
      "A probe level model for analysis of GeneChip gene expression data is presented which identified more than 10,000 single-feature polymorphisms between two barley genotypes , with a high sensitivity .\n",
      "{4: 'probe level model'}\n",
      "Rule 4: probe level model\n",
      "\n",
      "\n",
      "\n",
      "To identify genes whose transcript levels varied between genetically identical individuals , we first used an ANOVA model with a conservative assessment of significance .\n",
      "{4: 'ANOVA model'}\n",
      "Rule 4: ANOVA model\n",
      "\n",
      "\n",
      "\n",
      "Shinya Matsumoto proposed a clustering method that allows the use of each of the triplicate datasets as a probability distribution function , thereby avoiding the step of pooling data points into a median or mean .\n",
      "{4: 'clustering method'}\n",
      "Rule 4: clustering method\n",
      "\n",
      "\n",
      "\n",
      "The strength of each factor is further supported by the order of appearance of the corresponding variable in a forward stepwise regression model .\n",
      "{2: 'forward stepwise regression model', 4: 'regression model'}\n",
      "Rule 2: forward stepwise regression model\n",
      "\n",
      "\n",
      "\n",
      "Finally , Sandelin and Wasserman used their own column comparison function within the context of a dynamic programming alignment approach to compare DNA motifs .\n",
      "{2: 'dynamic programming alignment approach', 4: 'programming alignment approach'}\n",
      "Rule 2: dynamic programming alignment approach\n",
      "\n",
      "\n",
      "\n",
      "Comparison of polysomal associated mRNA between developmental stages using microarray analysis provides an approach to a genomic-wide investigation of translation dynamics during development .\n",
      "{4: 'microarray analysis'}\n",
      "Rule 4: microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "Our methodology is based on the edge-betweenness clustering algorithm proposed by Newman and Girvan .\n",
      "{4: 'edge-betweenness clustering algorithm'}\n",
      "Rule 4: edge-betweenness clustering algorithm\n",
      "\n",
      "\n",
      "\n",
      "These filters consisted in identifying trees in which : the human seed protein has non-primate proteins as nearest phylogenetic neighbors ; such topology can not be explained simply by the loss of the orthologous sequences in the other primates or multiple losses in mammalian groups ; the partition suggesting the HGT is supported by a high posterior probability in the Bayesian analysis ; and that partition is also supported by ML analysis .\n",
      "{4: 'ML analysis'}\n",
      "Rule 4: ML analysis\n",
      "\n",
      "\n",
      "\n",
      "As a further check on the accuracy of the number of estimated gene duplicates on informative branches , I estimated the number of gene duplicates and gene losses using an unrelated likelihood method .\n",
      "{2: 'unrelated likelihood method', 4: 'likelihood method'}\n",
      "Rule 2: unrelated likelihood method\n",
      "\n",
      "\n",
      "\n",
      "The E-MAP method creates high-density genetic-interaction networks consisting of aggravating or alleviating edge types .\n",
      "{4: 'E-MAP method'}\n",
      "Rule 4: E-MAP method\n",
      "\n",
      "\n",
      "\n",
      "It changes functional annotation analysis from term- or gene-centric to biological module-centric .\n",
      "{2: 'functional annotation analysis', 4: 'annotation analysis'}\n",
      "Rule 2: functional annotation analysis\n",
      "\n",
      "\n",
      "\n",
      "Thus , the Tol2-mediated gene transfer method should be useful in studying the roles played by genes that are involved in late organogenesis in chicken .\n",
      "{2: 'Tol2-mediated gene transfer method', 4: 'gene transfer method'}\n",
      "Rule 2: Tol2-mediated gene transfer method\n",
      "\n",
      "\n",
      "\n",
      "The ' Markov chain discrimination ' method is our implementation of the ' PFRSampler ' algorithm of Grad et al. .\n",
      "{4: 'Markov chain method'}\n",
      "Rule 4: Markov chain method\n",
      "\n",
      "\n",
      "\n",
      "The ' Markov chain discrimination ' method is our implementation of the ' PFRSampler ' algorithm of Grad et al. .\n",
      "{4: 'PFRSampler algorithm'}\n",
      "Rule 4: PFRSampler algorithm\n",
      "\n",
      "\n",
      "\n",
      "Here , we report a computational approach based on a novel machine learning technique , which enabled the identification of genome-wide TFBSs .\n",
      "{2: 'novel machine learning technique', 4: 'machine learning technique'}\n",
      "Rule 2: novel machine learning technique\n",
      "\n",
      "\n",
      "\n",
      "Our machine learning technique significantly improved the overall recognition and , therefore , the identification of faithful HNF4α targets .\n",
      "{4: 'machine learning technique'}\n",
      "Rule 4: machine learning technique\n",
      "\n",
      "\n",
      "\n",
      "In order to assess the branching of chætognaths and to stress the usefulness of RP genes for phylogenomics , a RP dataset was assembled using the composite dataset approach .\n",
      "{2: 'composite dataset approach', 4: 'dataset approach'}\n",
      "Rule 2: composite dataset approach\n",
      "\n",
      "\n",
      "\n",
      "To rule out the possibility that this discrepancy is a computational artifact , we applied the transfrag method to our tiling array data also .\n",
      "{4: 'transfrag method'}\n",
      "Rule 4: transfrag method\n",
      "\n",
      "\n",
      "\n",
      "The second type of voltammetry method involves the breakdown of the actual complex in situ and is termed pseudovoltammetry , which is useful for metals that react at the electrode directly .\n",
      "{4: 'voltammetry method'}\n",
      "Rule 4: voltammetry method\n",
      "\n",
      "\n",
      "\n",
      "Compared to traditional methodologies , this procedure is far more successful at acquiring a narrow range of pyrite particles , as reflected in batch dissolution experiments and SEM analysis .\n",
      "{4: 'SEM analysis'}\n",
      "Rule 4: SEM analysis\n",
      "\n",
      "\n",
      "\n",
      "The interfacial stiffness was defined as the slope calculated from a linear regression analysis of the data between 0 , 5° and 3° .\n",
      "{2: 'linear regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: linear regression analysis\n",
      "\n",
      "\n",
      "\n",
      "First , the use of the propensity score method may be quite useful in reducing selection bias between self and proxy respondents in survey research .\n",
      "{4: 'propensity score method'}\n",
      "Rule 4: propensity score method\n",
      "\n",
      "\n",
      "\n",
      "The Heckman method was developed by an economist , James Heckman , to address problems of self-selection among women participating in the labor force .\n",
      "{4: 'Heckman method'}\n",
      "Rule 4: Heckman method\n",
      "\n",
      "\n",
      "\n",
      "The anchor-based approach we used estimates the change score at which the questionnaires discriminate best between improved and stable patients .\n",
      "{4: 'change score'}\n",
      "Rule 4: change score\n",
      "\n",
      "\n",
      "\n",
      "An econometric scaling method was used for the development of the EuroQol .\n",
      "{2: 'econometric scaling method', 4: 'scaling method'}\n",
      "Rule 2: econometric scaling method\n",
      "\n",
      "\n",
      "\n",
      "The path analysis used structural equation modeling where all 4 time-points were represented in all models tested .\n",
      "{4: 'path analysis'}\n",
      "Rule 4: path analysis\n",
      "\n",
      "\n",
      "\n",
      "Trained interviewers directly elicited utilities using the time trade-off method .\n",
      "{4: 'time trade-off method'}\n",
      "Rule 4: time trade-off method\n",
      "\n",
      "\n",
      "\n",
      "Qualitative content analysis elicits contextual meaning in context through the development of emerging themes .\n",
      "{2: 'Qualitative content analysis', 4: 'content analysis'}\n",
      "Rule 2: Qualitative content analysis\n",
      "\n",
      "\n",
      "\n",
      "Consequently , we conduct an alternative specification test described in .\n",
      "{2: 'alternative specification test', 4: 'specification test'}\n",
      "Rule 2: alternative specification test\n",
      "\n",
      "\n",
      "\n",
      "Two-step cluster analysis was used as an exploratory tool to determine subpopulations or clusters within the dataset .\n",
      "{2: 'Two-step cluster analysis', 4: 'cluster analysis'}\n",
      "Rule 2: Two-step cluster analysis\n",
      "\n",
      "\n",
      "\n",
      "Perez-Castellano et al reported a new mapping approach to help localize the atrial insertion of AcP by reproducing the atrial activation sequence during orthodromic tachycardia through atrial pacing at the mapping catheter .\n",
      "{2: 'new mapping approach', 4: 'mapping approach'}\n",
      "Rule 2: new mapping approach\n",
      "\n",
      "\n",
      "\n",
      "For the lactating woman , a short-term method of contraception that poses no halakhic problem is that of the lactational amenorrhea method .\n",
      "{2: 'lactational amenorrhea method', 4: 'amenorrhea method'}\n",
      "Rule 2: lactational amenorrhea method\n",
      "\n",
      "\n",
      "\n",
      "The validity of the Modified Baecke Questionnaire score was assessed among 21 elderly men and women using the doubly labeled water method as the reference criterion .\n",
      "{2: 'Modified Baecke Questionnaire score', 4: 'Baecke Questionnaire score'}\n",
      "Rule 2: Modified Baecke Questionnaire score\n",
      "\n",
      "\n",
      "\n",
      "The validity of the Modified Baecke Questionnaire score was assessed among 21 elderly men and women using the doubly labeled water method as the reference criterion .\n",
      "{2: 'labeled water method', 4: 'water method'}\n",
      "Rule 2: labeled water method\n",
      "\n",
      "\n",
      "\n",
      "Only individuals who were self-classified as not meeting current physical activity recommendations , by means of an adapted stage of exercise behavior change model , were invited to participate .\n",
      "{4: 'exercise behavior change model'}\n",
      "Rule 4: exercise behavior change model\n",
      "\n",
      "\n",
      "\n",
      "Positive selection cells were taken and incubated with FITC-labeled anti-CD4 antibody to determine positive yield by FACS analysis .\n",
      "{4: 'FACS analysis'}\n",
      "Rule 4: FACS analysis\n",
      "\n",
      "\n",
      "\n",
      "Absolute data analysis was performed using the Affymetrix Microarray Suite 5.0 software .\n",
      "{2: 'Absolute data analysis', 4: 'data analysis'}\n",
      "Rule 2: Absolute data analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Jenk', 'lemma': 'jenk', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=4', 'children': []}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 5, 'deprel': 'case', 'misc': 'start_char=5|end_char=7', 'children': []}\n",
      "{'id': 3, 'text': 'optimization', 'lemma': 'optimization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=8|end_char=20', 'children': []}\n",
      "{'id': 4, 'text': 'classification', 'lemma': 'classification', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=21|end_char=35', 'children': []}\n",
      "{'id': 5, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'nsubj:pass', 'misc': 'start_char=36|end_char=42', 'children': [1, 2, 3, 4]}\n",
      "{'id': 6, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 7, 'deprel': 'aux:pass', 'misc': 'start_char=43|end_char=46', 'children': []}\n",
      "{'id': 7, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=47|end_char=51', 'children': [5, 6, 9, 19]}\n",
      "{'id': 8, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 9, 'deprel': 'mark', 'misc': 'start_char=52|end_char=54', 'children': []}\n",
      "{'id': 9, 'text': 'determine', 'lemma': 'determine', 'upos': 'VERB', 'xpos': 'VB', 'head': 7, 'deprel': 'xcomp', 'misc': 'start_char=55|end_char=64', 'children': [8, 12]}\n",
      "{'id': 10, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 12, 'deprel': 'det', 'misc': 'start_char=65|end_char=68', 'children': []}\n",
      "{'id': 11, 'text': 'critical', 'lemma': 'critical', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 12, 'deprel': 'amod', 'misc': 'start_char=69|end_char=77', 'children': []}\n",
      "{'id': 12, 'text': 'intervals', 'lemma': 'interval', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 9, 'deprel': 'obj', 'misc': 'start_char=78|end_char=87', 'children': [10, 11, 15]}\n",
      "{'id': 13, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 15, 'deprel': 'case', 'misc': 'start_char=88|end_char=91', 'children': []}\n",
      "{'id': 14, 'text': 'livestock', 'lemma': 'livestock', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'compound', 'misc': 'start_char=92|end_char=101', 'children': []}\n",
      "{'id': 15, 'text': 'density', 'lemma': 'density', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'nmod', 'misc': 'start_char=102|end_char=109', 'children': [13, 14, 18]}\n",
      "{'id': 16, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 18, 'deprel': 'cc', 'misc': 'start_char=110|end_char=113', 'children': []}\n",
      "{'id': 17, 'text': 'manure-use', 'lemma': 'manure-use', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 18, 'deprel': 'amod', 'misc': 'start_char=114|end_char=124', 'children': []}\n",
      "{'id': 18, 'text': 'maps', 'lemma': 'map', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'conj', 'misc': 'start_char=125|end_char=129', 'children': [16, 17]}\n",
      "{'id': 19, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 7, 'deprel': 'punct', 'misc': 'start_char=130|end_char=131', 'children': []}\n",
      "Jenk 's optimization classification method was used to determine the critical intervals for livestock density and manure-use maps .\n",
      "{4: 'optimization classification method', 5: \"Jenk 's optimization classification method\"}\n",
      "Rule 5: Jenk 's optimization classification method\n",
      "\n",
      "\n",
      "\n",
      "The Spatial filtering methodology employs non-parametric statistical techniques as a tool in exploratory spatial data analysis .\n",
      "{2: 'exploratory spatial data analysis', 4: 'data analysis'}\n",
      "Rule 2: exploratory spatial data analysis\n",
      "\n",
      "\n",
      "\n",
      "In order to explore the geographic patterns of our two outcomes of interest , we used the spatial scan statistic to detect and evaluate the statistical significance of any geographic clusters of each outcome .\n",
      "{2: 'spatial scan statistic', 4: 'scan statistic'}\n",
      "Rule 2: spatial scan statistic\n",
      "\n",
      "\n",
      "\n",
      "The multi-stage geocoding method used by the WA DOH is documented online .\n",
      "{2: 'multi-stage geocoding method', 4: 'geocoding method'}\n",
      "Rule 2: multi-stage geocoding method\n",
      "\n",
      "\n",
      "\n",
      "To generate the landslide susceptibility distribution map the standardized causal factor distribution maps were combined using the weighted linear combination method .\n",
      "{2: 'weighted linear combination method', 4: 'combination method'}\n",
      "Rule 2: weighted linear combination method\n",
      "\n",
      "\n",
      "\n",
      "The CIs followed the gamma distribution and were calculated following Fay-Feuer method for the upper limits and the Anderson-Rosemberg method recommended by NCHS for lower limits .\n",
      "{4: 'Fay-Feuer method'}\n",
      "Rule 4: Fay-Feuer method\n",
      "\n",
      "\n",
      "\n",
      "The most referred approach relies on the space-time scan statistic , which identifies the most significant cluster of a particular shape in space and time .\n",
      "{2: 'space-time scan statistic', 4: 'scan statistic'}\n",
      "Rule 2: space-time scan statistic\n",
      "\n",
      "\n",
      "\n",
      "In order to determine the reliability of the estimates provided by the prediction surface areas , a crossed validation method was used .\n",
      "{2: 'crossed validation method', 4: 'validation method'}\n",
      "Rule 2: crossed validation method\n",
      "\n",
      "\n",
      "\n",
      "Our model may also avoid a systematic underestimation of IMD score in less deprived areas , and a systematic overestimation of scores in more deprived areas , that was seen when using postcode-linked scores .\n",
      "{4: 'IMD score'}\n",
      "Rule 4: IMD score\n",
      "\n",
      "\n",
      "\n",
      "The Monte Carlo hypothesis method was used to test the statistical significance of possible clusters , and a p value was obtained by ranking the likelihood of an observed cluster in the dataset over the maximum likelihoods of 999 randomly-produced datasets .\n",
      "{4: 'Monte Carlo hypothesis method'}\n",
      "Rule 4: Monte Carlo hypothesis method\n",
      "\n",
      "\n",
      "\n",
      "These synthetic data were then brought to local scales using the SDSM method .\n",
      "{4: 'SDSM method'}\n",
      "Rule 4: SDSM method\n",
      "\n",
      "\n",
      "\n",
      "To detect the specific locations of either high rate or low rate clusters with a minimum of assumptions about cluster size , and to evaluate their statistical significance , we employed the spatial scan statistic proposed by Kulldorff .\n",
      "{2: 'spatial scan statistic', 4: 'scan statistic'}\n",
      "Rule 2: spatial scan statistic\n",
      "\n",
      "\n",
      "\n",
      "In order to summarize the MCM cases dataset composed of 34 annual values from 1966 to 1999 for each of the 8 West African countries under study and to compare the disease dynamics in these countries , we use the Correspondence Analysis .\n",
      "{4: 'Correspondence Analysis'}\n",
      "Rule 4: Correspondence Analysis\n",
      "\n",
      "\n",
      "\n",
      "The Knox method defines pairs of events as being either close or not close in time or space .\n",
      "{4: 'Knox method'}\n",
      "Rule 4: Knox method\n",
      "\n",
      "\n",
      "\n",
      "Kwan et al. use an interesting three dimensional geovisualization method to display movement across time and space .\n",
      "{2: 'interesting three dimensional geovisualization method', 4: 'geovisualization method'}\n",
      "Rule 2: interesting three dimensional geovisualization method\n",
      "\n",
      "\n",
      "\n",
      "SSS is based on the likelihood ratio test , and analyses have been available for count data using either a Poisson or Bernoulli model .\n",
      "{4: 'likelihood ratio test'}\n",
      "Rule 4: likelihood ratio test\n",
      "\n",
      "\n",
      "\n",
      "This grid was then converted into a statistical surface using the kernel density technique .\n",
      "{4: 'kernel density technique'}\n",
      "Rule 4: kernel density technique\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 10, 'deprel': 'advcl', 'misc': 'start_char=0|end_char=5', 'children': [4]}\n",
      "{'id': 2, 'text': 'Higuchi', 'lemma': 'higuchi', 'upos': 'NOUN', 'xpos': 'NN', 'head': 4, 'deprel': 'nmod:poss', 'misc': 'start_char=6|end_char=13', 'children': []}\n",
      "{'id': 3, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 4, 'deprel': 'case', 'misc': 'start_char=14|end_char=16', 'children': []}\n",
      "{'id': 4, 'text': 'algorithm', 'lemma': 'algorithm', 'upos': 'NOUN', 'xpos': 'NN', 'head': 1, 'deprel': 'obj', 'misc': 'start_char=17|end_char=26', 'children': [2, 3, 5]}\n",
      "{'id': 5, 'text': '7', 'lemma': '7', 'upos': 'NUM', 'xpos': 'CD', 'head': 4, 'deprel': 'nummod', 'misc': 'start_char=27|end_char=28', 'children': []}\n",
      "{'id': 6, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 8, 'deprel': 'det', 'misc': 'start_char=29|end_char=32', 'children': []}\n",
      "{'id': 7, 'text': 'fractal', 'lemma': 'fractal', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 8, 'deprel': 'amod', 'misc': 'start_char=33|end_char=40', 'children': []}\n",
      "{'id': 8, 'text': 'dimension', 'lemma': 'dimension', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'nsubj:pass', 'misc': 'start_char=41|end_char=50', 'children': [6, 7]}\n",
      "{'id': 9, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 10, 'deprel': 'aux:pass', 'misc': 'start_char=51|end_char=54', 'children': []}\n",
      "{'id': 10, 'text': 'calculated', 'lemma': 'calculate', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=55|end_char=65', 'children': [1, 8, 9, 11, 17]}\n",
      "{'id': 11, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 10, 'deprel': 'xcomp', 'misc': 'start_char=66|end_char=71', 'children': [14]}\n",
      "{'id': 12, 'text': 'custom', 'lemma': 'custom', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 14, 'deprel': 'amod', 'misc': 'start_char=72|end_char=78', 'children': []}\n",
      "{'id': 13, 'text': 'written', 'lemma': 'write', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 14, 'deprel': 'amod', 'misc': 'start_char=79|end_char=86', 'children': []}\n",
      "{'id': 14, 'text': 'software', 'lemma': 'software', 'upos': 'NOUN', 'xpos': 'NN', 'head': 11, 'deprel': 'obj', 'misc': 'start_char=87|end_char=95', 'children': [12, 13, 16]}\n",
      "{'id': 15, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 16, 'deprel': 'case', 'misc': 'start_char=96|end_char=98', 'children': []}\n",
      "{'id': 16, 'text': 'Matlab', 'lemma': 'matlab', 'upos': 'NOUN', 'xpos': 'NN', 'head': 14, 'deprel': 'nmod', 'misc': 'start_char=99|end_char=105', 'children': [15]}\n",
      "{'id': 17, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 10, 'deprel': 'punct', 'misc': 'start_char=106|end_char=107', 'children': []}\n",
      "Using Higuchi 's algorithm 7 the fractal dimension was calculated using custom written software in Matlab .\n",
      "{5: \"Higuchi 's algorithm\"}\n",
      "Rule 5: Higuchi 's algorithm\n",
      "\n",
      "\n",
      "\n",
      "Gene expression profiling using microarray technology allows the expression analysis of thousands of genes simultaneously 6-8 .\n",
      "{4: 'expression analysis'}\n",
      "Rule 4: expression analysis\n",
      "\n",
      "\n",
      "\n",
      "To address this issue , we developed an aqueous-based electrochemical deposition technique to fabricate vertically aligned standing nanostructures .\n",
      "{2: 'aqueous-based electrochemical deposition technique', 4: 'deposition technique'}\n",
      "Rule 2: aqueous-based electrochemical deposition technique\n",
      "\n",
      "\n",
      "\n",
      "After liposome preparation , reduced thiol groups of Fab or scFv fragments are joined via surface linkage to the maleimide group of the aforementioned PEG-liposome , obtaining a stable thioether bond .\n",
      "{4: 'liposome preparation'}\n",
      "Rule 4: liposome preparation\n",
      "\n",
      "\n",
      "\n",
      "This estimate of multiple copies of SSTR2 per exosomes was corroborated by a different quantization method using exosome-coated beads analyzed by FACS .\n",
      "{2: 'different quantization method', 4: 'quantization method'}\n",
      "Rule 2: different quantization method\n",
      "\n",
      "\n",
      "\n",
      "The Force Integration to Equal Limits mapping method can be used to produce a robust measurement of relative elasticity .\n",
      "{2: 'Equal Limits mapping method', 4: 'Limits mapping method'}\n",
      "Rule 2: Equal Limits mapping method\n",
      "\n",
      "\n",
      "\n",
      "Homogenous mutation assays based on two-color fluorescence coincidence analysis have also been reported .\n",
      "{2: 'two-color fluorescence coincidence analysis', 4: 'fluorescence coincidence analysis'}\n",
      "Rule 2: two-color fluorescence coincidence analysis\n",
      "\n",
      "\n",
      "\n",
      "The on-spot background correction method gave the greatest discrimination power , and was used for all subsequent distribution analyses .\n",
      "{2: 'on-spot background correction method', 4: 'background correction method'}\n",
      "Rule 2: on-spot background correction method\n",
      "\n",
      "\n",
      "\n",
      "Several methods for assessing promoter methylation status have been reported , but the most widely used is Methylation-Specific PCR analysis after bisulphite treatment .\n",
      "{2: 'Methylation-Specific PCR analysis', 4: 'PCR analysis'}\n",
      "Rule 2: Methylation-Specific PCR analysis\n",
      "\n",
      "\n",
      "\n",
      "Finally , to visualize the effect of a transition , the time series analysis was carried out using locally weighted regression , applying a decomposition procedure based on loess .\n",
      "{4: 'time series analysis'}\n",
      "Rule 4: time series analysis\n",
      "\n",
      "\n",
      "\n",
      "We used the constant comparative method20 , 21 of qualitative data analysis to develop and implement consistent and comprehensive coding of the open-ended data .\n",
      "{2: 'qualitative data analysis', 4: 'data analysis'}\n",
      "Rule 2: qualitative data analysis\n",
      "\n",
      "\n",
      "\n",
      "Stimson originally described his ' hanging arm ' technique for reducing shoulder dislocations .\n",
      "{2: 'hanging arm technique', 4: 'arm technique'}\n",
      "Rule 2: hanging arm technique\n",
      "\n",
      "\n",
      "\n",
      "The data were analyzed using qualitative methods of content analysis and constant comparison , derived from grounded theory approach .\n",
      "{4: 'content analysis'}\n",
      "Rule 4: content analysis\n",
      "\n",
      "\n",
      "\n",
      "The crystallization / immersion method was used to conduct a qualitative analysis using transcripts from the nine interviews .\n",
      "{4: 'crystallization / immersion method'}\n",
      "Rule 4: crystallization / immersion method\n",
      "\n",
      "\n",
      "\n",
      "The most popular bioconjugation technique involves the use of a zero-length crosslinker , 1-ethyl-3- carbodiimide hydrochloride , in the presence of a hydrophilic active group , N-hydroxysulfosuccinimide , for the formation of a stable amide bond between carboxylic acid-functionalized QDs and any biomolecules containing a primary amine .\n",
      "{2: 'popular bioconjugation technique', 4: 'bioconjugation technique'}\n",
      "Rule 2: popular bioconjugation technique\n",
      "\n",
      "\n",
      "\n",
      "Another method , which will reduce the number of ambiguities in the B locus , is the utilization of a two tube group amplification approach .\n",
      "{4: 'tube group amplification approach'}\n",
      "Rule 4: tube group amplification approach\n",
      "\n",
      "\n",
      "\n",
      "Exosomes secreted in the supernatant of MD-DC cultures were purified to 175 fold the starting volume according to a GMP method previously described .\n",
      "{4: 'GMP method'}\n",
      "Rule 4: GMP method\n",
      "\n",
      "\n",
      "\n",
      "For this purpose , we chose to apply the \" nearest shrunken centroid \" algorithm , as proposed by Tibshirani et al .\n",
      "{2: 'nearest shrunken centroid algorithm', 4: 'nearest shrunken centroid algorithm'}\n",
      "Rule 2: nearest shrunken centroid algorithm\n",
      "\n",
      "\n",
      "\n",
      "Ultramulti-color flowcytometer has been used to assess the frequency and the type of cytokine secretion of antigen-specific CD4+ and CD8+ T cell responses in non-human primates vaccinated with HIV gag conjugated to TLR agonists , or volunteers vaccinated against HIV using the \" Prime-Boost \" approach .\n",
      "{4: 'Prime-Boost approach'}\n",
      "Rule 4: Prime-Boost approach\n",
      "\n",
      "\n",
      "\n",
      "The advent of molecular biology tools , especially the PCR multiplex technique , opens new avenues of research : this method enables easy determination of sex , stage and physiological status using only a fragment of a mosquito morphologically assigned to An. gambiae s.l. .\n",
      "{2: 'PCR multiplex technique', 4: 'PCR technique'}\n",
      "Rule 2: PCR multiplex technique\n",
      "\n",
      "\n",
      "\n",
      "In this paper , a real-time PCR method is described which accurately ascertains parasite pfmdr 1 genotype .\n",
      "{2: 'real-time PCR method', 4: 'PCR method'}\n",
      "Rule 2: real-time PCR method\n",
      "\n",
      "\n",
      "\n",
      "A SSOP-ELISA method is described that allows simple , high-throughput detection of kdr SNPs in An. gambiae s.l .\n",
      "{4: 'SSOP-ELISA method'}\n",
      "Rule 4: SSOP-ELISA method\n",
      "\n",
      "\n",
      "\n",
      "Blood samples were immediately centrifuged and plasma stored in cryotubes at -70°C up to and including transport to Novartis Pharma in Paris , France , where plasma lumefantrine levels were determined blindly using a previously described high performance liquid chromatography method .\n",
      "{2: 'described high performance liquid chromatography method', 4: 'performance liquid chromatography method'}\n",
      "Rule 2: described high performance liquid chromatography method\n",
      "\n",
      "\n",
      "\n",
      "Use of biocontrol agents , source reduction of opportunistic breeding of vector mosquitoes , treatment , health education , environmental management , maintenance of cleanliness and personal hygiene are important components of bio-environmental control strategy .\n",
      "{2: 'bio-environmental control strategy', 4: 'control strategy'}\n",
      "Rule 2: bio-environmental control strategy\n",
      "\n",
      "\n",
      "\n",
      "After DNA extraction , the PCR-Sequence Specific Oligonucleotide Probing method was used for molecular genotyping of point mutations in the dihydrofolate reductase and dyhydropteroate synthetase genes .\n",
      "{2: 'PCR-Sequence Specific Oligonucleotide Probing method', 4: 'PCR-Sequence Specific Oligonucleotide Probing method'}\n",
      "Rule 2: PCR-Sequence Specific Oligonucleotide Probing method\n",
      "\n",
      "\n",
      "\n",
      "In nearly all of the studies reviewed , cause of death was ascertained by using the verbal autopsy method .\n",
      "{2: 'verbal autopsy method', 4: 'autopsy method'}\n",
      "Rule 2: verbal autopsy method\n",
      "\n",
      "\n",
      "\n",
      "While exploring a plausible mechanism of refractoriness based on nitric oxide synthase physiology among the sibling species of An. culicifacies , a sensitive , specific and cost effective high performance liquid chromatography method was developed , which is not influenced by the presence of biogenic amines , for the determination of NO2- and NO3- from mosquito mid-guts and haemolymph .\n",
      "{2: 'sensitive specific and cost effective high performance liquid chromatography method', 4: 'performance liquid chromatography method'}\n",
      "Rule 2: sensitive specific and cost effective high performance liquid chromatography method\n",
      "\n",
      "\n",
      "\n",
      "This anion HPLC method coupled with ultrafiltration to reduce protein and salt contaminants has not been used before to measure midgut and haemolymph , nitrite and nitrate concentrations in mosquitoes .\n",
      "{4: 'anion HPLC method'}\n",
      "Rule 4: anion HPLC method\n",
      "\n",
      "\n",
      "\n",
      "To identify interactions between P. falciparum and human proteins , a modified yeast two-hybrid approach was applied as described previously .\n",
      "{2: 'modified yeast two-hybrid approach', 4: 'yeast approach'}\n",
      "Rule 2: modified yeast two-hybrid approach\n",
      "\n",
      "\n",
      "\n",
      "Such slow growing clones can be identified sooner by using the PCR method and transferred to higher volume cultures before culture lysis .\n",
      "{4: 'PCR method'}\n",
      "Rule 4: PCR method\n",
      "\n",
      "\n",
      "\n",
      "The microarray method was used as described in Crameri et al .\n",
      "{4: 'microarray method'}\n",
      "Rule 4: microarray method\n",
      "\n",
      "\n",
      "\n",
      "Linear Discrimination Analysis was applied using the subset of genes selected from the previous step to assess whether the genes can discriminate the high from the low aggressive nature of the training and test samples .\n",
      "{2: 'Linear Discrimination Analysis', 4: 'Discrimination Analysis'}\n",
      "Rule 2: Linear Discrimination Analysis\n",
      "\n",
      "\n",
      "\n",
      "Prediction Analysis for Microarrays was carried out using the Excel version of the program .\n",
      "{4: 'Prediction Analysis'}\n",
      "Rule 4: Prediction Analysis\n",
      "\n",
      "\n",
      "\n",
      "This study utilized a novel stem-looped TaqMan RT-PCR method to measure the expression levels of 160 mature miRNAs in a collection of thyroid cell lines .\n",
      "{2: 'novel stem-looped TaqMan RT-PCR method', 4: 'TaqMan RT-PCR method'}\n",
      "Rule 2: novel stem-looped TaqMan RT-PCR method\n",
      "\n",
      "\n",
      "\n",
      "We utilized a novel stem-looped TaqMan RT-PCR method to quantify the expression profiles of 180 mature miRNAs in a collection of primary and recurrent serous papillary adenocarcinomas .\n",
      "{2: 'novel stem-looped TaqMan RT-PCR method', 4: 'TaqMan RT-PCR method'}\n",
      "Rule 2: novel stem-looped TaqMan RT-PCR method\n",
      "\n",
      "\n",
      "\n",
      "In the study presented here , we have focused on using information from identified compounds by developing and applying a new biochemical mapping method , PROFILE .\n",
      "{2: 'new biochemical mapping method', 4: 'mapping method'}\n",
      "Rule 2: new biochemical mapping method\n",
      "\n",
      "\n",
      "\n",
      "Since the classification error estimated in this way is susceptible to bias from over-fitting , cross validation using the 632+ bootstrapping method , as described by Davies et al , was used to estimate the error eB632+ .\n",
      "{4: 'bootstrapping method'}\n",
      "Rule 4: bootstrapping method\n",
      "\n",
      "\n",
      "\n",
      "We used the overlapping PCR method to construct the chimeras .\n",
      "{2: 'overlapping PCR method', 4: 'PCR method'}\n",
      "Rule 2: overlapping PCR method\n",
      "\n",
      "\n",
      "\n",
      "The QPCR genotyping method we report here facilitates accurate , rapid and effective genotyping of Wlds copy number in both spontaneous mutant mice and transgenic animals expressing Wlds , representing an improved , cost effective and more efficient general purpose method than PFGE , the most accurate alternative method reported thus far .\n",
      "{4: 'QPCR genotyping method'}\n",
      "Rule 4: QPCR genotyping method\n",
      "\n",
      "\n",
      "\n",
      "The QPCR genotyping method we report here facilitates accurate , rapid and effective genotyping of Wlds copy number in both spontaneous mutant mice and transgenic animals expressing Wlds , representing an improved , cost effective and more efficient general purpose method than PFGE , the most accurate alternative method reported thus far .\n",
      "{2: 'improved cost effective and more efficient general purpose method', 4: 'purpose method'}\n",
      "Rule 2: improved cost effective and more efficient general purpose method\n",
      "\n",
      "\n",
      "\n",
      "Two basic computational approaches were used to study the workings of such integrated models : rFBA —a method for simulating growth in batch cultures by predicting dynamic flux profiles in a changing environment .\n",
      "{4: 'rFBA —a method'}\n",
      "Rule 4: rFBA —a method\n",
      "\n",
      "\n",
      "\n",
      "The identification of consistent , steady-state metabolic and regulatory behaviors in a given , constant environment , using an extreme pathway analysis .\n",
      "{2: 'extreme pathway analysis', 4: 'pathway analysis'}\n",
      "Rule 2: extreme pathway analysis\n",
      "\n",
      "\n",
      "\n",
      "Furthermore , Washburn and colleagues have shown that the spectral counts quantitative method performed as well or better than stable isotope labeling-based quantitation methods when determining relative change calls .\n",
      "{2: 'spectral counts quantitative method', 4: 'counts method'}\n",
      "Rule 2: spectral counts quantitative method\n",
      "\n",
      "\n",
      "\n",
      "In conclusion , a computer-aided rational design approach was successfully applied to microbe engineering or breeding and verified by biological experiments .\n",
      "{2: 'computer-aided rational design approach', 4: 'design approach'}\n",
      "Rule 2: computer-aided rational design approach\n",
      "\n",
      "\n",
      "\n",
      "Here we describe a high-throughput quantitative , real-time , reverse-transcription PCR method for the measurement of both the relative level of expression of a particular transcript in a given tissue or cell type , and the relative change in expression of a particular transcript after pharmacologic or genotypic manipulation .\n",
      "{2: 'high-throughput quantitative real-time reverse-transcription PCR method', 4: 'PCR method'}\n",
      "Rule 2: high-throughput quantitative real-time reverse-transcription PCR method\n",
      "\n",
      "\n",
      "\n",
      "We have developed a 2-dimensional gel method for identification of RNA sequences crosslinked by the intercalative drug 4'-hydroxymethyl-4 , 5 ' , 8-trimethylpsoralen .\n",
      "{2: '2-dimensional gel method', 4: 'gel method'}\n",
      "Rule 2: 2-dimensional gel method\n",
      "\n",
      "\n",
      "\n",
      "Cleavage specific to the elongation complex has been quantified using ternary complex analysis .\n",
      "{2: 'ternary complex analysis', 4: 'complex analysis'}\n",
      "Rule 2: ternary complex analysis\n",
      "\n",
      "\n",
      "\n",
      "A matrix-assisted laser desorption / ionization time-of-flight mass spectrometry based method has recently been reported for the typing of single nucleotide polymorphisms using single nucleotide primer extension .\n",
      "{2: 'matrix-assisted laser desorption / ionization time-of-flight mass spectrometry based method', 4: 'laser desorption / ionization method'}\n",
      "Rule 2: matrix-assisted laser desorption / ionization time-of-flight mass spectrometry based method\n",
      "\n",
      "\n",
      "\n",
      "The recombinant plasmid can subsequently be transferred to and stably maintained in bacteria for efficient plasmid preparation .\n",
      "{2: 'efficient plasmid preparation', 4: 'plasmid preparation'}\n",
      "Rule 2: efficient plasmid preparation\n",
      "\n",
      "\n",
      "\n",
      "Using this protocol for DNA preparation , successful transfection of functional 1 Mb human artificial chromosome DNA into human cells has also been achieved .\n",
      "{4: 'DNA preparation'}\n",
      "Rule 4: DNA preparation\n",
      "\n",
      "\n",
      "\n",
      "A modification of the serum oxidation method described by Regnstrom et al. was used .\n",
      "{4: 'serum oxidation method'}\n",
      "Rule 4: serum oxidation method\n",
      "\n",
      "\n",
      "\n",
      "A dietary analysis method is described that provides a new tool for establishing relationships between diet and disease .\n",
      "{2: 'dietary analysis method', 4: 'analysis method'}\n",
      "Rule 2: dietary analysis method\n",
      "\n",
      "\n",
      "\n",
      "The 24-hour recall method is the most commonly used assessment tool in large cross-sectional surveys and skeletal development studies in both children and adults .\n",
      "{2: '24-hour recall method', 4: 'recall method'}\n",
      "Rule 2: 24-hour recall method\n",
      "\n",
      "\n",
      "\n",
      "As previously stated , the 24-hour recall method is the most often used dietary assessment tool in large clinical studies .\n",
      "{2: '24-hour recall method', 4: 'recall method'}\n",
      "Rule 2: 24-hour recall method\n",
      "\n",
      "\n",
      "\n",
      "Several earlier studies have employed multivariate techniques such as factor analysis to investigate MetS .\n",
      "{4: 'factor analysis'}\n",
      "Rule 4: factor analysis\n",
      "\n",
      "\n",
      "\n",
      "First , the multivariate factor analysis was performed with the FACTANAL function , with the maximum likelihood estimate option and the \" Varimax \" rotation , in Splus version 6.2 of Insightful Corp. , Seattle , WA .\n",
      "{2: 'multivariate factor analysis', 4: 'factor analysis'}\n",
      "Rule 2: multivariate factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Comparison of allelic frequencies between cases and controls was achieved through the χ2 test and the p value was empirically computed with the program CLUMP .\n",
      "{4: 'χ2 test'}\n",
      "Rule 4: χ2 test\n",
      "\n",
      "\n",
      "\n",
      "The Pedigree Disequilibrium Test allows us to evaluate evidence of LD in general pedigree data .\n",
      "{4: 'Pedigree Disequilibrium Test'}\n",
      "Rule 4: Pedigree Disequilibrium Test\n",
      "\n",
      "\n",
      "\n",
      "For a valid test of association with evidence of linkage , we count the number of times the replicate LOD score exceeds the observed LOD score , for a number of pairs equal to the original .\n",
      "{4: 'replicate LOD score'}\n",
      "Rule 4: replicate LOD score\n",
      "\n",
      "\n",
      "\n",
      "For a valid test of association with evidence of linkage , we count the number of times the replicate LOD score exceeds the observed LOD score , for a number of pairs equal to the original .\n",
      "{2: 'observed LOD score', 4: 'LOD score'}\n",
      "Rule 2: observed LOD score\n",
      "\n",
      "\n",
      "\n",
      "In order to investigate the long-term effects of novel stimulation on the spatiotemporal evolution of ongoing neuronal activity , we took advantage of a neuronal ensemble correlation method previously shown to detect experience-dependent reactivation of rodent hippocampal ensembles during SW and REM sleep .\n",
      "{2: 'neuronal ensemble correlation method', 4: 'ensemble correlation method'}\n",
      "Rule 2: neuronal ensemble correlation method\n",
      "\n",
      "\n",
      "\n",
      "To obtain experimental evidence that TM1 of Drosophila ORs inserts into the membrane with the N-terminus intracellular , we first used the β-galactosidase β-gal fusion technique .\n",
      "{4: 'β-galactosidase β-gal fusion technique'}\n",
      "Rule 4: β-galactosidase β-gal fusion technique\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Vitalis', 'lemma': 'vitalis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'nsubj:pass', 'misc': 'start_char=0|end_char=7', 'children': [5]}\n",
      "{'id': 2, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 5, 'deprel': 'cc', 'misc': 'start_char=8|end_char=11', 'children': []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3, 'text': 'Couvet', 'lemma': 'couvet', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=12|end_char=18', 'children': []}\n",
      "{'id': 4, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 5, 'deprel': 'case', 'misc': 'start_char=19|end_char=21', 'children': []}\n",
      "{'id': 5, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 1, 'deprel': 'conj', 'misc': 'start_char=22|end_char=28', 'children': [2, 3, 4]}\n",
      "{'id': 6, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 7, 'deprel': 'aux:pass', 'misc': 'start_char=29|end_char=32', 'children': []}\n",
      "{'id': 7, 'text': 'applied', 'lemma': 'apply', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=33|end_char=40', 'children': [1, 6, 10, 11]}\n",
      "{'id': 8, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'TO', 'head': 10, 'deprel': 'case', 'misc': 'start_char=41|end_char=43', 'children': []}\n",
      "{'id': 9, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 10, 'deprel': 'det', 'misc': 'start_char=44|end_char=47', 'children': []}\n",
      "{'id': 10, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 7, 'deprel': 'obl', 'misc': 'start_char=48|end_char=52', 'children': [8, 9]}\n",
      "{'id': 11, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 7, 'deprel': 'punct', 'misc': 'start_char=53|end_char=54', 'children': []}\n",
      "Vitalis and Couvet 's method was applied to the data .\n",
      "{5: \"Couvet 's method\"}\n",
      "Rule 5: Couvet 's method\n",
      "\n",
      "\n",
      "\n",
      "Similarity relationships between activity patterns were further characterized by factor analysis .\n",
      "{4: 'factor analysis'}\n",
      "Rule 4: factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Ages were imputed using the Elastic Net method .\n",
      "{2: 'Elastic Net method', 4: 'Net method'}\n",
      "Rule 2: Elastic Net method\n",
      "\n",
      "\n",
      "\n",
      "In the gene circuit method , a gene circuit model , in which one real number characterizes the regulatory effect of one gene on another , is fit to quantitative gene expression data by parallel Lam simulated annealing , and finally biological conclusions are obtained .\n",
      "{4: 'gene circuit method'}\n",
      "Rule 4: gene circuit method\n",
      "\n",
      "\n",
      "\n",
      "In the gene circuit method , a gene circuit model , in which one real number characterizes the regulatory effect of one gene on another , is fit to quantitative gene expression data by parallel Lam simulated annealing , and finally biological conclusions are obtained .\n",
      "{4: 'gene circuit model'}\n",
      "Rule 4: gene circuit model\n",
      "\n",
      "\n",
      "\n",
      "The CLR test uses the spatial distribution of mutation frequencies in a genomic region and levels of variability among a population sample of DNA sequences to test for evidence of a selective sweep .\n",
      "{4: 'CLR test'}\n",
      "Rule 4: CLR test\n",
      "\n",
      "\n",
      "\n",
      "We model the extraction problem as a combinatorial detection problem for at least three specific reasons : The data are obtained from a replica exchange molecular dynamics method .\n",
      "{2: 'replica exchange molecular dynamics method', 4: 'exchange molecular dynamics method'}\n",
      "Rule 2: replica exchange molecular dynamics method\n",
      "\n",
      "\n",
      "\n",
      "In order to detect such long-range periodic patterns in inherently noisy chromosome position-dependent data , wavelet analysis has been used in several studies .\n",
      "{4: 'wavelet analysis'}\n",
      "Rule 4: wavelet analysis\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we have used our evolutionary design method to design cis-regulatory domains of single operons .\n",
      "{2: 'evolutionary design method', 4: 'design method'}\n",
      "Rule 2: evolutionary design method\n",
      "\n",
      "\n",
      "\n",
      "Coupled with additional biological knowledge , however , the results of EMBP analysis can help infer disease-related pathways , which , in turn can help develop therapeutic interventions .\n",
      "{4: 'EMBP analysis'}\n",
      "Rule 4: EMBP analysis\n",
      "\n",
      "\n",
      "\n",
      "The second study we use for comparison describes a fragment assembly method that uses secondary structure information derived from the true structure to produce compact decoys .\n",
      "{4: 'fragment assembly method'}\n",
      "Rule 4: fragment assembly method\n",
      "\n",
      "\n",
      "\n",
      "We have developed a novel modification of the phylogenetic profile method that bypasses several of these problems , especially the orthology—or functional equivalence as it can also be perceived—detection problem , and can detect interacting multigene families .\n",
      "{2: 'phylogenetic profile method', 4: 'profile method'}\n",
      "Rule 2: phylogenetic profile method\n",
      "\n",
      "\n",
      "\n",
      "Our graph bigram method improves on this approach by accounting for all occurrences of the point mutation and protein terms throughout the length of the text instead of measuring one local relationship .\n",
      "{4: 'graph bigram method'}\n",
      "Rule 4: graph bigram method\n",
      "\n",
      "\n",
      "\n",
      "Previous approaches for summarizing Dirichlet Process mixture model components have used pairwise co-clustering probabilities as a similarity measure for input into an agglomerative clustering algorithm .\n",
      "{2: 'agglomerative clustering algorithm', 4: 'clustering algorithm'}\n",
      "Rule 2: agglomerative clustering algorithm\n",
      "\n",
      "\n",
      "\n",
      "Due to the large number of odorants used in the Drosophila experiment we decide to use a different feature extraction method that is similar to the Lorentzian but is easier to apply to all kind of signals .\n",
      "{2: 'different feature extraction method', 4: 'feature extraction method'}\n",
      "Rule 2: different feature extraction method\n",
      "\n",
      "\n",
      "\n",
      "We included the domain architecture comparison strategy that exhibited the best performance from that study in our current study .\n",
      "{4: 'domain architecture comparison strategy'}\n",
      "Rule 4: domain architecture comparison strategy\n",
      "\n",
      "\n",
      "\n",
      "In order to find such patterns , which may not necessarily form a connected tree , a tree-structure probabilistic model was developed , called the probabilistic sibling-dependent tree Markov model , or PSTMM .\n",
      "{2: 'probabilistic sibling-dependent tree Markov model', 4: 'tree Markov model'}\n",
      "Rule 2: probabilistic sibling-dependent tree Markov model\n",
      "\n",
      "\n",
      "\n",
      "To study the correlation between parameters and the effectiveness of proposed vaccination strategies , we apply the Latin Hypercube sampling method .\n",
      "{4: 'Latin Hypercube sampling method'}\n",
      "Rule 4: Latin Hypercube sampling method\n",
      "\n",
      "\n",
      "\n",
      "The only partially pan-specific HLA-DR prediction algorithm publicly available is the TEPITOPE method .\n",
      "{2: 'pan-specific HLA-DR prediction algorithm publicly available algorithm', 4: 'HLA-DR prediction algorithm'}\n",
      "Rule 2: pan-specific HLA-DR prediction algorithm publicly available algorithm\n",
      "\n",
      "\n",
      "\n",
      "The only partially pan-specific HLA-DR prediction algorithm publicly available is the TEPITOPE method .\n",
      "{4: 'TEPITOPE method'}\n",
      "Rule 4: TEPITOPE method\n",
      "\n",
      "\n",
      "\n",
      "We have introduced a novel , multisegment alignment method for time series .\n",
      "{2: 'novel multisegment alignment method', 4: 'alignment method'}\n",
      "Rule 2: novel multisegment alignment method\n",
      "\n",
      "\n",
      "\n",
      "Based on fluorescence recovery after photobleaching experiments , we have developed a finite element method to analyze , simulate , and subtract the diffusion effect of mobile biosensors .\n",
      "{2: 'finite element method', 4: 'element method'}\n",
      "Rule 2: finite element method\n",
      "\n",
      "\n",
      "\n",
      "In this study we present an in silico analysis method to determine pooling of variables in complex dynamic models of biochemical reaction networks .\n",
      "{2: 'in silico analysis method', 4: 'analysis method'}\n",
      "Rule 2: in silico analysis method\n",
      "\n",
      "\n",
      "\n",
      "We chose Zero Eigenvalue Analysis as a technique for searching parameter values that produce bistability in our model .\n",
      "{2: 'Zero Eigenvalue Analysis', 4: 'Eigenvalue Analysis'}\n",
      "Rule 2: Zero Eigenvalue Analysis\n",
      "\n",
      "\n",
      "\n",
      "The model investigated in this work is simulated using the Gillespie algorithm , implemented as a C++ function linked to MATLAB .\n",
      "{4: 'Gillespie algorithm'}\n",
      "Rule 4: Gillespie algorithm\n",
      "\n",
      "\n",
      "\n",
      "Principal Component Analysis or Essential Dynamics reduces the dimensionality of the covariance matrix by diagonalization .\n",
      "{2: 'Principal Component Analysis', 4: 'Component Analysis'}\n",
      "Rule 2: Principal Component Analysis\n",
      "\n",
      "\n",
      "\n",
      "Among the many methods used to detect communities in graphs , the modularity optimization algorithm of Newman is one of the most efficient and accurate to date .\n",
      "{4: 'modularity optimization algorithm'}\n",
      "Rule 4: modularity optimization algorithm\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 2, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'essence', 'lemma': 'essence', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'nsubj', 'misc': 'start_char=4|end_char=11', 'children': [1, 8]}\n",
      "{'id': 3, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 8, 'deprel': 'case', 'misc': 'start_char=12|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'Cartan', 'lemma': 'cartan', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'nmod:poss', 'misc': 'start_char=15|end_char=21', 'children': []}\n",
      "{'id': 5, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 8, 'deprel': 'case', 'misc': 'start_char=22|end_char=24', 'children': []}\n",
      "{'id': 6, 'text': 'moving', 'lemma': 'moving', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'compound', 'misc': 'start_char=25|end_char=31', 'children': []}\n",
      "{'id': 7, 'text': 'frame', 'lemma': 'frame', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'compound', 'misc': 'start_char=32|end_char=37', 'children': []}\n",
      "{'id': 8, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=38|end_char=44', 'children': [3, 4, 5, 6, 7]}\n",
      "{'id': 9, 'text': 'is', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=45|end_char=47', 'children': [2, 12, 31]}\n",
      "{'id': 10, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 12, 'deprel': 'mark', 'misc': 'start_char=48|end_char=52', 'children': []}\n",
      "{'id': 11, 'text': 'it', 'lemma': 'it', 'upos': 'PRON', 'xpos': 'PRP', 'head': 12, 'deprel': 'nsubj', 'misc': 'start_char=53|end_char=55', 'children': []}\n",
      "{'id': 12, 'text': 'creates', 'lemma': 'create', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 9, 'deprel': 'ccomp', 'misc': 'start_char=56|end_char=63', 'children': [10, 11, 14]}\n",
      "{'id': 13, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 14, 'deprel': 'det', 'misc': 'start_char=64|end_char=65', 'children': []}\n",
      "{'id': 14, 'text': 'correspondence', 'lemma': 'correspondence', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=66|end_char=80', 'children': [13, 18]}\n",
      "{'id': 15, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 18, 'deprel': 'case', 'misc': 'start_char=81|end_char=88', 'children': []}\n",
      "{'id': 16, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 18, 'deprel': 'det', 'misc': 'start_char=89|end_char=92', 'children': []}\n",
      "{'id': 17, 'text': 'different', 'lemma': 'different', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 18, 'deprel': 'amod', 'misc': 'start_char=93|end_char=102', 'children': []}\n",
      "{'id': 18, 'text': 'orders', 'lemma': 'order', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 14, 'deprel': 'nmod', 'misc': 'start_char=103|end_char=109', 'children': [15, 16, 17, 20, 27]}\n",
      "{'id': 19, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'misc': 'start_char=110|end_char=112', 'children': []}\n",
      "{'id': 20, 'text': 'description', 'lemma': 'description', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'nmod', 'misc': 'start_char=113|end_char=124', 'children': [19, 22]}\n",
      "{'id': 21, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 22, 'deprel': 'case', 'misc': 'start_char=125|end_char=127', 'children': []}\n",
      "{'id': 22, 'text': 'trajectories', 'lemma': 'trajectory', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 20, 'deprel': 'nmod', 'misc': 'start_char=128|end_char=140', 'children': [21]}\n",
      "{'id': 23, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 27, 'deprel': 'cc', 'misc': 'start_char=141|end_char=144', 'children': []}\n",
      "{'id': 24, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 27, 'deprel': 'det', 'misc': 'start_char=145|end_char=148', 'children': []}\n",
      "{'id': 25, 'text': 'possible', 'lemma': 'possible', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 27, 'deprel': 'amod', 'misc': 'start_char=149|end_char=157', 'children': []}\n",
      "{'id': 26, 'text': 'coordinate', 'lemma': 'coordinate', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 27, 'deprel': 'amod', 'misc': 'start_char=158|end_char=168', 'children': []}\n",
      "{'id': 27, 'text': 'frames', 'lemma': 'frame', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 18, 'deprel': 'conj', 'misc': 'start_char=169|end_char=175', 'children': [23, 24, 25, 26, 30]}\n",
      "{'id': 28, 'text': 'on', 'lemma': 'on', 'upos': 'ADP', 'xpos': 'IN', 'head': 30, 'deprel': 'case', 'misc': 'start_char=176|end_char=178', 'children': []}\n",
      "{'id': 29, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 30, 'deprel': 'det', 'misc': 'start_char=179|end_char=182', 'children': []}\n",
      "{'id': 30, 'text': 'plane', 'lemma': 'plane', 'upos': 'NOUN', 'xpos': 'NN', 'head': 27, 'deprel': 'nmod', 'misc': 'start_char=183|end_char=188', 'children': [28, 29]}\n",
      "{'id': 31, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 9, 'deprel': 'punct', 'misc': 'start_char=189|end_char=190', 'children': []}\n",
      "The essence of Cartan 's moving frame method is that it creates a correspondence between the different orders of description of trajectories and the possible coordinate frames on the plane .\n",
      "{4: 'moving frame method', 5: \"Cartan 's moving frame method\"}\n",
      "Rule 5: Cartan 's moving frame method\n",
      "\n",
      "\n",
      "\n",
      "We utilized the unsupervised clustering algorithm implemented in STRUCTURE to group individuals into genetic clusters in such a way that each individual is given an estimated membership coefficient for each cluster , corresponding to the fraction of his or her genome inferred to have ancestry in the cluster .\n",
      "{2: 'unsupervised clustering algorithm', 4: 'clustering algorithm'}\n",
      "Rule 2: unsupervised clustering algorithm\n",
      "\n",
      "\n",
      "\n",
      "HaploStats expands on the likelihood approach to account for ambiguity in case-control studies by using a generalized linear model to test for haplotype association , which allows for adjustment of nongenetic covariates .\n",
      "{4: 'likelihood approach'}\n",
      "Rule 4: likelihood approach\n",
      "\n",
      "\n",
      "\n",
      "Factor analysis of correspondence was performed using the Genetix software .\n",
      "{4: 'Factor analysis'}\n",
      "Rule 4: Factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Thus , rather than generating maximal sets of potential genes , we designed a stringent gene identification method that maximally recognizes orthologous genes that can be used to reconstruct the ancestral genome .\n",
      "{2: 'stringent gene identification method', 4: 'gene identification method'}\n",
      "Rule 2: stringent gene identification method\n",
      "\n",
      "\n",
      "\n",
      "We used a modified gene set enrichment analysis , which measures the cumulative effect of small but consistent changes in expression levels of genes within a gene set .\n",
      "{2: 'modified gene set enrichment analysis', 4: 'gene set enrichment analysis'}\n",
      "Rule 2: modified gene set enrichment analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'An', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 3, 'deprel': 'det', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'interesting', 'lemma': 'interesting', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 3, 'deprel': 'amod', 'misc': 'start_char=3|end_char=14', 'children': []}\n",
      "{'id': 3, 'text': 'feature', 'lemma': 'feature', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'nsubj', 'misc': 'start_char=15|end_char=22', 'children': [1, 2, 7]}\n",
      "{'id': 4, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 7, 'deprel': 'case', 'misc': 'start_char=23|end_char=25', 'children': []}\n",
      "{'id': 5, 'text': 'Tzeng', 'lemma': 'tzeng', 'upos': 'NOUN', 'xpos': 'NN', 'head': 7, 'deprel': 'nmod:poss', 'misc': 'start_char=26|end_char=31', 'children': []}\n",
      "{'id': 6, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 7, 'deprel': 'case', 'misc': 'start_char=32|end_char=34', 'children': []}\n",
      "{'id': 7, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 3, 'deprel': 'nmod', 'misc': 'start_char=35|end_char=41', 'children': [4, 5, 6]}\n",
      "{'id': 8, 'text': 'is', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=42|end_char=44', 'children': [3, 15, 21]}\n",
      "{'id': 9, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 15, 'deprel': 'mark', 'misc': 'start_char=45|end_char=49', 'children': []}\n",
      "{'id': 10, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 12, 'deprel': 'det', 'misc': 'start_char=50|end_char=53', 'children': []}\n",
      "{'id': 11, 'text': 'rare', 'lemma': 'rare', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 12, 'deprel': 'amod', 'misc': 'start_char=54|end_char=58', 'children': []}\n",
      "{'id': 12, 'text': 'haplotypes', 'lemma': 'haplotype', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'nsubj:pass', 'misc': 'start_char=59|end_char=69', 'children': [10, 11]}\n",
      "{'id': 13, 'text': 'can', 'lemma': 'can', 'upos': 'AUX', 'xpos': 'MD', 'head': 15, 'deprel': 'aux', 'misc': 'start_char=70|end_char=73', 'children': []}\n",
      "{'id': 14, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 15, 'deprel': 'aux:pass', 'misc': 'start_char=74|end_char=76', 'children': []}\n",
      "{'id': 15, 'text': 'grouped', 'lemma': 'group', 'upos': 'VERB', 'xpos': 'VBN', 'head': 8, 'deprel': 'ccomp', 'misc': 'start_char=77|end_char=84', 'children': [9, 12, 13, 14, 20]}\n",
      "{'id': 16, 'text': 'into', 'lemma': 'into', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'misc': 'start_char=85|end_char=89', 'children': []}\n",
      "{'id': 17, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 20, 'deprel': 'det', 'misc': 'start_char=90|end_char=93', 'children': []}\n",
      "{'id': 18, 'text': 'closest', 'lemma': 'closest', 'upos': 'ADJ', 'xpos': 'JJS', 'head': 20, 'deprel': 'amod', 'misc': 'start_char=94|end_char=101', 'children': []}\n",
      "{'id': 19, 'text': 'major', 'lemma': 'major', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 20, 'deprel': 'amod', 'misc': 'start_char=102|end_char=107', 'children': []}\n",
      "{'id': 20, 'text': 'haplotypes', 'lemma': 'haplotype', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=108|end_char=118', 'children': [16, 17, 18, 19]}\n",
      "{'id': 21, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 8, 'deprel': 'punct', 'misc': 'start_char=119|end_char=120', 'children': []}\n",
      "An interesting feature of Tzeng 's method is that the rare haplotypes can be grouped into the closest major haplotypes .\n",
      "{5: \"Tzeng 's method\"}\n",
      "Rule 5: Tzeng 's method\n",
      "\n",
      "\n",
      "\n",
      "For example , Wang and Rannala used an additive selection model and a forward approach with a normal approximation to the binomial selection process .\n",
      "{2: 'additive selection model', 4: 'selection model'}\n",
      "Rule 2: additive selection model\n",
      "\n",
      "\n",
      "\n",
      "We use the single-locus TDT method in GeneHunter for the Linkage analyses .\n",
      "{2: 'single-locus TDT method', 4: 'TDT method'}\n",
      "Rule 2: single-locus TDT method\n",
      "\n",
      "\n",
      "\n",
      "In conclusion , we have introduced a novel semi-automatic screening method for skeletal phenotyping by applying neuronal networks in combination with fpVCT , so far limited to five different mice models .\n",
      "{2: 'novel semi-automatic screening method', 4: 'screening method'}\n",
      "Rule 2: novel semi-automatic screening method\n",
      "\n",
      "\n",
      "\n",
      "Therefore , we adapted and applied the 2D Wavelet-Transform Modulus Maxima method .\n",
      "{2: '2D Wavelet-Transform Modulus Maxima method', 4: '2D Wavelet-Transform Modulus Maxima method'}\n",
      "Rule 2: 2D Wavelet-Transform Modulus Maxima method\n",
      "\n",
      "\n",
      "\n",
      "The sliding window method was used to identify regions where neighboring SNPs consistently show differences in allele frequency between cases and controls .\n",
      "{2: 'sliding window method', 4: 'window method'}\n",
      "Rule 2: sliding window method\n",
      "\n",
      "\n",
      "\n",
      "A second combinatorial control technique relies on temperature-dependent degradation of the mRNA of the target gene .\n",
      "{2: 'second combinatorial control technique', 4: 'control technique'}\n",
      "Rule 2: second combinatorial control technique\n",
      "\n",
      "\n",
      "\n",
      "Lander and Botstein developed the classic interval mapping method , in which they showed how to perform a QTL mapping strategy implemented with the most likely genotypes for the genome regions in between marker locations , given the genotypes at the flanking markers .\n",
      "{2: 'classic interval mapping method', 4: 'interval mapping method'}\n",
      "Rule 2: classic interval mapping method\n",
      "\n",
      "\n",
      "\n",
      "The functional enrichment analysis introduced here allows association between eQTLs and biological pathways , enabling the identification of both novel members and novel regulators of these pathways .\n",
      "{2: 'functional enrichment analysis', 4: 'enrichment analysis'}\n",
      "Rule 2: functional enrichment analysis\n",
      "\n",
      "\n",
      "\n",
      "First , association analysis was done with correction by genomic control .\n",
      "{4: 'association analysis'}\n",
      "Rule 4: association analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 5, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'most', 'lemma': 'most', 'upos': 'ADV', 'xpos': 'RBS', 'head': 4, 'deprel': 'advmod', 'misc': 'start_char=4|end_char=8', 'children': []}\n",
      "{'id': 3, 'text': 'commonly', 'lemma': 'commonly', 'upos': 'ADV', 'xpos': 'RB', 'head': 4, 'deprel': 'advmod', 'misc': 'start_char=9|end_char=17', 'children': []}\n",
      "{'id': 4, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 5, 'deprel': 'amod', 'misc': 'start_char=18|end_char=22', 'children': [2, 3]}\n",
      "{'id': 5, 'text': 'approach', 'lemma': 'approach', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'nsubj', 'misc': 'start_char=23|end_char=31', 'children': [1, 4, 8, 9, 15]}\n",
      "{'id': 6, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 8, 'deprel': 'case', 'misc': 'start_char=32|end_char=35', 'children': []}\n",
      "{'id': 7, 'text': 'pathway', 'lemma': 'pathway', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'compound', 'misc': 'start_char=36|end_char=43', 'children': []}\n",
      "{'id': 8, 'text': 'analysis', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=44|end_char=52', 'children': [6, 7, 11]}\n",
      "{'id': 9, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 5, 'deprel': 'punct', 'misc': 'start_char=53|end_char=54', 'children': []}\n",
      "{'id': 10, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 11, 'deprel': 'det', 'misc': 'start_char=55|end_char=58', 'children': []}\n",
      "{'id': 11, 'text': 'enrichment', 'lemma': 'enrichment', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'appos', 'misc': 'start_char=59|end_char=69', 'children': [10, 13, 14]}\n",
      "{'id': 12, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 13, 'deprel': 'cc', 'misc': 'start_char=70|end_char=72', 'children': []}\n",
      "{'id': 13, 'text': 'overrepresentation', 'lemma': 'overrepresentation', 'upos': 'NOUN', 'xpos': 'NN', 'head': 11, 'deprel': 'conj', 'misc': 'start_char=73|end_char=91', 'children': [12]}\n",
      "{'id': 14, 'text': 'analysis', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 11, 'deprel': 'conj', 'misc': 'start_char=92|end_char=100', 'children': []}\n",
      "{'id': 15, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 5, 'deprel': 'punct', 'misc': 'start_char=101|end_char=102', 'children': []}\n",
      "{'id': 16, 'text': 'uses', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=103|end_char=107', 'children': [5, 20, 21]}\n",
      "{'id': 17, 'text': 'Fisher', 'lemma': 'fisher', 'upos': 'NOUN', 'xpos': 'NN', 'head': 20, 'deprel': 'nmod:poss', 'misc': 'start_char=108|end_char=114', 'children': [18]}\n",
      "{'id': 18, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 17, 'deprel': 'case', 'misc': 'start_char=115|end_char=117', 'children': []}\n",
      "{'id': 19, 'text': 'exact', 'lemma': 'exact', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 20, 'deprel': 'amod', 'misc': 'start_char=118|end_char=123', 'children': []}\n",
      "{'id': 20, 'text': 'test', 'lemma': 'test', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'obj', 'misc': 'start_char=124|end_char=128', 'children': [17, 19]}\n",
      "{'id': 21, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=129|end_char=130', 'children': []}\n",
      "The most commonly used approach for pathway analysis , the enrichment or overrepresentation analysis , uses Fisher 's exact test .\n",
      "{5: \"Fisher 's exact test\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 5: Fisher 's exact test\n",
      "\n",
      "\n",
      "\n",
      "Our results offer strong proof that the Solexa method can be used to rapidly reveal multiple aspects of genomic content and organization , especially base substitutions , which greatly simplifies experimental design and facilitates our understanding of the biology of model organisms .\n",
      "{4: 'Solexa method'}\n",
      "Rule 4: Solexa method\n",
      "\n",
      "\n",
      "\n",
      "A recently developed branch support measure , the approximate Likelihood Ratio Test , can also be used to assess the support for branches .\n",
      "{2: 'approximate Likelihood Ratio Test', 4: 'Likelihood Ratio Test'}\n",
      "Rule 2: approximate Likelihood Ratio Test\n",
      "\n",
      "\n",
      "\n",
      "To control for the possibility of spurious associations resulting from population stratification we used the EIGENSTRAT approach of Price et al .\n",
      "{4: 'EIGENSTRAT approach'}\n",
      "Rule 4: EIGENSTRAT approach\n",
      "\n",
      "\n",
      "\n",
      "If a pathway contains G non-overlapping genes , a method to do this is to use the weighted-sum method on each gene , and combine the resulting p-values with the Fisher product test statisticSince π1 , … , πG are i.i.d. uniformly distributed under the null-hypothesis , T is χ2-distributed with 2G degrees of freedom , and can be evaluated accordingly .\n",
      "{4: 'Fisher product test'}\n",
      "Rule 4: Fisher product test\n",
      "\n",
      "\n",
      "\n",
      "Genomic DNA gel blot analysis with probes derived from different ΨSRKs was used to assess the composition of the S locus in various accessions of A. thaliana .\n",
      "{2: 'Genomic DNA gel blot analysis', 4: 'DNA gel blot analysis'}\n",
      "Rule 2: Genomic DNA gel blot analysis\n",
      "\n",
      "\n",
      "\n",
      "Lastly , we apply the analytical best-tag Bonferroni method which uses the Bonferroni correction for the per-marker threshold and estimates power for each causal SNP by using the most correlated marker .\n",
      "{2: 'analytical best-tag Bonferroni method', 4: 'Bonferroni method'}\n",
      "Rule 2: analytical best-tag Bonferroni method\n",
      "\n",
      "\n",
      "\n",
      "The random walk method was used to select households .\n",
      "{2: 'random walk method', 4: 'walk method'}\n",
      "Rule 2: random walk method\n",
      "\n",
      "\n",
      "\n",
      "Because we selected the partners of the cases as control individuals , and because it turned out , as expected , that couples tend to travel together , we performed a conditional logistic regression analysis to calculate odds ratios for the relation between travel and venous thrombosis .\n",
      "{2: 'conditional logistic regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: conditional logistic regression analysis\n",
      "\n",
      "\n",
      "\n",
      "We employed cross-sectional time series analysis by generalized least-square regression for random effects using the xtreg command in STATA 8.0 software .\n",
      "{2: 'cross-sectional time series analysis', 4: 'time series analysis'}\n",
      "Rule 2: cross-sectional time series analysis\n",
      "\n",
      "\n",
      "\n",
      "To evaluate the number of false positives , we used a Monte Carlo approach based on 1,000 random sample label permutations .\n",
      "{4: 'Monte Carlo approach'}\n",
      "Rule 4: Monte Carlo approach\n",
      "\n",
      "\n",
      "\n",
      "The data on sexual partnerships and condom use were collected using the Informal Confidential Voting Interview method for 75 % of respondents selected at random in the first round of the survey .\n",
      "{2: 'Informal Confidential Voting Interview method', 4: 'Voting Interview method'}\n",
      "Rule 2: Informal Confidential Voting Interview method\n",
      "\n",
      "\n",
      "\n",
      "In the sensitivity analysis , we used a more refined approach , known as “nearest-neighbor” imputation .\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "Drug concentrations in plasma were determined by a validated high pressure , liquid chromatography method with ultraviolet detection .\n",
      "{2: 'validated high pressure liquid chromatography method', 4: 'pressure liquid chromatography method'}\n",
      "Rule 2: validated high pressure liquid chromatography method\n",
      "\n",
      "\n",
      "\n",
      "A supervised analysis was also performed to determine genes that were significantly differentially expressed between pre- and post-epigenetic treatment in clinical samples using significance analysis ofg microarrays .\n",
      "{4: 'significance analysis'}\n",
      "Rule 4: significance analysis\n",
      "\n",
      "\n",
      "\n",
      "Figure 1 shows the hierarchical Bayesian consensus tree generated by a GTR invariant-sites plus gamma model .\n",
      "{2: 'GTR invariant-sites model', 4: 'GTR model'}\n",
      "Rule 2: GTR invariant-sites model\n",
      "\n",
      "\n",
      "\n",
      "However , by using a related model organism as a proxy for missing functional genomic data and applying multiple layers of subtractive filters based on comparative sequence analysis , we can pre-validate a pool of targets to facilitate their entry into drug discovery programs .\n",
      "{2: 'comparative sequence analysis', 4: 'sequence analysis'}\n",
      "Rule 2: comparative sequence analysis\n",
      "\n",
      "\n",
      "\n",
      "The MHW method is extensively described in the Methods section and schematically depicted in Figure 2 .\n",
      "{4: 'MHW method'}\n",
      "Rule 4: MHW method\n",
      "\n",
      "\n",
      "\n",
      "Thus , this public health pursuit is herein addressed with the MHW forecasting method .\n",
      "{4: 'MHW forecasting method'}\n",
      "Rule 4: MHW forecasting method\n",
      "\n",
      "\n",
      "\n",
      "The MHW method captures these interactions , decomposing highly non-linear TS features and hence , ascribing a non-linear ‘flavor’ to disease TS forecasts .\n",
      "{4: 'MHW method'}\n",
      "Rule 4: MHW method\n",
      "\n",
      "\n",
      "\n",
      "We estimated marker location-specific ancestry using the HMM , in which the transmission probability was calculated based on the continuous gene flow model .\n",
      "{2: 'continuous gene flow model', 4: 'gene flow model'}\n",
      "Rule 2: continuous gene flow model\n",
      "\n",
      "\n",
      "\n",
      "Heteroduplexes are isolated , separated on polyacrylamide gels , and quantified using Southern blots for heteroduplex analysis .\n",
      "{4: 'heteroduplex analysis'}\n",
      "Rule 4: heteroduplex analysis\n",
      "\n",
      "\n",
      "\n",
      "The system for heteroduplex analysis described here utilizes several commonly performed methods , with a few modifications , to create , isolate , and detect heteroduplexes formed in vivo .\n",
      "{4: 'heteroduplex analysis'}\n",
      "Rule 4: heteroduplex analysis\n",
      "\n",
      "\n",
      "\n",
      "We propose use of GC to correct for conservativeness of the GRAMMAR approach outlined earlier .\n",
      "{4: 'GRAMMAR approach'}\n",
      "Rule 4: GRAMMAR approach\n",
      "\n",
      "\n",
      "\n",
      "In the space-time permutation scan statistic , the time window is varied at time spans ranging from one month to six months and anchored on the last month of the time window , using data restricted up to that point .\n",
      "{2: 'space-time permutation scan statistic', 4: 'permutation scan statistic'}\n",
      "Rule 2: space-time permutation scan statistic\n",
      "\n",
      "\n",
      "\n",
      "The standardized nearest neighbour distance method was used to describe the degree of spatial clustering of the A and B cell distributions obtained in the “extrinsic” and “intrinsic” models .\n",
      "{2: 'standardized nearest neighbour distance method', 4: 'neighbour distance method'}\n",
      "Rule 2: standardized nearest neighbour distance method\n",
      "\n",
      "\n",
      "\n",
      "The whole cell approach also allows for an analysis in time of distinct entry intermediates , a study that is currently under investigation .\n",
      "{2: 'whole cell approach', 4: 'cell approach'}\n",
      "Rule 2: whole cell approach\n",
      "\n",
      "\n",
      "\n",
      "The Product of Approximate Conditionals model of Li and Stephens was used to further investigate the recombination rate over the entire region and over the proposed non-recombining block .\n",
      "{2: 'Approximate Conditionals model', 4: 'Conditionals model'}\n",
      "Rule 2: Approximate Conditionals model\n",
      "\n",
      "\n",
      "\n",
      "Telschow et al. determined analytically critical migration rates in a two population model with bidirectional CI using standard fixpoint analysis .\n",
      "{4: 'population model'}\n",
      "Rule 4: population model\n",
      "\n",
      "\n",
      "\n",
      "Telschow et al. determined analytically critical migration rates in a two population model with bidirectional CI using standard fixpoint analysis .\n",
      "{2: 'standard fixpoint analysis', 4: 'fixpoint analysis'}\n",
      "Rule 2: standard fixpoint analysis\n",
      "\n",
      "\n",
      "\n",
      "We used the single section disector method to estimate the size and number of vesicles contained in a random sample of labeled prefrontal cortico-thalamic boutons .\n",
      "{2: 'single section disector method', 4: 'section disector method'}\n",
      "Rule 2: single section disector method\n",
      "\n",
      "\n",
      "\n",
      "The Significance Analysis of Microarrays program , which evaluates the distribution of the t statistic with numerous random permutations of group assignments , indicated that there were more than 3,000 sex-related differences when limiting the false discovery rate to 5 % .\n",
      "{4: 'Significance Analysis'}\n",
      "Rule 4: Significance Analysis\n",
      "\n",
      "\n",
      "\n",
      "The gene expression database was examined for differential expression in men and women after re-calculating expression scores with the GCRMA method as implemented by ArrayAssist Lite software .\n",
      "{4: 'GCRMA method'}\n",
      "Rule 4: GCRMA method\n",
      "\n",
      "\n",
      "\n",
      "Using the GMR-hid ey-FLP method , we conducted an EMS-mutagenesis screen for chromosome arm 3L to identify recessive suppressors of the GMR-hid eye ablation phenotype .\n",
      "{4: 'GMR-hid ey-FLP method'}\n",
      "Rule 4: GMR-hid ey-FLP method\n",
      "\n",
      "\n",
      "\n",
      "Second , we used the Bayesian clustering algorithm implemented in Structure 2.1 .\n",
      "{2: 'Bayesian clustering algorithm', 4: 'clustering algorithm'}\n",
      "Rule 2: Bayesian clustering algorithm\n",
      "\n",
      "\n",
      "\n",
      "Capitalizing on DNA-based technology , the Membranome phage-Ab collection offers a complementary approach to standard proteomic analysis by applying unmatched throughput and high sensitivity of microarray technology to protein expression analysis .\n",
      "{4: 'protein expression analysis'}\n",
      "Rule 4: protein expression analysis\n",
      "\n",
      "\n",
      "\n",
      "It is important to point out that the WT method of fitting the effective reproductive model over fits the model and suffers from generalizeability .\n",
      "{4: 'WT method'}\n",
      "Rule 4: WT method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'There', 'lemma': 'there', 'upos': 'PRON', 'xpos': 'EX', 'head': 2, 'deprel': 'expl', 'misc': 'start_char=0|end_char=5', 'children': []}\n",
      "{'id': 2, 'text': 'are', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBP', 'head': 0, 'deprel': 'root', 'misc': 'start_char=6|end_char=9', 'children': [1, 4, 44]}\n",
      "{'id': 3, 'text': 'several', 'lemma': 'several', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 4, 'deprel': 'amod', 'misc': 'start_char=10|end_char=17', 'children': []}\n",
      "{'id': 4, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 2, 'deprel': 'nsubj', 'misc': 'start_char=18|end_char=25', 'children': [3, 8]}\n",
      "{'id': 5, 'text': 'that', 'lemma': 'that', 'upos': 'PRON', 'xpos': 'WDT', 'head': 8, 'deprel': 'nsubj:pass', 'misc': 'start_char=26|end_char=30', 'children': []}\n",
      "{'id': 6, 'text': 'can', 'lemma': 'can', 'upos': 'AUX', 'xpos': 'MD', 'head': 8, 'deprel': 'aux', 'misc': 'start_char=31|end_char=34', 'children': []}\n",
      "{'id': 7, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 8, 'deprel': 'aux:pass', 'misc': 'start_char=35|end_char=37', 'children': []}\n",
      "{'id': 8, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 4, 'deprel': 'acl:relcl', 'misc': 'start_char=38|end_char=42', 'children': [5, 6, 7, 10, 22]}\n",
      "{'id': 9, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 10, 'deprel': 'mark', 'misc': 'start_char=43|end_char=45', 'children': []}\n",
      "{'id': 10, 'text': 'solve', 'lemma': 'solve', 'upos': 'VERB', 'xpos': 'VB', 'head': 8, 'deprel': 'xcomp', 'misc': 'start_char=46|end_char=51', 'children': [9, 12]}\n",
      "{'id': 11, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 12, 'deprel': 'det', 'misc': 'start_char=52|end_char=56', 'children': []}\n",
      "{'id': 12, 'text': 'matrix', 'lemma': 'matrix', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'obj', 'misc': 'start_char=57|end_char=63', 'children': [11, 15]}\n",
      "{'id': 13, 'text': 'including', 'lemma': 'include', 'upos': 'VERB', 'xpos': 'VBG', 'head': 15, 'deprel': 'case', 'misc': 'start_char=64|end_char=73', 'children': []}\n",
      "{'id': 14, 'text': 'simply', 'lemma': 'simply', 'upos': 'ADV', 'xpos': 'RB', 'head': 15, 'deprel': 'advmod', 'misc': 'start_char=74|end_char=80', 'children': []}\n",
      "{'id': 15, 'text': 'solving', 'lemma': 'solve', 'upos': 'VERB', 'xpos': 'VBG', 'head': 12, 'deprel': 'acl', 'misc': 'start_char=81|end_char=88', 'children': [13, 14, 17]}\n",
      "{'id': 16, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 17, 'deprel': 'case', 'misc': 'start_char=89|end_char=92', 'children': []}\n",
      "{'id': 17, 'text': 'each', 'lemma': 'each', 'upos': 'DET', 'xpos': 'DT', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=93|end_char=97', 'children': [16, 20]}\n",
      "{'id': 18, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'misc': 'start_char=98|end_char=100', 'children': []}\n",
      "{'id': 19, 'text': 'these', 'lemma': 'these', 'upos': 'DET', 'xpos': 'DT', 'head': 20, 'deprel': 'det', 'misc': 'start_char=101|end_char=106', 'children': []}\n",
      "{'id': 20, 'text': 'coefficients', 'lemma': 'coefficient', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 17, 'deprel': 'nmod', 'misc': 'start_char=107|end_char=119', 'children': [18, 19]}\n",
      "{'id': 21, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 22, 'deprel': 'cc', 'misc': 'start_char=120|end_char=122', 'children': []}\n",
      "{'id': 22, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 8, 'deprel': 'conj', 'misc': 'start_char=123|end_char=128', 'children': [21, 23, 39]}\n",
      "{'id': 23, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=129|end_char=136', 'children': [27]}\n",
      "{'id': 24, 'text': 'such', 'lemma': 'such', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 27, 'deprel': 'case', 'misc': 'start_char=137|end_char=141', 'children': [25]}\n",
      "{'id': 25, 'text': 'as', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 24, 'deprel': 'fixed', 'misc': 'start_char=142|end_char=144', 'children': []}\n",
      "{'id': 26, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 27, 'deprel': 'det', 'misc': 'start_char=145|end_char=148', 'children': []}\n",
      "{'id': 27, 'text': 'Levinson', 'lemma': 'levinson', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 23, 'deprel': 'nmod', 'misc': 'start_char=149|end_char=157', 'children': [24, 26, 28, 29, 30, 34, 38, 40]}\n",
      "{'id': 28, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 27, 'deprel': 'punct', 'misc': 'start_char=158|end_char=159', 'children': []}\n",
      "{'id': 29, 'text': 'Wiggins', 'lemma': 'wiggin', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=160|end_char=167', 'children': []}\n",
      "{'id': 30, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 27, 'deprel': 'punct', 'misc': 'start_char=168|end_char=169', 'children': []}\n",
      "{'id': 31, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 34, 'deprel': 'cc', 'misc': 'start_char=170|end_char=173', 'children': []}\n",
      "{'id': 32, 'text': 'Robertson', 'lemma': 'robertson', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'nmod:poss', 'misc': 'start_char=174|end_char=183', 'children': []}\n",
      "{'id': 33, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 34, 'deprel': 'case', 'misc': 'start_char=184|end_char=186', 'children': []}\n",
      "{'id': 34, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=187|end_char=193', 'children': [31, 32, 33]}\n",
      "{'id': 35, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 38, 'deprel': 'cc', 'misc': 'start_char=194|end_char=196', 'children': []}\n",
      "{'id': 36, 'text': 'Morf', 'lemma': 'morf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 38, 'deprel': 'nmod:poss', 'misc': 'start_char=197|end_char=201', 'children': []}\n",
      "{'id': 37, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 38, 'deprel': 'case', 'misc': 'start_char=202|end_char=204', 'children': []}\n",
      "{'id': 38, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=205|end_char=211', 'children': [35, 36, 37]}\n",
      "{'id': 39, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 22, 'deprel': 'punct', 'misc': 'start_char=212|end_char=213', 'children': []}\n",
      "{'id': 40, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 27, 'deprel': 'acl', 'misc': 'start_char=214|end_char=218', 'children': [43]}\n",
      "{'id': 41, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 43, 'deprel': 'case', 'misc': 'start_char=219|end_char=222', 'children': []}\n",
      "{'id': 42, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 43, 'deprel': 'det', 'misc': 'start_char=223|end_char=227', 'children': []}\n",
      "{'id': 43, 'text': 'analysis', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'obl', 'misc': 'start_char=228|end_char=236', 'children': [41, 42]}\n",
      "{'id': 44, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 2, 'deprel': 'punct', 'misc': 'start_char=237|end_char=238', 'children': []}\n",
      "There are several methods that can be used to solve this matrix including simply solving for each of these coefficients or using methods such as the Levinson , Wiggins , and Robertson 's method or Morf 's method , used for this analysis .\n",
      "{5: \"Robertson 's method\"}\n",
      "Rule 5: Robertson 's method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'There', 'lemma': 'there', 'upos': 'PRON', 'xpos': 'EX', 'head': 2, 'deprel': 'expl', 'misc': 'start_char=0|end_char=5', 'children': []}\n",
      "{'id': 2, 'text': 'are', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBP', 'head': 0, 'deprel': 'root', 'misc': 'start_char=6|end_char=9', 'children': [1, 4, 44]}\n",
      "{'id': 3, 'text': 'several', 'lemma': 'several', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 4, 'deprel': 'amod', 'misc': 'start_char=10|end_char=17', 'children': []}\n",
      "{'id': 4, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 2, 'deprel': 'nsubj', 'misc': 'start_char=18|end_char=25', 'children': [3, 8]}\n",
      "{'id': 5, 'text': 'that', 'lemma': 'that', 'upos': 'PRON', 'xpos': 'WDT', 'head': 8, 'deprel': 'nsubj:pass', 'misc': 'start_char=26|end_char=30', 'children': []}\n",
      "{'id': 6, 'text': 'can', 'lemma': 'can', 'upos': 'AUX', 'xpos': 'MD', 'head': 8, 'deprel': 'aux', 'misc': 'start_char=31|end_char=34', 'children': []}\n",
      "{'id': 7, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 8, 'deprel': 'aux:pass', 'misc': 'start_char=35|end_char=37', 'children': []}\n",
      "{'id': 8, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 4, 'deprel': 'acl:relcl', 'misc': 'start_char=38|end_char=42', 'children': [5, 6, 7, 10, 22]}\n",
      "{'id': 9, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 10, 'deprel': 'mark', 'misc': 'start_char=43|end_char=45', 'children': []}\n",
      "{'id': 10, 'text': 'solve', 'lemma': 'solve', 'upos': 'VERB', 'xpos': 'VB', 'head': 8, 'deprel': 'xcomp', 'misc': 'start_char=46|end_char=51', 'children': [9, 12]}\n",
      "{'id': 11, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 12, 'deprel': 'det', 'misc': 'start_char=52|end_char=56', 'children': []}\n",
      "{'id': 12, 'text': 'matrix', 'lemma': 'matrix', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'obj', 'misc': 'start_char=57|end_char=63', 'children': [11, 15]}\n",
      "{'id': 13, 'text': 'including', 'lemma': 'include', 'upos': 'VERB', 'xpos': 'VBG', 'head': 15, 'deprel': 'case', 'misc': 'start_char=64|end_char=73', 'children': []}\n",
      "{'id': 14, 'text': 'simply', 'lemma': 'simply', 'upos': 'ADV', 'xpos': 'RB', 'head': 15, 'deprel': 'advmod', 'misc': 'start_char=74|end_char=80', 'children': []}\n",
      "{'id': 15, 'text': 'solving', 'lemma': 'solve', 'upos': 'VERB', 'xpos': 'VBG', 'head': 12, 'deprel': 'acl', 'misc': 'start_char=81|end_char=88', 'children': [13, 14, 17]}\n",
      "{'id': 16, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 17, 'deprel': 'case', 'misc': 'start_char=89|end_char=92', 'children': []}\n",
      "{'id': 17, 'text': 'each', 'lemma': 'each', 'upos': 'DET', 'xpos': 'DT', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=93|end_char=97', 'children': [16, 20]}\n",
      "{'id': 18, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 20, 'deprel': 'case', 'misc': 'start_char=98|end_char=100', 'children': []}\n",
      "{'id': 19, 'text': 'these', 'lemma': 'these', 'upos': 'DET', 'xpos': 'DT', 'head': 20, 'deprel': 'det', 'misc': 'start_char=101|end_char=106', 'children': []}\n",
      "{'id': 20, 'text': 'coefficients', 'lemma': 'coefficient', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 17, 'deprel': 'nmod', 'misc': 'start_char=107|end_char=119', 'children': [18, 19]}\n",
      "{'id': 21, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 22, 'deprel': 'cc', 'misc': 'start_char=120|end_char=122', 'children': []}\n",
      "{'id': 22, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 8, 'deprel': 'conj', 'misc': 'start_char=123|end_char=128', 'children': [21, 23, 39]}\n",
      "{'id': 23, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=129|end_char=136', 'children': [27]}\n",
      "{'id': 24, 'text': 'such', 'lemma': 'such', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 27, 'deprel': 'case', 'misc': 'start_char=137|end_char=141', 'children': [25]}\n",
      "{'id': 25, 'text': 'as', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 24, 'deprel': 'fixed', 'misc': 'start_char=142|end_char=144', 'children': []}\n",
      "{'id': 26, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 27, 'deprel': 'det', 'misc': 'start_char=145|end_char=148', 'children': []}\n",
      "{'id': 27, 'text': 'Levinson', 'lemma': 'levinson', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 23, 'deprel': 'nmod', 'misc': 'start_char=149|end_char=157', 'children': [24, 26, 28, 29, 30, 34, 38, 40]}\n",
      "{'id': 28, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 27, 'deprel': 'punct', 'misc': 'start_char=158|end_char=159', 'children': []}\n",
      "{'id': 29, 'text': 'Wiggins', 'lemma': 'wiggin', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=160|end_char=167', 'children': []}\n",
      "{'id': 30, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 27, 'deprel': 'punct', 'misc': 'start_char=168|end_char=169', 'children': []}\n",
      "{'id': 31, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 34, 'deprel': 'cc', 'misc': 'start_char=170|end_char=173', 'children': []}\n",
      "{'id': 32, 'text': 'Robertson', 'lemma': 'robertson', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'nmod:poss', 'misc': 'start_char=174|end_char=183', 'children': []}\n",
      "{'id': 33, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 34, 'deprel': 'case', 'misc': 'start_char=184|end_char=186', 'children': []}\n",
      "{'id': 34, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=187|end_char=193', 'children': [31, 32, 33]}\n",
      "{'id': 35, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 38, 'deprel': 'cc', 'misc': 'start_char=194|end_char=196', 'children': []}\n",
      "{'id': 36, 'text': 'Morf', 'lemma': 'morf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 38, 'deprel': 'nmod:poss', 'misc': 'start_char=197|end_char=201', 'children': []}\n",
      "{'id': 37, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 38, 'deprel': 'case', 'misc': 'start_char=202|end_char=204', 'children': []}\n",
      "{'id': 38, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 27, 'deprel': 'conj', 'misc': 'start_char=205|end_char=211', 'children': [35, 36, 37]}\n",
      "{'id': 39, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 22, 'deprel': 'punct', 'misc': 'start_char=212|end_char=213', 'children': []}\n",
      "{'id': 40, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 27, 'deprel': 'acl', 'misc': 'start_char=214|end_char=218', 'children': [43]}\n",
      "{'id': 41, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 43, 'deprel': 'case', 'misc': 'start_char=219|end_char=222', 'children': []}\n",
      "{'id': 42, 'text': 'this', 'lemma': 'this', 'upos': 'DET', 'xpos': 'DT', 'head': 43, 'deprel': 'det', 'misc': 'start_char=223|end_char=227', 'children': []}\n",
      "{'id': 43, 'text': 'analysis', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'obl', 'misc': 'start_char=228|end_char=236', 'children': [41, 42]}\n",
      "{'id': 44, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 2, 'deprel': 'punct', 'misc': 'start_char=237|end_char=238', 'children': []}\n",
      "There are several methods that can be used to solve this matrix including simply solving for each of these coefficients or using methods such as the Levinson , Wiggins , and Robertson 's method or Morf 's method , used for this analysis .\n",
      "{5: \"Morf 's method\"}\n",
      "Rule 5: Morf 's method\n",
      "\n",
      "\n",
      "\n",
      "Plasma viral load was measured by the California Department of Health Services , Viral and Rickettsial Disease Laboratory using the Roche COBAS HIV-1 Monitor v1.5 test .\n",
      "{4: 'Roche COBAS HIV-1 Monitor test'}\n",
      "Rule 4: Roche COBAS HIV-1 Monitor test\n",
      "\n",
      "\n",
      "\n",
      "Based on this property , a cloning strategy called ‘Golden Gate’ cloning was devised that allows to obtain in one tube and one step close to one hundred percent correct recombinant plasmids after just a 5 minute restriction-ligation .\n",
      "{4: 'cloning strategy'}\n",
      "Rule 4: cloning strategy\n",
      "\n",
      "\n",
      "\n",
      "We modified DNA library preparation for the Illumina Genome Analyzer to allow the small amounts of ChIP-enriched DNA to be simultaneously used on both commercially available microarrays and Illumina sequencers .\n",
      "{4: 'DNA library preparation'}\n",
      "Rule 4: DNA library preparation\n",
      "\n",
      "\n",
      "\n",
      "To check the role of dendritic convergence in shaping network architecture , we adopted the ‘Economical Small World Network ’ analysis .\n",
      "{2: '‘Economical Small World Network ’ analysis', 4: 'World Network ’ analysis'}\n",
      "Rule 2: ‘Economical Small World Network ’ analysis\n",
      "\n",
      "\n",
      "\n",
      "In brief , spectral changes in oscillatory activity were analysed by means of Morlet wavelet analysis .\n",
      "{4: 'Morlet wavelet analysis'}\n",
      "Rule 4: Morlet wavelet analysis\n",
      "\n",
      "\n",
      "\n",
      "The spatial scan statistic was used to identify clusters of high WNv incidence within the study area .\n",
      "{2: 'spatial scan statistic', 4: 'scan statistic'}\n",
      "Rule 2: spatial scan statistic\n",
      "\n",
      "\n",
      "\n",
      "The comparative threshold cycle method was used to calculate the relative concentrations .\n",
      "{2: 'comparative threshold cycle method', 4: 'threshold cycle method'}\n",
      "Rule 2: comparative threshold cycle method\n",
      "\n",
      "\n",
      "\n",
      "The proposed procedure is based on an atlas-based cortical registration method using the curvature information , i.e. sulcus and gyrus .\n",
      "{2: 'atlas-based cortical registration method', 4: 'registration method'}\n",
      "Rule 2: atlas-based cortical registration method\n",
      "\n",
      "\n",
      "\n",
      "Though a quantitative trait linkage method , this model is also applicable for binary traits such as TB and PTST- .\n",
      "{2: 'quantitative trait linkage method', 4: 'trait linkage method'}\n",
      "Rule 2: quantitative trait linkage method\n",
      "\n",
      "\n",
      "\n",
      "To address the issue of a small sample size , we also utilized a multi-subject conjunction analysis to examine functional imaging data obtained from the piano improvisation experiments .\n",
      "{2: 'multi-subject conjunction analysis', 4: 'conjunction analysis'}\n",
      "Rule 2: multi-subject conjunction analysis\n",
      "\n",
      "\n",
      "\n",
      "The MLST method was developed by Dingle et al , to characterize C. jejuni strains and to identify clonal lineages in this species .\n",
      "{4: 'MLST method'}\n",
      "Rule 4: MLST method\n",
      "\n",
      "\n",
      "\n",
      "A sub-sample of 90 subjects was first used to confirm the reproducibility and validity of a novel measurement technique in DXA total body analysis-linear pixel count .\n",
      "{2: 'novel measurement technique', 4: 'measurement technique'}\n",
      "Rule 2: novel measurement technique\n",
      "\n",
      "\n",
      "\n",
      "To describe the biochemical reactions and connectivity of signaling molecules in this study , we adopted a deterministic ordinary differential equation model .\n",
      "{2: 'deterministic ordinary differential equation model', 4: 'equation model'}\n",
      "Rule 2: deterministic ordinary differential equation model\n",
      "\n",
      "\n",
      "\n",
      "The tissue-specific behavior of gene groups was visualized by multidimensional unfolding analysis .\n",
      "{2: 'multidimensional unfolding analysis', 4: 'unfolding analysis'}\n",
      "Rule 2: multidimensional unfolding analysis\n",
      "\n",
      "\n",
      "\n",
      "We present here a compositional imaging approach for the analysis and display of multi-component compositions .\n",
      "{2: 'compositional imaging approach', 4: 'imaging approach'}\n",
      "Rule 2: compositional imaging approach\n",
      "\n",
      "\n",
      "\n",
      "For the current implementation we use an adaptation of the ISODATA method to compute a local threshold at each node along the dendritic model .\n",
      "{4: 'ISODATA method'}\n",
      "Rule 4: ISODATA method\n",
      "\n",
      "\n",
      "\n",
      "Data for each malaria-related phenotype were first analysed using multivariate regression analysis according to the distribution of the data .\n",
      "{2: 'multivariate regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: multivariate regression analysis\n",
      "\n",
      "\n",
      "\n",
      "We used a previously described siRNA strategy to investigate the role of PKCι depletion in polyglutamine-induced cytotoxicity .\n",
      "{2: 'described siRNA strategy', 4: 'siRNA strategy'}\n",
      "Rule 2: described siRNA strategy\n",
      "\n",
      "\n",
      "\n",
      "This hypothesis was tested by adapting a time lapse microscopy method which we had developed , recently .\n",
      "{4: 'time lapse microscopy method'}\n",
      "Rule 4: time lapse microscopy method\n",
      "\n",
      "\n",
      "\n",
      "Our results show that this tag SNP method is very accurate and provides an excellent basis for population screening for CD .\n",
      "{4: 'tag SNP method'}\n",
      "Rule 4: tag SNP method\n",
      "\n",
      "\n",
      "\n",
      "Reinton et al. developed a real-time PCR method for detecting CD-associated HLA risk alleles .\n",
      "{2: 'real-time PCR method', 4: 'PCR method'}\n",
      "Rule 2: real-time PCR method\n",
      "\n",
      "\n",
      "\n",
      "To this aim , we have engineered viral particles containing IN fused to the Enhanced Cyan / Green Fluorescent Protein through the “trans-incorporation” technique .\n",
      "{4: '“trans-incorporation” technique'}\n",
      "Rule 4: “trans-incorporation” technique\n",
      "\n",
      "\n",
      "\n",
      "This approach confirmed the association between rs512625 and psoriasis with a protective effect in heterozygotes as found before with the regression approach .\n",
      "{4: 'regression approach'}\n",
      "Rule 4: regression approach\n",
      "\n",
      "\n",
      "\n",
      "FT is a noninvasive blood test that combines the quantitative results of 6 serum biochemical markers , [ alpha2-macroglobulin , haptoglobin , gamma glutamyl transpeptidase , total bilirubin , apolipoprotein A1 and alanine amino transferase ] with patient age and sex data in a patented artificial intelligence algorithm to generate a measure of fibrosis and necroinflammatory activity in the liver .\n",
      "{2: 'patented artificial intelligence algorithm', 4: 'intelligence algorithm'}\n",
      "Rule 2: patented artificial intelligence algorithm\n",
      "\n",
      "\n",
      "\n",
      "The Preece-Baines model is an automated mathematical method for describing normal growth from a given age before adolescence until adulthood .\n",
      "{4: 'Preece-Baines model'}\n",
      "Rule 4: Preece-Baines model\n",
      "\n",
      "\n",
      "\n",
      "We describe a standardized sample preparation and analytical procedure for easy bacterial classification and identification by MALDI mass spectrometry detection of protein mass patterns .\n",
      "{2: 'standardized sample preparation', 4: 'sample preparation'}\n",
      "Rule 2: standardized sample preparation\n",
      "\n",
      "\n",
      "\n",
      "To assess a pattern-wise comparison , an exact F test was finally carried out to get a P value from the PCA transformation .\n",
      "{2: 'exact F test', 4: 'F test'}\n",
      "Rule 2: exact F test\n",
      "\n",
      "\n",
      "\n",
      "Haplotype analysis was performed using the THESIAS software based on the SEM algorithm .\n",
      "{4: 'Haplotype analysis'}\n",
      "Rule 4: Haplotype analysis\n",
      "\n",
      "\n",
      "\n",
      "Haplotype analysis was performed using the THESIAS software based on the SEM algorithm .\n",
      "{4: 'SEM algorithm'}\n",
      "Rule 4: SEM algorithm\n",
      "\n",
      "\n",
      "\n",
      "We used the method developed by Stekel et al. for comparing digital expression patterns , and calculated a R statistic for each cluster , using an in-house program available upon request .\n",
      "{4: 'R statistic'}\n",
      "Rule 4: R statistic\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 2, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'outcomes', 'lemma': 'outcome', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 8, 'deprel': 'nsubj:pass', 'misc': 'start_char=4|end_char=12', 'children': [1, 6]}\n",
      "{'id': 3, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 6, 'deprel': 'case', 'misc': 'start_char=13|end_char=15', 'children': []}\n",
      "{'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 6, 'deprel': 'det', 'misc': 'start_char=16|end_char=19', 'children': []}\n",
      "{'id': 5, 'text': 'agonistic', 'lemma': 'agonistic', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 6, 'deprel': 'amod', 'misc': 'start_char=20|end_char=29', 'children': []}\n",
      "{'id': 6, 'text': 'interactions', 'lemma': 'interaction', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=30|end_char=42', 'children': [3, 4, 5]}\n",
      "{'id': 7, 'text': 'were', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 8, 'deprel': 'aux:pass', 'misc': 'start_char=43|end_char=47', 'children': []}\n",
      "{'id': 8, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=48|end_char=52', 'children': [2, 7, 10, 24]}\n",
      "{'id': 9, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 10, 'deprel': 'mark', 'misc': 'start_char=53|end_char=55', 'children': []}\n",
      "{'id': 10, 'text': 'calculate', 'lemma': 'calculate', 'upos': 'VERB', 'xpos': 'VB', 'head': 8, 'deprel': 'xcomp', 'misc': 'start_char=56|end_char=65', 'children': [9, 13, 18]}\n",
      "{'id': 11, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 13, 'deprel': 'det', 'misc': 'start_char=66|end_char=69', 'children': []}\n",
      "{'id': 12, 'text': 'dominance', 'lemma': 'dominance', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'compound', 'misc': 'start_char=70|end_char=79', 'children': []}\n",
      "{'id': 13, 'text': 'rank', 'lemma': 'rank', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'obj', 'misc': 'start_char=80|end_char=84', 'children': [11, 12, 16]}\n",
      "{'id': 14, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 16, 'deprel': 'case', 'misc': 'start_char=85|end_char=87', 'children': []}\n",
      "{'id': 15, 'text': 'each', 'lemma': 'each', 'upos': 'DET', 'xpos': 'DT', 'head': 16, 'deprel': 'det', 'misc': 'start_char=88|end_char=92', 'children': []}\n",
      "{'id': 16, 'text': 'male', 'lemma': 'male', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'nmod', 'misc': 'start_char=93|end_char=97', 'children': [14, 15]}\n",
      "{'id': 17, 'text': 'by', 'lemma': 'by', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 18, 'deprel': 'mark', 'misc': 'start_char=98|end_char=100', 'children': []}\n",
      "{'id': 18, 'text': 'applying', 'lemma': 'apply', 'upos': 'VERB', 'xpos': 'VBG', 'head': 10, 'deprel': 'advcl', 'misc': 'start_char=101|end_char=109', 'children': [17, 23]}\n",
      "{'id': 19, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 23, 'deprel': 'det', 'misc': 'start_char=110|end_char=113', 'children': []}\n",
      "{'id': 20, 'text': 'David', 'lemma': 'david', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'nmod:poss', 'misc': 'start_char=114|end_char=119', 'children': [21]}\n",
      "{'id': 21, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 20, 'deprel': 'case', 'misc': 'start_char=120|end_char=122', 'children': []}\n",
      "{'id': 22, 'text': 'score', 'lemma': 'score', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'compound', 'misc': 'start_char=123|end_char=128', 'children': []}\n",
      "{'id': 23, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'obj', 'misc': 'start_char=129|end_char=135', 'children': [19, 20, 22]}\n",
      "{'id': 24, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 8, 'deprel': 'punct', 'misc': 'start_char=136|end_char=137', 'children': []}\n",
      "The outcomes of the agonistic interactions were used to calculate the dominance rank of each male by applying the David 's score method .\n",
      "{4: 'score method', 5: \"David 's score method\"}\n",
      "Rule 5: David 's score method\n",
      "\n",
      "\n",
      "\n",
      "To circumvent this problem , we previously developed the cortical box method to analyze c-fos immunoreactivity , which we now applied to the analysis of ISH data .\n",
      "{2: 'cortical box method', 4: 'box method'}\n",
      "Rule 2: cortical box method\n",
      "\n",
      "\n",
      "\n",
      "For two-sided MADe method , considering gene k , either if Dk , m = Mk+Ck or if Dk , m = Mk−Ck , gene k will be selected as sample-level differentiated gene for sample m , where sample m is one of the selected samples in the dataset .\n",
      "{2: 'two-sided MADe method', 4: 'MADe method'}\n",
      "Rule 2: two-sided MADe method\n",
      "\n",
      "\n",
      "\n",
      "Multiple component analysis was performed on data collected from 62 patients using SPAD software .\n",
      "{2: 'Multiple component analysis', 4: 'component analysis'}\n",
      "Rule 2: Multiple component analysis\n",
      "\n",
      "\n",
      "\n",
      "Divergence times were estimated using a multiple calibration Bayesian approach with the MULTIDISTRIBUTE program package version 09.25.03 .\n",
      "{2: 'multiple calibration Bayesian approach', 4: 'calibration approach'}\n",
      "Rule 2: multiple calibration Bayesian approach\n",
      "\n",
      "\n",
      "\n",
      "ED analysis reduces the dimensionality of the covariance matrix by diagonalization .\n",
      "{4: 'ED analysis'}\n",
      "Rule 4: ED analysis\n",
      "\n",
      "\n",
      "\n",
      "The LFQP approach is rapid and more sensitive than many other proteomic methods , and it increases the protein dynamic range 3- to 4-fold as compared to 2D-PAGE .\n",
      "{4: 'LFQP approach'}\n",
      "Rule 4: LFQP approach\n",
      "\n",
      "\n",
      "\n",
      "The particle filter model outlined here attempts to improve the quality of tracking data while operating by a framework that is both accessible and efficient .\n",
      "{4: 'particle filter model'}\n",
      "Rule 4: particle filter model\n",
      "\n",
      "\n",
      "\n",
      "Subsequent isolation of the shRNA inserts and sequence analysis was required to identify the shRNA responsible for the bypass of the p53 mediated cell cycle arrest .\n",
      "{4: 'sequence analysis'}\n",
      "Rule 4: sequence analysis\n",
      "\n",
      "\n",
      "\n",
      "A novel identification method for identifying transcription start sites that improves the accuracy of TSS recognition for recently published methods is proposed .\n",
      "{2: 'novel identification method', 4: 'identification method'}\n",
      "Rule 2: novel identification method\n",
      "\n",
      "\n",
      "\n",
      "We overcome this problem by considering a generalization of the LS-algorithm , the term-order-free reverse engineering method .\n",
      "{2: 'term-order-free reverse engineering method', 4: 'engineering method'}\n",
      "Rule 2: term-order-free reverse engineering method\n",
      "\n",
      "\n",
      "\n",
      "Principle Components Analysis , using the Partek Genomics Suite , was performed to confirm the relatedness of data sets .\n",
      "{4: 'Principle Components Analysis'}\n",
      "Rule 4: Principle Components Analysis\n",
      "\n",
      "\n",
      "\n",
      "Association analyses using the Armitage trend test .\n",
      "{4: 'Armitage trend test'}\n",
      "Rule 4: Armitage trend test\n",
      "\n",
      "\n",
      "\n",
      "The LDD test identifies alleles undergoing selection by searching for an expected increase with distance in the fraction of inferred recombinant chromosomes surrounding a selected variant .\n",
      "{4: 'LDD test'}\n",
      "Rule 4: LDD test\n",
      "\n",
      "\n",
      "\n",
      "To assess damage to DNA , we used the Long-extension PCR technique .\n",
      "{2: 'Long-extension PCR technique', 4: 'PCR technique'}\n",
      "Rule 2: Long-extension PCR technique\n",
      "\n",
      "\n",
      "\n",
      "Previously , our laboratory reported on the development of an assay for BoNT detection and serotype differentiation termed the Endopep-MS method .\n",
      "{4: 'Endopep-MS method'}\n",
      "Rule 4: Endopep-MS method\n",
      "\n",
      "\n",
      "\n",
      "RP is a non-parametric statistical method which has demonstrated robustness in microarray analysis and has been shown to have a higher sensitivity and selectivity in comparison with t-test based statistical methods .\n",
      "{4: 'microarray analysis'}\n",
      "Rule 4: microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "The fractional cycle number at which the fluorescence passes the fixed threshold was used for quantification by using a comparative CT method .\n",
      "{2: 'comparative CT method', 4: 'CT method'}\n",
      "Rule 2: comparative CT method\n",
      "\n",
      "\n",
      "\n",
      "Another mapping strategy is “genome-wide linkage approach” .\n",
      "{4: 'mapping strategy'}\n",
      "Rule 4: mapping strategy\n",
      "\n",
      "\n",
      "\n",
      "Biomarker discovery by LC / MS / MS based method was reproducible as previously documented .\n",
      "{2: 'LC / MS / MS based method', 4: 'LC / MS / MS method'}\n",
      "Rule 2: LC / MS / MS based method\n",
      "\n",
      "\n",
      "\n",
      "To assign multiple labels to a given set of sequences , we employed the training method used for gene detection in Drosophila .\n",
      "{4: 'training method'}\n",
      "Rule 4: training method\n",
      "\n",
      "\n",
      "\n",
      "Additionally , a separate assessment technique , TSVMod , was applied .\n",
      "{2: 'separate assessment technique', 4: 'assessment technique'}\n",
      "Rule 2: separate assessment technique\n",
      "\n",
      "\n",
      "\n",
      "All weights were determined using the Simulated Tempering Equal Acceptance Ratio method .\n",
      "{2: 'Simulated Tempering Equal Acceptance Ratio method', 4: 'Tempering Equal Acceptance Ratio method'}\n",
      "Rule 2: Simulated Tempering Equal Acceptance Ratio method\n",
      "\n",
      "\n",
      "\n",
      "All weights were determined using the Simulated Tempering Equal Acceptance Ratio method .\n",
      "{2: 'Simulated Tempering Equal Acceptance Ratio method', 4: 'Tempering Equal Acceptance Ratio method'}\n",
      "Rule 2: Simulated Tempering Equal Acceptance Ratio method\n",
      "\n",
      "\n",
      "\n",
      "Our explorations were motivated by a desire to predict protein interaction networks using the evolutionary correlation method .\n",
      "{2: 'evolutionary correlation method', 4: 'correlation method'}\n",
      "Rule 2: evolutionary correlation method\n",
      "\n",
      "\n",
      "\n",
      "The sliding window approach , on the other hand , is novel but independent of previous annotations .\n",
      "{2: 'sliding window approach', 4: 'window approach'}\n",
      "Rule 2: sliding window approach\n",
      "\n",
      "\n",
      "\n",
      "Therefore , we employed a sensitive qRT-PCR approach for the direct assessment of pathogen gene expression in vivo .\n",
      "{2: 'sensitive qRT-PCR approach', 4: 'qRT-PCR approach'}\n",
      "Rule 2: sensitive qRT-PCR approach\n",
      "\n",
      "\n",
      "\n",
      "We developed a fractionation method to isolate intact BCVs from infected BHK-21 cells .\n",
      "{4: 'fractionation method'}\n",
      "Rule 4: fractionation method\n",
      "\n",
      "\n",
      "\n",
      "We developed an in silico screening method that incorporates experiment- and informatics-derived evidence for a more reliable prediction of PPREs and PPAR target genes .\n",
      "{2: 'in silico screening method', 4: 'screening method'}\n",
      "Rule 2: in silico screening method\n",
      "\n",
      "\n",
      "\n",
      "A T2 relaxometry method that received FDA approval for clinical liver iron estimation has recently been developed by St. Pierre et al. .\n",
      "{4: 'T2 relaxometry method'}\n",
      "Rule 4: T2 relaxometry method\n",
      "\n",
      "\n",
      "\n",
      "A cluster analysis technique , which made use of the qualitative nature of the data , was used to cluster similar items .\n",
      "{4: 'cluster analysis technique'}\n",
      "Rule 4: cluster analysis technique\n",
      "\n",
      "\n",
      "\n",
      "Based on the optimal properties for VIGS inserts defined by the above experiments , we developed a cDNA library synthesis method suitable for constructing VIGS libraries .\n",
      "{2: 'cDNA library synthesis method suitable method', 4: 'cDNA library synthesis method'}\n",
      "Rule 2: cDNA library synthesis method suitable method\n",
      "\n",
      "\n",
      "\n",
      "The Brass Growth Balance method was first applied to provincial data to correct for undercount of adult deaths .\n",
      "{4: 'Brass Growth Balance method'}\n",
      "Rule 4: Brass Growth Balance method\n",
      "\n",
      "\n",
      "\n",
      "The spike detection algorithm used an adaptive combination of level and edge detection mechanisms that allowed it to detect events of varying shape and amplitude .\n",
      "{4: 'spike detection algorithm'}\n",
      "Rule 4: spike detection algorithm\n",
      "\n",
      "\n",
      "\n",
      "The other measurement , which is considered by many to be the “gold standard , ” is the measurement of urinary nicotine and metabolites from 24-h urine samples without creatinine normalization .\n",
      "{4: 'creatinine normalization'}\n",
      "Rule 4: creatinine normalization\n",
      "\n",
      "\n",
      "\n",
      "Data analysis was performed using Lightcycler™ Second Derivatives Method software .\n",
      "{4: 'Data analysis'}\n",
      "Rule 4: Data analysis\n",
      "\n",
      "\n",
      "\n",
      "For mouse samples the relative quantification method was used .\n",
      "{2: 'relative quantification method', 4: 'quantification method'}\n",
      "Rule 2: relative quantification method\n",
      "\n",
      "\n",
      "\n",
      "For the BAL protein phenotype , three additional SSLPs on chromosome 1 were analyzed , and a permutation test was performed with only chromosome 1 .\n",
      "{4: 'permutation test'}\n",
      "Rule 4: permutation test\n",
      "\n",
      "\n",
      "\n",
      "A haplotype analysis was carried out similar to that done previously by Prows and Leikauf to determine the contribution of each QTL and QTL combination to the overall BAL protein phenotype .\n",
      "{4: 'haplotype analysis'}\n",
      "Rule 4: haplotype analysis\n",
      "\n",
      "\n",
      "\n",
      "Although the regression analysis was post hoc , the a priori intent had been to investigate the proportions of patients improving or deteriorating by categorizing the changes in AQLQ , following the suggestion that this may help with interpreting the importance of HRQoL results at an individual patient level .\n",
      "{4: 'regression analysis'}\n",
      "Rule 4: regression analysis\n",
      "\n",
      "\n",
      "\n",
      "Multiple linear regression analysis with an interaction term was used to establish the statistical significances of differences in terms of genotype and cigarette smoke exposure for each parameter .\n",
      "{2: 'Multiple linear regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: Multiple linear regression analysis\n",
      "\n",
      "\n",
      "\n",
      "A differential cell count was performed using a Beckman-Coulter Act5diff haematology analyzer to determine total cell number and the purity of the cell preparation .\n",
      "{4: 'cell preparation'}\n",
      "Rule 4: cell preparation\n",
      "\n",
      "\n",
      "\n",
      "A differential cell count was performed using a Beckman-Coulter Act5diff haematology analyzer to determine total cell number and the purity of the cell preparation .\n",
      "{4: 'cell preparation'}\n",
      "Rule 4: cell preparation\n",
      "\n",
      "\n",
      "\n",
      "A differential cell count was performed using a Beckman-Coulter Act5diff haematology analyzer to determine total cell number and the purity of the cell preparation .\n",
      "{4: 'cell preparation'}\n",
      "Rule 4: cell preparation\n",
      "\n",
      "\n",
      "\n",
      "The codeML method uses the codon as a unit of evolution as opposed to a nucleotide , and thus allows us to estimate the percentage of positions that are being positively selected instead of averaging the rates of positive selection over the entire gene .\n",
      "{4: 'codeML method'}\n",
      "Rule 4: codeML method\n",
      "\n",
      "\n",
      "\n",
      "However other methodologies such as fluorescence analysis or RNA measurement do not allow for the selection of stable , non-transient gene expression .\n",
      "{4: 'fluorescence analysis'}\n",
      "Rule 4: fluorescence analysis\n",
      "\n",
      "\n",
      "\n",
      "The genomic locations of the proviral integrations were determined using the splinkerette-based PCR method .\n",
      "{2: 'splinkerette-based PCR method', 4: 'PCR method'}\n",
      "Rule 2: splinkerette-based PCR method\n",
      "\n",
      "\n",
      "\n",
      "The length polymorphism analysis of 3 ' BLV flanking sequences was performed by making a run-off .\n",
      "{4: 'length polymorphism analysis'}\n",
      "Rule 4: length polymorphism analysis\n",
      "\n",
      "\n",
      "\n",
      "Microarray signal normalization was performed using the \" median-normalization \" procedure .\n",
      "{4: 'Microarray signal normalization'}\n",
      "Rule 4: Microarray signal normalization\n",
      "\n",
      "\n",
      "\n",
      "The length polymorphism analysis of 3 ' BLV flanking sequences was performed by making a run-off .\n",
      "{4: 'length polymorphism analysis'}\n",
      "Rule 4: length polymorphism analysis\n",
      "\n",
      "\n",
      "\n",
      "Our qPCR approach indicates the presence of a dynamic SRB community in these extreme ecosystems , with seasonal fluctuations related to temperature changes and to pronounced waste disposal incidents .\n",
      "{4: 'qPCR approach'}\n",
      "Rule 4: qPCR approach\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "We conducted a survival analysis based upon Cox regression as a substitute for logistic regression .\n",
      "{4: 'survival analysis'}\n",
      "Rule 4: survival analysis\n",
      "\n",
      "\n",
      "\n",
      "DNA isolation , for the selection of relevant BC5S2 progenies , was performed by a rapid alkaline based extraction method .\n",
      "{4: 'extraction method'}\n",
      "Rule 4: extraction method\n",
      "\n",
      "\n",
      "\n",
      "First , to the co-dominant genotypes we applied the Bayesian clustering method implemented in the Structure 2.1 package .\n",
      "{2: 'Bayesian clustering method', 4: 'clustering method'}\n",
      "Rule 2: Bayesian clustering method\n",
      "\n",
      "\n",
      "\n",
      "The methods of categorical data analysis and logistic regression are described in many texts on statistics , for example .\n",
      "{2: 'categorical data analysis', 4: 'data analysis'}\n",
      "Rule 2: categorical data analysis\n",
      "\n",
      "\n",
      "\n",
      "In response to the above , and a set of concerns from prior experimental work , the intraplex method was developed .\n",
      "{4: 'intraplex method'}\n",
      "Rule 4: intraplex method\n",
      "\n",
      "\n",
      "\n",
      "A novel cloning method for the design and production of specific , high-affinity-reacting proteins is presented .\n",
      "{2: 'novel cloning method', 4: 'cloning method'}\n",
      "Rule 2: novel cloning method\n",
      "\n",
      "\n",
      "\n",
      "The model will be validated by comparing its behavior to that of in-vivo organ-directed experiments using the established pattern oriented method described by Grimm et al. .\n",
      "{2: 'established pattern oriented method', 4: 'pattern method'}\n",
      "Rule 2: established pattern oriented method\n",
      "\n",
      "\n",
      "\n",
      "Specifically , we used a freely available and easy to use exploratory regression technique to predict 30-day mortality following stroke in a rural Indian population and compared the accuracy of the technique with these existing stroke scales , resulting in more accurate prediction than the existing scores .\n",
      "{2: 'exploratory regression technique', 4: 'regression technique'}\n",
      "Rule 2: exploratory regression technique\n",
      "\n",
      "\n",
      "\n",
      "Cross-validation is a technique that has been used to determine the best fit model given a particular dataset .\n",
      "{2: 'best fit model', 4: 'fit model'}\n",
      "Rule 2: best fit model\n",
      "\n",
      "\n",
      "\n",
      "The second genotyping method was Taqman .\n",
      "{2: 'second genotyping method', 4: 'genotyping method'}\n",
      "Rule 2: second genotyping method\n",
      "\n",
      "\n",
      "\n",
      "Known as a \" shotgun \" approach , the membrane- and core-enriched fractions were directly digested with trypsin , and analyzed using LC-ESI-Q-TOF MS .\n",
      "{4: 'shotgun approach'}\n",
      "Rule 4: shotgun approach\n",
      "\n",
      "\n",
      "\n",
      "Tests of heterogeneous synonymous substitution rates among sites were performed using the REL analysis implemented in the HYPHY phylogenetic package .\n",
      "{4: 'REL analysis'}\n",
      "Rule 4: REL analysis\n",
      "\n",
      "\n",
      "\n",
      "For the small datasets we additionally ran a random effects likelihood analysis using an empirical Bayes approach with NJ phylogenetic trees in Datamonkey .\n",
      "{2: 'random effects likelihood analysis', 4: 'effects likelihood analysis'}\n",
      "Rule 2: random effects likelihood analysis\n",
      "\n",
      "\n",
      "\n",
      "For the small datasets we additionally ran a random effects likelihood analysis using an empirical Bayes approach with NJ phylogenetic trees in Datamonkey .\n",
      "{2: 'empirical Bayes approach', 4: 'Bayes approach'}\n",
      "Rule 2: empirical Bayes approach\n",
      "\n",
      "\n",
      "\n",
      "SLAC is a counting method that , given a set of input sequences , an associated phylogeny and a codon based substitution model , involves counting the number of synonymous and non-synonymous changes that occur at a given site .\n",
      "{4: 'codon based substitution model'}\n",
      "Rule 4: codon based substitution model\n",
      "\n",
      "\n",
      "\n",
      "To obtain additional statistical data on differential selection signals detectable in our AI and CI datasets , we used the relative effects likelihood based PARRIS selection analysis method .\n",
      "{4: 'PARRIS selection analysis method'}\n",
      "Rule 4: PARRIS selection analysis method\n",
      "\n",
      "\n",
      "\n",
      "The second in vitro ligation approach to generate CRAds without HR was developed by Danthinne .\n",
      "{2: 'second in vitro ligation approach', 4: 'ligation approach'}\n",
      "Rule 2: second in vitro ligation approach\n",
      "\n",
      "\n",
      "\n",
      "When all these different practical refinements are combined , the final result is a molecular diagnostic method that is not only rapid and reliable , but one that is also easy to perform and applicable to use for testing large numbers of samples since the FQ-PCR presented the benefits of increased speed due to reduced cycle time and remove of post-amplification process , offering considerable labor savings and allowing higher throughput analysis than conventional PCR assays and thus is favorable for the transition of this method from research to routine use in laboratories .\n",
      "{2: 'higher throughput analysis', 4: 'throughput analysis'}\n",
      "Rule 2: higher throughput analysis\n",
      "\n",
      "\n",
      "\n",
      "The 26 risk factors were chosen by the authors and weighted arbitrarily from 1 - 4 with , for example , Haemoglobin 10 g / dL scoring 1 and age 80 years scoring 4 .\n",
      "{4: 'dL scoring'}\n",
      "Rule 4: dL scoring\n",
      "\n",
      "\n",
      "\n",
      "The novel development of the DNA microarray technique in 1995 has altered the concepts and assessments of mRNA expression .\n",
      "{4: 'DNA microarray technique'}\n",
      "Rule 4: DNA microarray technique\n",
      "\n",
      "\n",
      "\n",
      "We used a weighting method as described above to combine exposure measurement from different phone types ; NMT = 1 , GSM = 0 , 1 and cordless phones = 0.01 .\n",
      "{4: 'weighting method'}\n",
      "Rule 4: weighting method\n",
      "\n",
      "\n",
      "\n",
      "For instance , since this film method can prepare 2- to 50-µm-thick fresh-frozen sections , section thickness should be modified to reflect the experimental purpose .\n",
      "{4: 'film method'}\n",
      "Rule 4: film method\n",
      "\n",
      "\n",
      "\n",
      "By comparison , approximately 10 positive wells were identified using the more conventional mouse spleen method after three immunization injections .\n",
      "{2: 'conventional mouse spleen method', 4: 'mouse spleen method'}\n",
      "Rule 2: conventional mouse spleen method\n",
      "\n",
      "\n",
      "\n",
      "Diffusion tensor analysis also yields the 3D vector expressed as the component of the x , y , and z dimensions of the diffusion .\n",
      "{4: 'Diffusion tensor analysis'}\n",
      "Rule 4: Diffusion tensor analysis\n",
      "\n",
      "\n",
      "\n",
      "To determine the effect of the different DMARDs on the progression of the DAS28-3 , the HAQ score , and the Larsen score we fitted a population-averaged model by weighted estimating equations nested by patient and visit , using the command GENMOD of SAS / STAT 8.2 for Windows .\n",
      "{4: 'HAQ score'}\n",
      "Rule 4: HAQ score\n",
      "\n",
      "\n",
      "\n",
      "To determine the effect of the different DMARDs on the progression of the DAS28-3 , the HAQ score , and the Larsen score we fitted a population-averaged model by weighted estimating equations nested by patient and visit , using the command GENMOD of SAS / STAT 8.2 for Windows .\n",
      "{4: 'Larsen score'}\n",
      "Rule 4: Larsen score\n",
      "\n",
      "\n",
      "\n",
      "Statistical comparisons of differences in the association of RA status with CAC across subgroups were conducted using the Wald test .\n",
      "{4: 'Wald test'}\n",
      "Rule 4: Wald test\n",
      "\n",
      "\n",
      "\n",
      "The mRNA levels of both sGC subunits were determined by the quantitative RT-PCR technique .\n",
      "{2: 'quantitative RT-PCR technique', 4: 'RT-PCR technique'}\n",
      "Rule 2: quantitative RT-PCR technique\n",
      "\n",
      "\n",
      "\n",
      "In the CoForest algorithm , N random trees are firstly initiated from the bootstrapped training set from the labeled set L to create a random forest .\n",
      "{4: 'CoForest algorithm'}\n",
      "Rule 4: CoForest algorithm\n",
      "\n",
      "\n",
      "\n",
      "Thirdly , a hidden Markov model based module / profile was developed for searching exclusively nuclear and non-nuclear domains in a protein .\n",
      "{2: 'hidden Markov model', 4: 'Markov model'}\n",
      "Rule 2: hidden Markov model\n",
      "\n",
      "\n",
      "\n",
      "As a side experiment , we tested the TC method for the disambiguation of MeSH terms without including the MeSH hand annotations in the automatic annotations provided by GoPubMed , to estimate how the quality of the input influences the quality of the results .\n",
      "{4: 'TC method'}\n",
      "Rule 4: TC method\n",
      "\n",
      "\n",
      "\n",
      "Most recently , Lin et al. developed a greedy haplotyping algorithm that takes advantage of the high density SNP markers .\n",
      "{2: 'greedy haplotyping algorithm', 4: 'haplotyping algorithm'}\n",
      "Rule 2: greedy haplotyping algorithm\n",
      "\n",
      "\n",
      "\n",
      "In parallel , the mixed DMD duplicate profiles were compared to a single pair of mixed control sample profiles , using the pairwise comparison survival method .\n",
      "{2: 'pairwise comparison survival method', 4: 'comparison survival method'}\n",
      "Rule 2: pairwise comparison survival method\n",
      "\n",
      "\n",
      "\n",
      "The similarity score calculated by FASTA can apply to stretches smaller than 80 aa , Allermatch™ converts such a similarity score to an 80 aa window .\n",
      "{4: 'similarity score'}\n",
      "Rule 4: similarity score\n",
      "\n",
      "\n",
      "\n",
      "The similarity score calculated by FASTA can apply to stretches smaller than 80 aa , Allermatch™ converts such a similarity score to an 80 aa window .\n",
      "{2: 'such a similarity score', 4: 'similarity score'}\n",
      "Rule 2: such a similarity score\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DF-SNPs algorithm incorporates the following processes : a two-step approach to impute missing SNPs ; use of 10-fold cross-validation when calculating frequency of SNPs , SNP types and SNP patterns in discriminating cases from controls ; and estimating statistical significance by comparing frequencies from with those from a random test also using 10-fold cross validation .\n",
      "{4: 'DF-SNPs algorithm'}\n",
      "Rule 4: DF-SNPs algorithm\n",
      "\n",
      "\n",
      "\n",
      "A major issue in microarray normalization is the definition of the set of constant probes to which the data are normalized .\n",
      "{4: 'microarray normalization'}\n",
      "Rule 4: microarray normalization\n",
      "\n",
      "\n",
      "\n",
      "After standardizing , the log ratio observations are modeled with a two-component mixture model ; a normal component for those genes that are not differentially expressed and a uniform component for those that are .\n",
      "{2: 'two-component mixture model', 4: 'mixture model'}\n",
      "Rule 2: two-component mixture model\n",
      "\n",
      "\n",
      "\n",
      "The main theoretical issue of array CGH data analysis lies in the estimation of the number of segments that requires the definition of appropriate penalty function and constant .\n",
      "{4: 'array CGH data analysis'}\n",
      "Rule 4: array CGH data analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'In', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 2, 'deprel': 'case', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'addition', 'lemma': 'addition', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'obl', 'misc': 'start_char=3|end_char=11', 'children': [1]}\n",
      "{'id': 3, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 9, 'deprel': 'punct', 'misc': 'start_char=12|end_char=13', 'children': []}\n",
      "{'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 8, 'deprel': 'det', 'misc': 'start_char=14|end_char=17', 'children': []}\n",
      "{'id': 5, 'text': 'Zipf', 'lemma': 'zipf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'nmod:poss', 'misc': 'start_char=18|end_char=22', 'children': [6]}\n",
      "{'id': 6, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 5, 'deprel': 'case', 'misc': 'start_char=23|end_char=25', 'children': []}\n",
      "{'id': 7, 'text': 'law', 'lemma': 'law', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'compound', 'misc': 'start_char=26|end_char=29', 'children': []}\n",
      "{'id': 8, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'nsubj', 'misc': 'start_char=30|end_char=36', 'children': [4, 5, 7]}\n",
      "{'id': 9, 'text': 'produced', 'lemma': 'produce', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=37|end_char=45', 'children': [2, 3, 8, 11, 35, 58]}\n",
      "{'id': 10, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 11, 'deprel': 'compound', 'misc': 'start_char=46|end_char=50', 'children': []}\n",
      "{'id': 11, 'text': 'distributions', 'lemma': 'distribution', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 9, 'deprel': 'obj', 'misc': 'start_char=51|end_char=64', 'children': [10, 15]}\n",
      "{'id': 12, 'text': 'which', 'lemma': 'which', 'upos': 'PRON', 'xpos': 'WDT', 'head': 15, 'deprel': 'nsubj', 'misc': 'start_char=65|end_char=70', 'children': []}\n",
      "{'id': 13, 'text': 'are', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBP', 'head': 15, 'deprel': 'cop', 'misc': 'start_char=71|end_char=74', 'children': []}\n",
      "{'id': 14, 'text': 'more', 'lemma': 'more', 'upos': 'ADV', 'xpos': 'RBR', 'head': 15, 'deprel': 'advmod', 'misc': 'start_char=75|end_char=79', 'children': []}\n",
      "{'id': 15, 'text': 'similar', 'lemma': 'similar', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 11, 'deprel': 'acl:relcl', 'misc': 'start_char=80|end_char=87', 'children': [12, 13, 14, 17]}\n",
      "{'id': 16, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 17, 'deprel': 'case', 'misc': 'start_char=88|end_char=95', 'children': []}\n",
      "{'id': 17, 'text': 'arrays', 'lemma': 'array', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=96|end_char=102', 'children': [16, 18, 24]}\n",
      "{'id': 18, 'text': 'allowing', 'lemma': 'allow', 'upos': 'VERB', 'xpos': 'VBG', 'head': 17, 'deprel': 'acl', 'misc': 'start_char=103|end_char=111', 'children': [21]}\n",
      "{'id': 19, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 21, 'deprel': 'case', 'misc': 'start_char=112|end_char=115', 'children': []}\n",
      "{'id': 20, 'text': 'between-array', 'lemma': 'between-array', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 21, 'deprel': 'amod', 'misc': 'start_char=116|end_char=129', 'children': []}\n",
      "{'id': 21, 'text': 'comparisons', 'lemma': 'comparison', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 18, 'deprel': 'obl', 'misc': 'start_char=130|end_char=141', 'children': [19, 20]}\n",
      "{'id': 22, 'text': 'which', 'lemma': 'which', 'upos': 'PRON', 'xpos': 'WDT', 'head': 24, 'deprel': 'nsubj', 'misc': 'start_char=142|end_char=147', 'children': []}\n",
      "{'id': 23, 'text': 'are', 'lemma': 'be', 'upos': 'VERB', 'xpos': 'VBP', 'head': 24, 'deprel': 'cop', 'misc': 'start_char=148|end_char=151', 'children': []}\n",
      "{'id': 24, 'text': 'advantageous', 'lemma': 'advantageous', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 17, 'deprel': 'acl:relcl', 'misc': 'start_char=152|end_char=164', 'children': [22, 23, 26]}\n",
      "{'id': 25, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 26, 'deprel': 'case', 'misc': 'start_char=165|end_char=167', 'children': []}\n",
      "{'id': 26, 'text': 'terms', 'lemma': 'term', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 24, 'deprel': 'obl', 'misc': 'start_char=168|end_char=173', 'children': [25, 29]}\n",
      "{'id': 27, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 29, 'deprel': 'case', 'misc': 'start_char=174|end_char=176', 'children': []}\n",
      "{'id': 28, 'text': 'both', 'lemma': 'both', 'upos': 'DET', 'xpos': 'DT', 'head': 29, 'deprel': 'det', 'misc': 'start_char=177|end_char=181', 'children': []}\n",
      "{'id': 29, 'text': 'cost', 'lemma': 'cost', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'nmod', 'misc': 'start_char=182|end_char=186', 'children': [27, 28]}\n",
      "{'id': 30, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 35, 'deprel': 'punct', 'misc': 'start_char=187|end_char=188', 'children': []}\n",
      "{'id': 31, 'text': 'because', 'lemma': 'because', 'upos': 'ADP', 'xpos': 'IN', 'head': 35, 'deprel': 'case', 'misc': 'start_char=189|end_char=196', 'children': [32]}\n",
      "{'id': 32, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 31, 'deprel': 'fixed', 'misc': 'start_char=197|end_char=199', 'children': []}\n",
      "{'id': 33, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 35, 'deprel': 'det', 'misc': 'start_char=200|end_char=203', 'children': []}\n",
      "{'id': 34, 'text': 'reduced', 'lemma': 'reduce', 'upos': 'VERB', 'xpos': 'VBN', 'head': 35, 'deprel': 'amod', 'misc': 'start_char=204|end_char=211', 'children': []}\n",
      "{'id': 35, 'text': 'number', 'lemma': 'number', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'obl', 'misc': 'start_char=212|end_char=218', 'children': [30, 31, 33, 34, 37, 43, 47, 48]}\n",
      "{'id': 36, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 37, 'deprel': 'case', 'misc': 'start_char=219|end_char=221', 'children': []}\n",
      "{'id': 37, 'text': 'microarrays', 'lemma': 'microarray', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 35, 'deprel': 'nmod', 'misc': 'start_char=222|end_char=233', 'children': [36, 39]}\n",
      "{'id': 38, 'text': 'that', 'lemma': 'that', 'upos': 'PRON', 'xpos': 'WDT', 'head': 39, 'deprel': 'nsubj', 'misc': 'start_char=234|end_char=238', 'children': []}\n",
      "{'id': 39, 'text': 'need', 'lemma': 'need', 'upos': 'VERB', 'xpos': 'VBP', 'head': 37, 'deprel': 'acl:relcl', 'misc': 'start_char=239|end_char=243', 'children': [38, 42, 45, 50]}\n",
      "{'id': 40, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 42, 'deprel': 'mark', 'misc': 'start_char=244|end_char=246', 'children': []}\n",
      "{'id': 41, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 42, 'deprel': 'aux:pass', 'misc': 'start_char=247|end_char=249', 'children': []}\n",
      "{'id': 42, 'text': 'run', 'lemma': 'run', 'upos': 'VERB', 'xpos': 'VBN', 'head': 39, 'deprel': 'xcomp', 'misc': 'start_char=250|end_char=253', 'children': [40, 41]}\n",
      "{'id': 43, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 35, 'deprel': 'punct', 'misc': 'start_char=254|end_char=255', 'children': []}\n",
      "{'id': 44, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 47, 'deprel': 'cc', 'misc': 'start_char=256|end_char=259', 'children': []}\n",
      "{'id': 45, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 39, 'deprel': 'punct', 'misc': 'start_char=260|end_char=261', 'children': []}\n",
      "{'id': 46, 'text': 'statistical', 'lemma': 'statistical', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 47, 'deprel': 'amod', 'misc': 'start_char=262|end_char=273', 'children': []}\n",
      "{'id': 47, 'text': 'power', 'lemma': 'power', 'upos': 'NOUN', 'xpos': 'NN', 'head': 35, 'deprel': 'conj', 'misc': 'start_char=274|end_char=279', 'children': [44, 46]}\n",
      "{'id': 48, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 35, 'deprel': 'punct', 'misc': 'start_char=280|end_char=281', 'children': []}\n",
      "{'id': 49, 'text': 'by', 'lemma': 'by', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 50, 'deprel': 'mark', 'misc': 'start_char=282|end_char=284', 'children': []}\n",
      "{'id': 50, 'text': 'allowing', 'lemma': 'allow', 'upos': 'VERB', 'xpos': 'VBG', 'head': 39, 'deprel': 'advcl', 'misc': 'start_char=285|end_char=293', 'children': [49, 53]}\n",
      "{'id': 51, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 53, 'deprel': 'case', 'misc': 'start_char=294|end_char=297', 'children': []}\n",
      "{'id': 52, 'text': 'greater', 'lemma': 'greater', 'upos': 'ADJ', 'xpos': 'JJR', 'head': 53, 'deprel': 'amod', 'misc': 'start_char=298|end_char=305', 'children': []}\n",
      "{'id': 53, 'text': 'numbers', 'lemma': 'number', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 50, 'deprel': 'obl', 'misc': 'start_char=306|end_char=313', 'children': [51, 52, 54, 56]}\n",
      "{'id': 54, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 53, 'deprel': 'punct', 'misc': 'start_char=314|end_char=315', 'children': []}\n",
      "{'id': 55, 'text': 'experimental', 'lemma': 'experimental', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 56, 'deprel': 'amod', 'misc': 'start_char=316|end_char=328', 'children': []}\n",
      "{'id': 56, 'text': 'design', 'lemma': 'design', 'upos': 'NOUN', 'xpos': 'NN', 'head': 53, 'deprel': 'appos', 'misc': 'start_char=329|end_char=335', 'children': [55, 57]}\n",
      "{'id': 57, 'text': 'permitting', 'lemma': 'permit', 'upos': 'VERB', 'xpos': 'VBG', 'head': 56, 'deprel': 'acl', 'misc': 'start_char=336|end_char=346', 'children': []}\n",
      "{'id': 58, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 9, 'deprel': 'punct', 'misc': 'start_char=347|end_char=348', 'children': []}\n",
      "In addition , the Zipf 's law method produced data distributions which are more similar between arrays allowing for between-array comparisons which are advantageous in terms of both cost , because of the reduced number of microarrays that need to be run , and , statistical power , by allowing for greater numbers , experimental design permitting .\n",
      "{4: 'law method', 5: \"Zipf 's law method\"}\n",
      "Rule 5: Zipf 's law method\n",
      "\n",
      "\n",
      "\n",
      "To compare RB-KNN to other methods for integrating heterogeneous data , we tested the SVM algorithm proposed in on the same dataset .\n",
      "{4: 'SVM algorithm'}\n",
      "Rule 4: SVM algorithm\n",
      "\n",
      "\n",
      "\n",
      "The PSI-BLAST profile method requires that the target protein first be aligned with orthologous sequences .\n",
      "{4: 'PSI-BLAST profile method'}\n",
      "Rule 4: PSI-BLAST profile method\n",
      "\n",
      "\n",
      "\n",
      "Rhodes et al. combined the results of four prostate cancer studies using a p-value approach .\n",
      "{4: 'p-value approach'}\n",
      "Rule 4: p-value approach\n",
      "\n",
      "\n",
      "\n",
      "Where classification has occurred , the graph of the output from the ROC analysis forms a curve .\n",
      "{4: 'ROC analysis'}\n",
      "Rule 4: ROC analysis\n",
      "\n",
      "\n",
      "\n",
      "After the WT analysis , the padding tags are discarded and the original signal is recovered .\n",
      "{4: 'WT analysis'}\n",
      "Rule 4: WT analysis\n",
      "\n",
      "\n",
      "\n",
      "They evaluated their approach based on different datasets available for Saccharomyces cerevisiae , and showed that their model has better precision than the hierarchical C4.5 model proposed by .\n",
      "{2: 'hierarchical C4.5 model', 4: 'C4.5 model'}\n",
      "Rule 2: hierarchical C4.5 model\n",
      "\n",
      "\n",
      "\n",
      "Moreover , this model would not be easily re-usable for other channel current analysis without significant restructuring and re-tuning .\n",
      "{2: 'other channel current analysis', 4: 'channel analysis'}\n",
      "Rule 2: other channel current analysis\n",
      "\n",
      "\n",
      "\n",
      "The p-value corresponding to a given match score for a transcription factor binding site is the probability of observing a match score at least as great for a randomly generated site .\n",
      "{2: 'given match score', 4: 'match score'}\n",
      "Rule 2: given match score\n",
      "\n",
      "\n",
      "\n",
      "The p-value corresponding to a given match score for a transcription factor binding site is the probability of observing a match score at least as great for a randomly generated site .\n",
      "{4: 'match score'}\n",
      "Rule 4: match score\n",
      "\n",
      "\n",
      "\n",
      "An equiprobable discretization technique is then applied where the breakpoints are defined such that the area defined by the boundaries of the breakpoint and the Gaussian curves are equal .\n",
      "{2: 'equiprobable discretization technique', 4: 'discretization technique'}\n",
      "Rule 2: equiprobable discretization technique\n",
      "\n",
      "\n",
      "\n",
      "The alignments between the sequences of the selected representatives of all COGs of unknown structures and the structures of selected templates identified by Pcons were used as a starting point for modeling of the members of : COG0565 , COG4752 , COG1303 , COG1818 , COG1772 , COG4080 , COG1901 , COG2419 , COG2428 and COG1756 tertiary structure using the \" FRankenstein 's Monster \" approach , comprising cycles of model building , evaluation , realignment in poorly scored regions and merging of best scoring fragments .\n",
      "{4: \"FRankenstein 's Monster approach\"}\n",
      "Rule 4: FRankenstein 's Monster approach\n",
      "\n",
      "\n",
      "\n",
      "PCA analysis of this matrix was then used to project the sequences onto 2 or 3 dimensions , which allowed identification of possible sequence clusters .\n",
      "{4: 'PCA analysis'}\n",
      "Rule 4: PCA analysis\n",
      "\n",
      "\n",
      "\n",
      "It is quite obvious that the high-throughput prediction of specific oligos is important for application in large-scale gene analysis .\n",
      "{2: 'large-scale gene analysis', 4: 'gene analysis'}\n",
      "Rule 2: large-scale gene analysis\n",
      "\n",
      "\n",
      "\n",
      "We find that the use of the proposed normalization method alone without the use of mock control is sufficient to identify the binding events and that the correlation among biological replicates also improves as a result .\n",
      "{2: 'proposed normalization method', 4: 'normalization method'}\n",
      "Rule 2: proposed normalization method\n",
      "\n",
      "\n",
      "\n",
      "The evolutionary information mainly uses Hidden Markov model PHC score , Hidden Markov model relative entropy , SIFT score and the biochemical difference between the wild-type residue and newly introduced residue .\n",
      "{2: 'Hidden Markov model PHC score', 4: 'Markov model PHC score'}\n",
      "Rule 2: Hidden Markov model PHC score\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'In', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 2, 'deprel': 'case', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'particular', 'lemma': 'particular', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 6, 'deprel': 'obl', 'misc': 'start_char=3|end_char=13', 'children': [1]}\n",
      "{'id': 3, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=14|end_char=15', 'children': []}\n",
      "{'id': 4, 'text': 'it', 'lemma': 'it', 'upos': 'PRON', 'xpos': 'PRP', 'head': 6, 'deprel': 'nsubj:pass', 'misc': 'start_char=16|end_char=18', 'children': []}\n",
      "{'id': 5, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 6, 'deprel': 'aux:pass', 'misc': 'start_char=19|end_char=22', 'children': []}\n",
      "{'id': 6, 'text': 'seen', 'lemma': 'see', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=23|end_char=27', 'children': [2, 3, 4, 5, 10, 35]}\n",
      "{'id': 7, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 10, 'deprel': 'case', 'misc': 'start_char=28|end_char=30', 'children': []}\n",
      "{'id': 8, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 10, 'deprel': 'det', 'misc': 'start_char=31|end_char=34', 'children': []}\n",
      "{'id': 9, 'text': 'previous', 'lemma': 'previous', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 10, 'deprel': 'amod', 'misc': 'start_char=35|end_char=43', 'children': []}\n",
      "{'id': 10, 'text': 'report', 'lemma': 'report', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'obl', 'misc': 'start_char=44|end_char=50', 'children': [7, 8, 9, 17]}\n",
      "{'id': 11, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 17, 'deprel': 'mark', 'misc': 'start_char=51|end_char=55', 'children': []}\n",
      "{'id': 12, 'text': 'these', 'lemma': 'these', 'upos': 'DET', 'xpos': 'DT', 'head': 13, 'deprel': 'det', 'misc': 'start_char=56|end_char=61', 'children': []}\n",
      "{'id': 13, 'text': 'points', 'lemma': 'point', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 17, 'deprel': 'nsubj:pass', 'misc': 'start_char=62|end_char=68', 'children': [12]}\n",
      "{'id': 14, 'text': 'could', 'lemma': 'could', 'upos': 'AUX', 'xpos': 'MD', 'head': 17, 'deprel': 'aux', 'misc': 'start_char=69|end_char=74', 'children': []}\n",
      "{'id': 15, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 17, 'deprel': 'aux:pass', 'misc': 'start_char=75|end_char=77', 'children': []}\n",
      "{'id': 16, 'text': 'adequately', 'lemma': 'adequately', 'upos': 'ADV', 'xpos': 'RB', 'head': 17, 'deprel': 'advmod', 'misc': 'start_char=78|end_char=88', 'children': []}\n",
      "{'id': 17, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBN', 'head': 10, 'deprel': 'ccomp', 'misc': 'start_char=89|end_char=93', 'children': [11, 13, 14, 15, 16, 19]}\n",
      "{'id': 18, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 19, 'deprel': 'mark', 'misc': 'start_char=94|end_char=96', 'children': []}\n",
      "{'id': 19, 'text': 'estimate', 'lemma': 'estimate', 'upos': 'VERB', 'xpos': 'VB', 'head': 17, 'deprel': 'xcomp', 'misc': 'start_char=97|end_char=105', 'children': [18, 22, 34]}\n",
      "{'id': 20, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 22, 'deprel': 'det', 'misc': 'start_char=106|end_char=109', 'children': []}\n",
      "{'id': 21, 'text': 'Rényi', 'lemma': 'rényi', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'compound', 'misc': 'start_char=110|end_char=115', 'children': []}\n",
      "{'id': 22, 'text': 'entropy', 'lemma': 'entropy', 'upos': 'NOUN', 'xpos': 'NN', 'head': 19, 'deprel': 'obj', 'misc': 'start_char=116|end_char=123', 'children': [20, 21, 26]}\n",
      "{'id': 23, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 26, 'deprel': 'case', 'misc': 'start_char=124|end_char=126', 'children': []}\n",
      "{'id': 24, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 26, 'deprel': 'det', 'misc': 'start_char=127|end_char=130', 'children': []}\n",
      "{'id': 25, 'text': 'original', 'lemma': 'original', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 26, 'deprel': 'amod', 'misc': 'start_char=131|end_char=139', 'children': []}\n",
      "{'id': 26, 'text': 'sequence', 'lemma': 'sequence', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'nmod', 'misc': 'start_char=140|end_char=148', 'children': [23, 24, 25]}\n",
      "{'id': 27, 'text': 'through', 'lemma': 'through', 'upos': 'ADP', 'xpos': 'IN', 'head': 34, 'deprel': 'case', 'misc': 'start_char=149|end_char=156', 'children': []}\n",
      "{'id': 28, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 34, 'deprel': 'det', 'misc': 'start_char=157|end_char=160', 'children': []}\n",
      "{'id': 29, 'text': 'Parzen', 'lemma': 'parzen', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'nmod:poss', 'misc': 'start_char=161|end_char=167', 'children': []}\n",
      "{'id': 30, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 34, 'deprel': 'case', 'misc': 'start_char=168|end_char=170', 'children': []}\n",
      "{'id': 31, 'text': 'window', 'lemma': 'window', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'compound', 'misc': 'start_char=171|end_char=177', 'children': []}\n",
      "{'id': 32, 'text': 'density', 'lemma': 'density', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'compound', 'misc': 'start_char=178|end_char=185', 'children': []}\n",
      "{'id': 33, 'text': 'estimation', 'lemma': 'estimation', 'upos': 'NOUN', 'xpos': 'NN', 'head': 34, 'deprel': 'compound', 'misc': 'start_char=186|end_char=196', 'children': []}\n",
      "{'id': 34, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 19, 'deprel': 'obl', 'misc': 'start_char=197|end_char=203', 'children': [27, 28, 29, 30, 31, 32, 33]}\n",
      "{'id': 35, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=204|end_char=205', 'children': []}\n",
      "In particular , it was seen in the previous report that these points could be adequately used to estimate the Rényi entropy of the original sequence through the Parzen 's window density estimation method .\n",
      "{4: 'window density estimation method', 5: \"Parzen 's window density estimation method\"}\n",
      "Rule 5: Parzen 's window density estimation method\n",
      "\n",
      "\n",
      "\n",
      "If we assume that for each local region of the input space can be represented by reduced vectors generated by an efficient dimensionality reduction method and there is a corresponding scalar output yi into which it maps ; then the GRNN can be approximated within acceptable accuracy .\n",
      "{2: 'efficient dimensionality reduction method', 4: 'dimensionality reduction method'}\n",
      "Rule 2: efficient dimensionality reduction method\n",
      "\n",
      "\n",
      "\n",
      "The better overlap was noted between quantile and lumi normalization , with average being the best performing algorithm among the ones present in BeadStudio software .\n",
      "{4: 'performing algorithm'}\n",
      "Rule 4: performing algorithm\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Randomization', 'lemma': 'randomization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'compound', 'misc': 'start_char=0|end_char=13', 'children': []}\n",
      "{'id': 2, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 17, 'deprel': 'nsubj', 'misc': 'start_char=14|end_char=21', 'children': [1, 4]}\n",
      "{'id': 3, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 17, 'deprel': 'mark', 'misc': 'start_char=22|end_char=26', 'children': []}\n",
      "{'id': 4, 'text': 'permute', 'lemma': 'permute', 'upos': 'VERB', 'xpos': 'VBP', 'head': 2, 'deprel': 'acl', 'misc': 'start_char=27|end_char=34', 'children': [6]}\n",
      "{'id': 5, 'text': 'gene', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'compound', 'misc': 'start_char=35|end_char=39', 'children': []}\n",
      "{'id': 6, 'text': 'labels', 'lemma': 'label', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 4, 'deprel': 'obj', 'misc': 'start_char=40|end_char=46', 'children': [5, 7, 13, 14]}\n",
      "{'id': 7, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=47|end_char=48', 'children': []}\n",
      "{'id': 8, 'text': 'such', 'lemma': 'such', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 13, 'deprel': 'case', 'misc': 'start_char=49|end_char=53', 'children': [9]}\n",
      "{'id': 9, 'text': 'as', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 8, 'deprel': 'fixed', 'misc': 'start_char=54|end_char=56', 'children': []}\n",
      "{'id': 10, 'text': 'Fisher', 'lemma': 'fisher', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'nmod:poss', 'misc': 'start_char=57|end_char=63', 'children': []}\n",
      "{'id': 11, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 13, 'deprel': 'case', 'misc': 'start_char=64|end_char=66', 'children': []}\n",
      "{'id': 12, 'text': 'exact', 'lemma': 'exact', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 13, 'deprel': 'amod', 'misc': 'start_char=67|end_char=72', 'children': []}\n",
      "{'id': 13, 'text': 'test', 'lemma': 'test', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'nmod', 'misc': 'start_char=73|end_char=77', 'children': [8, 10, 11, 12]}\n",
      "{'id': 14, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=78|end_char=79', 'children': []}\n",
      "{'id': 15, 'text': 'do', 'lemma': 'do', 'upos': 'AUX', 'xpos': 'VBP', 'head': 17, 'deprel': 'aux', 'misc': 'start_char=80|end_char=82', 'children': []}\n",
      "{'id': 16, 'text': 'not', 'lemma': 'not', 'upos': 'PART', 'xpos': 'RB', 'head': 17, 'deprel': 'advmod', 'misc': 'start_char=83|end_char=86', 'children': []}\n",
      "{'id': 17, 'text': 'preserve', 'lemma': 'preserve', 'upos': 'VERB', 'xpos': 'VB', 'head': 0, 'deprel': 'root', 'misc': 'start_char=87|end_char=95', 'children': [2, 3, 15, 16, 20, 22, 27]}\n",
      "{'id': 18, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 20, 'deprel': 'det', 'misc': 'start_char=96|end_char=99', 'children': []}\n",
      "{'id': 19, 'text': 'correlation', 'lemma': 'correlation', 'upos': 'NOUN', 'xpos': 'NN', 'head': 20, 'deprel': 'compound', 'misc': 'start_char=100|end_char=111', 'children': []}\n",
      "{'id': 20, 'text': 'structure', 'lemma': 'structure', 'upos': 'NOUN', 'xpos': 'NN', 'head': 17, 'deprel': 'obj', 'misc': 'start_char=112|end_char=121', 'children': [18, 19]}\n",
      "{'id': 21, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 22, 'deprel': 'cc', 'misc': 'start_char=122|end_char=125', 'children': []}\n",
      "{'id': 22, 'text': 'misrepresent', 'lemma': 'misrepresent', 'upos': 'VERB', 'xpos': 'VBP', 'head': 17, 'deprel': 'conj', 'misc': 'start_char=126|end_char=138', 'children': [21, 26]}\n",
      "{'id': 23, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 26, 'deprel': 'det', 'misc': 'start_char=139|end_char=142', 'children': []}\n",
      "{'id': 24, 'text': 'group', 'lemma': 'group', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'nmod:poss', 'misc': 'start_char=143|end_char=148', 'children': [25]}\n",
      "{'id': 25, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 24, 'deprel': 'case', 'misc': 'start_char=149|end_char=151', 'children': []}\n",
      "{'id': 26, 'text': 'significance', 'lemma': 'significance', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=152|end_char=164', 'children': [23, 24]}\n",
      "{'id': 27, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 17, 'deprel': 'punct', 'misc': 'start_char=165|end_char=166', 'children': []}\n",
      "Randomization methods that permute gene labels , such as Fisher 's exact test , do not preserve the correlation structure and misrepresent the group 's significance .\n",
      "{5: \"Fisher 's exact test\"}\n",
      "Rule 5: Fisher 's exact test\n",
      "\n",
      "\n",
      "\n",
      "Therefore , the VIP gene selection approach could identify additional subsets of informative genes that would not always be selected by the p-value ranking method .\n",
      "{4: 'VIP gene selection approach'}\n",
      "Rule 4: VIP gene selection approach\n",
      "\n",
      "\n",
      "\n",
      "Therefore , the VIP gene selection approach could identify additional subsets of informative genes that would not always be selected by the p-value ranking method .\n",
      "{4: 'p-value ranking method'}\n",
      "Rule 4: p-value ranking method\n",
      "\n",
      "\n",
      "\n",
      "Also , the ' cr ' method may select a different downstream gene as part of the data construction procedure .\n",
      "{4: 'cr method'}\n",
      "Rule 4: cr method\n",
      "\n",
      "\n",
      "\n",
      "Distributional similarity , that is identifying terms by other terms which occur in close proximity , has also been shown to be effective for identifying synonymy , most notably the Latent Semantic Analysis method of Cederberg & Widdows .\n",
      "{2: 'Latent Semantic Analysis method', 4: 'Analysis method'}\n",
      "Rule 2: Latent Semantic Analysis method\n",
      "\n",
      "\n",
      "\n",
      "The idea that domain-domain interactions should be discovered as putative explanations of protein-protein interactions rather than predictors of these interactions was also the cornerstone of a recently proposed Parsimonious Explanation method , which assumes that interactions between proteins evolved in a parsimonious way , and uses optimization to predict domain interactions .\n",
      "{2: 'proposed Parsimonious Explanation method', 4: 'Explanation method'}\n",
      "Rule 2: proposed Parsimonious Explanation method\n",
      "\n",
      "\n",
      "\n",
      "For structural motif finding , Yao et al. proposed an algorithm based on covariance models , and Hamada et al. proposed a graph mining approach .\n",
      "{4: 'graph mining approach'}\n",
      "Rule 4: graph mining approach\n",
      "\n",
      "\n",
      "\n",
      "When tested on an independent set that was not seen by the method during the training and feature selection , the decision tree method achieves 82.6 % overall accuracy with 0.604 MCC .\n",
      "{4: 'decision tree method'}\n",
      "Rule 4: decision tree method\n",
      "\n",
      "\n",
      "\n",
      "Also , possible misspecifications of a survival model are taken into account .\n",
      "{4: 'survival model'}\n",
      "Rule 4: survival model\n",
      "\n",
      "\n",
      "\n",
      "Our network model provided a good way to solve the problem by assigning variances to the predictions to obtain certain degree of tolerance to the fluctuation of spectra intensities .\n",
      "{4: 'network model'}\n",
      "Rule 4: network model\n",
      "\n",
      "\n",
      "\n",
      "Whereas buried non-polar area dominates the ΔG model , consistent with previous work , other interactions assume much greater importance for the mutant complexes , and the ΔG binding model does not reproduce the spread of ΔGEXP within mutant sets .\n",
      "{4: 'ΔG model'}\n",
      "Rule 4: ΔG model\n",
      "\n",
      "\n",
      "\n",
      "Whereas buried non-polar area dominates the ΔG model , consistent with previous work , other interactions assume much greater importance for the mutant complexes , and the ΔG binding model does not reproduce the spread of ΔGEXP within mutant sets .\n",
      "{4: 'ΔG binding model'}\n",
      "Rule 4: ΔG binding model\n",
      "\n",
      "\n",
      "\n",
      "The Wilcoxon rank sum and Kolmogorov-Smirnov statistics are examples of possible global statistics , with the Wilcoxon rank sum statistic providing a similar setup to the original GSEA implementation .\n",
      "{4: 'Wilcoxon rank sum statistic'}\n",
      "Rule 4: Wilcoxon rank sum statistic\n",
      "\n",
      "\n",
      "\n",
      "By default , the sigPathway approach uses a q-value approach to control the false discovery rate , however here the Benjamini and Yekutieli correction was applied to the raw p-values produced by the calculate .\n",
      "{4: 'sigPathway approach'}\n",
      "Rule 4: sigPathway approach\n",
      "\n",
      "\n",
      "\n",
      "By default , the sigPathway approach uses a q-value approach to control the false discovery rate , however here the Benjamini and Yekutieli correction was applied to the raw p-values produced by the calculate .\n",
      "{4: 'q-value approach'}\n",
      "Rule 4: q-value approach\n",
      "\n",
      "\n",
      "\n",
      "Here the default permutation approach employed by each method was used , except in the case of sigPathway where the outputs relating to sample permutation were utilized .\n",
      "{2: 'default permutation approach', 4: 'permutation approach'}\n",
      "Rule 2: default permutation approach\n",
      "\n",
      "\n",
      "\n",
      "In order to reduce the dimensionality of the pathway data , we employ principal component analysis to define a one-dimensional summary pk of the expression values of the genes in the pathway P for sample k .\n",
      "{2: 'principal component analysis', 4: 'component analysis'}\n",
      "Rule 2: principal component analysis\n",
      "\n",
      "\n",
      "\n",
      "DISCLOSE allows to select the most appropriate clustering method and to visually inspect the clusters obtained for a given DNA microarray dataset .\n",
      "{2: 'appropriate clustering method', 4: 'clustering method'}\n",
      "Rule 2: appropriate clustering method\n",
      "\n",
      "\n",
      "\n",
      "The I-TASSER method is an extension of the previous TASSER method .\n",
      "{4: 'I-TASSER method'}\n",
      "Rule 4: I-TASSER method\n",
      "\n",
      "\n",
      "\n",
      "The I-TASSER method is an extension of the previous TASSER method .\n",
      "{2: 'previous TASSER method', 4: 'TASSER method'}\n",
      "Rule 2: previous TASSER method\n",
      "\n",
      "\n",
      "\n",
      "The source analysis resulted in two estimates for the N1m sources in the right and left hemispheres .\n",
      "{4: 'source analysis'}\n",
      "Rule 4: source analysis\n",
      "\n",
      "\n",
      "\n",
      "Using our vitrification method for increasing the cooling rate between 20°C to -10°C , the \" boiling off \" phenomenon was disappeared .\n",
      "{4: 'vitrification method'}\n",
      "Rule 4: vitrification method\n",
      "\n",
      "\n",
      "\n",
      "Direct sequencing analysis is almost 100 % sensitive for the detection of point mutations , small insertions , and deletions .\n",
      "{2: 'Direct sequencing analysis', 4: 'sequencing analysis'}\n",
      "Rule 2: Direct sequencing analysis\n",
      "\n",
      "\n",
      "\n",
      "This study demonstrated that the mismatch-specific endonuclease method was not only a comparatively faster procedure but was also significantly superior to DHPLC as a tool for gene mutation identification .\n",
      "{2: 'mismatch-specific endonuclease method', 4: 'endonuclease method'}\n",
      "Rule 2: mismatch-specific endonuclease method\n",
      "\n",
      "\n",
      "\n",
      "Toassess reproducibility of the image analysis , the pathologist blindly scored the 66 % of the total of patients and also randomly selected frames .\n",
      "{4: 'image analysis'}\n",
      "Rule 4: image analysis\n",
      "\n",
      "\n",
      "\n",
      "Factor analysis with rotation enabled identification of the dimensions in the questionnaire , and showed that the items selected measured domains that were identical to those hypothesised at the outset .\n",
      "{4: 'Factor analysis'}\n",
      "Rule 4: Factor analysis\n",
      "\n",
      "\n",
      "\n",
      "We pooled studies for each drug using the DerSimonian-Laird random effects model .\n",
      "{2: 'DerSimonian-Laird random effects model', 4: 'effects model'}\n",
      "Rule 2: DerSimonian-Laird random effects model\n",
      "\n",
      "\n",
      "\n",
      "Roederer and colleagues developed a test they have termed ' probability binning analysis ' to determine whether a test distribution of flow cytometry data is different from a control distribution .\n",
      "{4: 'probability binning analysis'}\n",
      "Rule 4: probability binning analysis\n",
      "\n",
      "\n",
      "\n",
      "Attempts to use the paclitaxel extraction method also for docetaxel were unsuccessful due to low and variable recovery .\n",
      "{4: 'paclitaxel extraction method'}\n",
      "Rule 4: paclitaxel extraction method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Variation', 'lemma': 'variation', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'nsubj:pass', 'misc': 'start_char=0|end_char=9', 'children': [4]}\n",
      "{'id': 2, 'text': 'within', 'lemma': 'within', 'upos': 'ADP', 'xpos': 'IN', 'head': 4, 'deprel': 'case', 'misc': 'start_char=10|end_char=16', 'children': []}\n",
      "{'id': 3, 'text': 'each', 'lemma': 'each', 'upos': 'DET', 'xpos': 'DT', 'head': 4, 'deprel': 'det', 'misc': 'start_char=17|end_char=21', 'children': []}\n",
      "{'id': 4, 'text': 'experiment', 'lemma': 'experiment', 'upos': 'NOUN', 'xpos': 'NN', 'head': 1, 'deprel': 'nmod', 'misc': 'start_char=22|end_char=32', 'children': [2, 3]}\n",
      "{'id': 5, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 6, 'deprel': 'aux:pass', 'misc': 'start_char=33|end_char=36', 'children': []}\n",
      "{'id': 6, 'text': 'measured', 'lemma': 'measure', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=37|end_char=45', 'children': [1, 5, 8, 16]}\n",
      "{'id': 7, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 8, 'deprel': 'cc', 'misc': 'start_char=46|end_char=49', 'children': []}\n",
      "{'id': 8, 'text': 'differences', 'lemma': 'difference', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 6, 'deprel': 'conj', 'misc': 'start_char=50|end_char=61', 'children': [7, 10]}\n",
      "{'id': 9, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 10, 'deprel': 'case', 'misc': 'start_char=62|end_char=69', 'children': []}\n",
      "{'id': 10, 'text': 'experiments', 'lemma': 'experiment', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 8, 'deprel': 'nmod', 'misc': 'start_char=70|end_char=81', 'children': [9, 11]}\n",
      "{'id': 11, 'text': 'tested', 'lemma': 'test', 'upos': 'VERB', 'xpos': 'VBN', 'head': 10, 'deprel': 'acl', 'misc': 'start_char=82|end_char=88', 'children': [12]}\n",
      "{'id': 12, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 11, 'deprel': 'xcomp', 'misc': 'start_char=89|end_char=94', 'children': [15]}\n",
      "{'id': 13, 'text': 'Bartlett', 'lemma': 'bartlett', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'nmod:poss', 'misc': 'start_char=95|end_char=103', 'children': [14]}\n",
      "{'id': 14, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 13, 'deprel': 'case', 'misc': 'start_char=104|end_char=106', 'children': []}\n",
      "{'id': 15, 'text': 'test', 'lemma': 'test', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=107|end_char=111', 'children': [13]}\n",
      "{'id': 16, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 6, 'deprel': 'punct', 'misc': 'start_char=112|end_char=113', 'children': []}\n",
      "Variation within each experiment was measured and differences between experiments tested using Bartlett 's test .\n",
      "{5: \"Bartlett 's test\"}\n",
      "Rule 5: Bartlett 's test\n",
      "\n",
      "\n",
      "\n",
      "Traditionally , iTRAQ data analysis is performed automatically with software , which greatly reduces the analysis by the end-user .\n",
      "{4: 'iTRAQ data analysis'}\n",
      "Rule 4: iTRAQ data analysis\n",
      "\n",
      "\n",
      "\n",
      "For this purpose we needed a reliable series of closely consecutive developmental stages , and to achieve this , we used the staging method proposed by Peterka et al. , in which embryo weight allows a more precise specification of the developmental stage of embryos exhibiting the same chronological age .\n",
      "{4: 'staging method'}\n",
      "Rule 4: staging method\n",
      "\n",
      "\n",
      "\n",
      "The RAGEP-PCR method described here uses gene-specific primers and randomly amplifies the nuclear and mitochondrial-like gene products .\n",
      "{4: 'RAGEP-PCR method'}\n",
      "Rule 4: RAGEP-PCR method\n",
      "\n",
      "\n",
      "\n",
      "Among these newly developed methods , the Bayesian relaxed molecular clock approach of Thorne et al. appears particularly promising .\n",
      "{2: 'Bayesian relaxed molecular clock approach', 4: 'clock approach'}\n",
      "Rule 2: Bayesian relaxed molecular clock approach\n",
      "\n",
      "\n",
      "\n",
      "All time estimates were calculated with a Bayesian local clock approach .\n",
      "{2: 'Bayesian local clock approach', 4: 'clock approach'}\n",
      "Rule 2: Bayesian local clock approach\n",
      "\n",
      "\n",
      "\n",
      "Thus , the signature method easily permits the researcher to use long and/or numerous genes in a study .\n",
      "{4: 'signature method'}\n",
      "Rule 4: signature method\n",
      "\n",
      "\n",
      "\n",
      "Firstly , we performed a distance-based relative rate test with RRTree on the 18S rRNA data to test whether taxa differed significantly in their relative substitution rates .\n",
      "{2: 'distance-based relative rate test', 4: 'rate test'}\n",
      "Rule 2: distance-based relative rate test\n",
      "\n",
      "\n",
      "\n",
      "Finally , the Naive Empirical Bayes and/or Bayes Empirical Bayes approach were used to calculate the posterior probability that each site belongs to the site class of positive selection under each model .\n",
      "{4: 'Bayes approach'}\n",
      "Rule 4: Bayes approach\n",
      "\n",
      "\n",
      "\n",
      "The approach includes a systematic exploration of the issues through case analysis .\n",
      "{4: 'case analysis'}\n",
      "Rule 4: case analysis\n",
      "\n",
      "\n",
      "\n",
      "This could possibly have improved the implementation strategy and the subsequent number of users .\n",
      "{4: 'implementation strategy'}\n",
      "Rule 4: implementation strategy\n",
      "\n",
      "\n",
      "\n",
      "For chromosome 20 , the confidence set approach gives one false positive for Replicate 9 .\n",
      "{4: 'confidence set approach'}\n",
      "Rule 4: confidence set approach\n",
      "\n",
      "\n",
      "\n",
      "Laird and colleagues have extended the original TDT to a comprehensive association analysis approach called FBAT .\n",
      "{2: 'comprehensive association analysis approach', 4: 'association analysis approach'}\n",
      "Rule 2: comprehensive association analysis approach\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Clark', 'lemma': 'clark', 'upos': 'NOUN', 'xpos': 'NN', 'head': 3, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=5', 'children': [2]}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 1, 'deprel': 'case', 'misc': 'start_char=6|end_char=8', 'children': []}\n",
      "{'id': 3, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'nsubj', 'misc': 'start_char=9|end_char=15', 'children': [1, 4, 8, 15, 22]}\n",
      "{'id': 4, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=16|end_char=17', 'children': []}\n",
      "{'id': 5, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 8, 'deprel': 'det', 'misc': 'start_char=18|end_char=21', 'children': []}\n",
      "{'id': 6, 'text': 'first', 'lemma': 'first', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 8, 'deprel': 'amod', 'misc': 'start_char=22|end_char=27', 'children': []}\n",
      "{'id': 7, 'text': 'developed', 'lemma': 'develop', 'upos': 'VERB', 'xpos': 'VBN', 'head': 8, 'deprel': 'amod', 'misc': 'start_char=28|end_char=37', 'children': []}\n",
      "{'id': 8, 'text': 'algorithm', 'lemma': 'algorithm', 'upos': 'NOUN', 'xpos': 'NN', 'head': 3, 'deprel': 'appos', 'misc': 'start_char=38|end_char=47', 'children': [5, 6, 7, 11]}\n",
      "{'id': 9, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 11, 'deprel': 'case', 'misc': 'start_char=48|end_char=51', 'children': []}\n",
      "{'id': 10, 'text': 'haplotype', 'lemma': 'haplotype', 'upos': 'NOUN', 'xpos': 'NN', 'head': 11, 'deprel': 'compound', 'misc': 'start_char=52|end_char=61', 'children': []}\n",
      "{'id': 11, 'text': 'reconstruction', 'lemma': 'reconstruction', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'nmod', 'misc': 'start_char=62|end_char=76', 'children': [9, 10]}\n",
      "{'id': 12, 'text': 'which', 'lemma': 'which', 'upos': 'PRON', 'xpos': 'WDT', 'head': 15, 'deprel': 'nsubj:pass', 'misc': 'start_char=77|end_char=82', 'children': []}\n",
      "{'id': 13, 'text': 'can', 'lemma': 'can', 'upos': 'AUX', 'xpos': 'MD', 'head': 15, 'deprel': 'aux', 'misc': 'start_char=83|end_char=86', 'children': []}\n",
      "{'id': 14, 'text': 'be', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VB', 'head': 15, 'deprel': 'aux:pass', 'misc': 'start_char=87|end_char=89', 'children': []}\n",
      "{'id': 15, 'text': 'viewed', 'lemma': 'view', 'upos': 'VERB', 'xpos': 'VBN', 'head': 3, 'deprel': 'acl:relcl', 'misc': 'start_char=90|end_char=96', 'children': [12, 13, 14, 18]}\n",
      "{'id': 16, 'text': 'as', 'lemma': 'as', 'upos': 'ADP', 'xpos': 'IN', 'head': 18, 'deprel': 'case', 'misc': 'start_char=97|end_char=99', 'children': []}\n",
      "{'id': 17, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 18, 'deprel': 'det', 'misc': 'start_char=100|end_char=101', 'children': []}\n",
      "{'id': 18, 'text': 'sort', 'lemma': 'sort', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'obl', 'misc': 'start_char=102|end_char=106', 'children': [16, 17, 21]}\n",
      "{'id': 19, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 21, 'deprel': 'case', 'misc': 'start_char=107|end_char=109', 'children': []}\n",
      "{'id': 20, 'text': 'parsimony', 'lemma': 'parsimony', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 21, 'deprel': 'amod', 'misc': 'start_char=110|end_char=119', 'children': []}\n",
      "{'id': 21, 'text': 'approach', 'lemma': 'approach', 'upos': 'NOUN', 'xpos': 'NN', 'head': 18, 'deprel': 'nmod', 'misc': 'start_char=120|end_char=128', 'children': [19, 20]}\n",
      "{'id': 22, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=129|end_char=130', 'children': []}\n",
      "{'id': 23, 'text': 'requires', 'lemma': 'require', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=131|end_char=139', 'children': [3, 24, 30, 32, 36]}\n",
      "{'id': 24, 'text': 'homozygote', 'lemma': 'homozygote', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'obj', 'misc': 'start_char=140|end_char=150', 'children': [26, 27]}\n",
      "{'id': 25, 'text': 'or', 'lemma': 'or', 'upos': 'CONJ', 'xpos': 'CC', 'head': 26, 'deprel': 'cc', 'misc': 'start_char=151|end_char=153', 'children': []}\n",
      "{'id': 26, 'text': 'single-site', 'lemma': 'single-site', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 24, 'deprel': 'conj', 'misc': 'start_char=154|end_char=165', 'children': [25]}\n",
      "{'id': 27, 'text': 'heterozygote', 'lemma': 'heterozygote', 'upos': 'NOUN', 'xpos': 'NN', 'head': 24, 'deprel': 'dep', 'misc': 'start_char=166|end_char=178', 'children': []}\n",
      "{'id': 28, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 30, 'deprel': 'case', 'misc': 'start_char=179|end_char=181', 'children': []}\n",
      "{'id': 29, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 30, 'deprel': 'det', 'misc': 'start_char=182|end_char=185', 'children': []}\n",
      "{'id': 30, 'text': 'sample', 'lemma': 'sample', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'obl', 'misc': 'start_char=186|end_char=192', 'children': [28, 29]}\n",
      "{'id': 31, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 32, 'deprel': 'mark', 'misc': 'start_char=193|end_char=195', 'children': []}\n",
      "{'id': 32, 'text': 'start', 'lemma': 'start', 'upos': 'VERB', 'xpos': 'VB', 'head': 23, 'deprel': 'xcomp', 'misc': 'start_char=196|end_char=201', 'children': [31, 35]}\n",
      "{'id': 33, 'text': 'its', 'lemma': 'its', 'upos': 'PRON', 'xpos': 'PRP$', 'head': 35, 'deprel': 'nmod:poss', 'misc': 'start_char=202|end_char=205', 'children': []}\n",
      "{'id': 34, 'text': 'inferential', 'lemma': 'inferential', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 35, 'deprel': 'amod', 'misc': 'start_char=206|end_char=217', 'children': []}\n",
      "{'id': 35, 'text': 'cascade', 'lemma': 'cascade', 'upos': 'NOUN', 'xpos': 'NN', 'head': 32, 'deprel': 'obj', 'misc': 'start_char=218|end_char=225', 'children': [33, 34]}\n",
      "{'id': 36, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 23, 'deprel': 'punct', 'misc': 'start_char=226|end_char=227', 'children': []}\n",
      "Clark 's method , the first developed algorithm for haplotype reconstruction which can be viewed as a sort of parsimony approach , requires homozygote or single-site heterozygote in the sample to start its inferential cascade .\n",
      "{5: \"Clark 's method\"}\n",
      "Rule 5: Clark 's method\n",
      "\n",
      "\n",
      "\n",
      "Linkage analysis was conducted on BXD mice using freely available software , and BXD genotype data shared by Robert W. Williams , University of Tennessee Health Science Center .\n",
      "{4: 'Linkage analysis'}\n",
      "Rule 4: Linkage analysis\n",
      "\n",
      "\n",
      "\n",
      "The 2-step variance component mapping approach was used also here , where the model used in step 2 was : Sij = μ+ dayj + ui + vip + vim + eij , where the fixed effect dayj accounts for the differences in survival probabilities between days .\n",
      "{2: '2-step variance component mapping approach', 4: 'variance component mapping approach'}\n",
      "Rule 2: 2-step variance component mapping approach\n",
      "\n",
      "\n",
      "\n",
      "Currently methods allowing for isolation of SINE and LINE from an unknown genome mostly depend on construction of genomic library and subsequently screening by colony hybridization method using probe specific to particular region of repeated elements .\n",
      "{4: 'colony hybridization method'}\n",
      "Rule 4: colony hybridization method\n",
      "\n",
      "\n",
      "\n",
      "Generally , orders selected in Mapmaker had an LOD score greater than 2 .\n",
      "{2: 'LOD score greater score', 4: 'LOD score'}\n",
      "Rule 2: LOD score greater score\n",
      "\n",
      "\n",
      "\n",
      "Our strategy for finding novel genes is to perform cDNA analysis using an organism closely related to humans , the cynomolgus monkey .\n",
      "{4: 'cDNA analysis'}\n",
      "Rule 4: cDNA analysis\n",
      "\n",
      "\n",
      "\n",
      "An attractive feature of the protein tagging method described in this study is that it is independent of antibody probes and allows for direct visualization of tagged proteins by confocal microscopy .\n",
      "{4: 'protein tagging method'}\n",
      "Rule 4: protein tagging method\n",
      "\n",
      "\n",
      "\n",
      "The degree of reproducibility of our amplification method was assessed by plotting the log2 values for paired hybridizations derived from independent amplifications of the same starting RNA , calculating the correlation coefficient for a series of independent replicates , and computing the mean correlation coefficient .\n",
      "{4: 'amplification method'}\n",
      "Rule 4: amplification method\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many approaches have been used to detect modules in metabolic network including elementary modes , extreme pathways , flux analysis .\n",
      "{4: 'flux analysis'}\n",
      "Rule 4: flux analysis\n",
      "\n",
      "\n",
      "\n",
      "The likelihood ratio test is used to determine whether or not two densities fit better than a single density .\n",
      "{4: 'likelihood ratio test'}\n",
      "Rule 4: likelihood ratio test\n",
      "\n",
      "\n",
      "\n",
      "Pearson correlation analysis of DNA adduct levels with the microarray and RTqPCR data shows that RTqPCR measurement of gene expression generally correlates better with the adduct levels , confirming its utility as a more sensitive measure of gene expression .\n",
      "{4: 'Pearson correlation analysis'}\n",
      "Rule 4: Pearson correlation analysis\n",
      "\n",
      "\n",
      "\n",
      "Combinations of PCR-selected cDNA subtraction and cDNA microarray analysis of the subtracted clones , or using probes generated by PCR-selected subtraction to screen Affymetrix GeneChips have been attempted .\n",
      "{4: 'cDNA microarray analysis'}\n",
      "Rule 4: cDNA microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "We focus only on the testing method , which we will refer to as median t .\n",
      "{4: 'testing method'}\n",
      "Rule 4: testing method\n",
      "\n",
      "\n",
      "\n",
      "This distinct normalization method calls for a correct internal control for the microarray and Q-RT-PCR data comparison .\n",
      "{2: 'distinct normalization method', 4: 'normalization method'}\n",
      "Rule 2: distinct normalization method\n",
      "\n",
      "\n",
      "\n",
      "The validity of the binary prioritization method was assessed by investigating the protein-protein interactions , functional enrichment and common promoter element binding sites of the top-ranked genes .\n",
      "{2: 'binary prioritization method', 4: 'prioritization method'}\n",
      "Rule 2: binary prioritization method\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we developed a feature selection method named Supervised Recursive Feature Addition .\n",
      "{4: 'feature selection method'}\n",
      "Rule 4: feature selection method\n",
      "\n",
      "\n",
      "\n",
      "In this \" mRNA-tagging \" approach , an epitope-labeled mRNA binding protein is transgenically expressed with a cell-specific promoter .\n",
      "{2: 'mRNA-tagging approach', 4: 'mRNA-tagging approach'}\n",
      "Rule 2: mRNA-tagging approach\n",
      "\n",
      "\n",
      "\n",
      "We also performed a pathway analysis with GSEA , a method that does not require preselection of genes by a statistical threshold but uses the whole dataset .\n",
      "{4: 'pathway analysis'}\n",
      "Rule 4: pathway analysis\n",
      "\n",
      "\n",
      "\n",
      "By applying a SFP detection method to two mammalian breeds for the first time , we detected transition and transversion single nucleotide polymorphisms , as well as insertions / deletions which can be used to rapidly develop markers for genetic mapping and association analysis in species where high density genotyping platforms are otherwise unavailable .\n",
      "{4: 'SFP detection method'}\n",
      "Rule 4: SFP detection method\n",
      "\n",
      "\n",
      "\n",
      "By applying a SFP detection method to two mammalian breeds for the first time , we detected transition and transversion single nucleotide polymorphisms , as well as insertions / deletions which can be used to rapidly develop markers for genetic mapping and association analysis in species where high density genotyping platforms are otherwise unavailable .\n",
      "{4: 'association analysis'}\n",
      "Rule 4: association analysis\n",
      "\n",
      "\n",
      "\n",
      "The GeneTrek approach has been proposed as an efficient way to evaluate the general properties of any genome .\n",
      "{4: 'GeneTrek approach'}\n",
      "Rule 4: GeneTrek approach\n",
      "\n",
      "\n",
      "\n",
      "When the initial GARD analysis failed to converge in the time allocated , the alignment was divided into two subregions at the breakpoint with the highest c-AIC-support in the initial analysis , and each subregion was then separately analysed with GARD .\n",
      "{2: 'initial GARD analysis', 4: 'GARD analysis'}\n",
      "Rule 2: initial GARD analysis\n",
      "\n",
      "\n",
      "\n",
      "At the end of the 24 hr , dead mosquitoes were discarded and alive individuals were maintained until they reached three days old before being preserved in RNA-later for genotyping , kdr detection and microarray analysis .\n",
      "{4: 'microarray analysis'}\n",
      "Rule 4: microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "This study showed the beneficial effect of a dual decoupling strategy between Nano-LC MALDI-TOF and TOF / TOF mass spectrometry on overall analytical time .\n",
      "{2: 'dual decoupling strategy', 4: 'decoupling strategy'}\n",
      "Rule 2: dual decoupling strategy\n",
      "\n",
      "\n",
      "\n",
      "We developed a GATC-PCR method to accurately measure absolute expression levels of mRNAs by means of competitive amplification of genomic and cDNA copies of each gene .\n",
      "{4: 'GATC-PCR method'}\n",
      "Rule 4: GATC-PCR method\n",
      "\n",
      "\n",
      "\n",
      "Biologically , we know that SNPs in close proximity are not independent , and therefore we are \" overcorrecting \" when we use the traditional Bonferroni method to adjust significance thresholds for multiple testing in GWAS studies .\n",
      "{2: 'traditional Bonferroni method', 4: 'Bonferroni method'}\n",
      "Rule 2: traditional Bonferroni method\n",
      "\n",
      "\n",
      "\n",
      "Multivariate Cox analysis showed the frailty index , age and sex to be significant predictors of mortality .\n",
      "{2: 'Multivariate Cox analysis', 4: 'Cox analysis'}\n",
      "Rule 2: Multivariate Cox analysis\n",
      "\n",
      "\n",
      "\n",
      "Tracking was accomplished using a computer vision technique known as flocking , which was developed by Hoey et al. .\n",
      "{4: 'computer vision technique'}\n",
      "Rule 4: computer vision technique\n",
      "\n",
      "\n",
      "\n",
      "The Framework method of analysis will be used .\n",
      "{4: 'Framework method'}\n",
      "Rule 4: Framework method\n",
      "\n",
      "\n",
      "\n",
      "For the sensitivity analysis we used three different hypotheses .\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "We used a 4-point ordinal variable as the indicator for \" the convenience of transportation \" and applied the ordered probit model in our multivariate analysis .\n",
      "{2: 'ordered probit model', 4: 'probit model'}\n",
      "Rule 2: ordered probit model\n",
      "\n",
      "\n",
      "\n",
      "Thus we recommend the use of this modified RosetteSep technique for obtaining any number of highly purified tonsil B lymphocytes .\n",
      "{2: 'modified RosetteSep technique', 4: 'RosetteSep technique'}\n",
      "Rule 2: modified RosetteSep technique\n",
      "\n",
      "\n",
      "\n",
      "If a countable number of colonies grew , the strain was considered to have potential heteroresistance to glycopeptide and was confirmed with population analysis profile method .\n",
      "{4: 'population analysis profile method'}\n",
      "Rule 4: population analysis profile method\n",
      "\n",
      "\n",
      "\n",
      "The patients ' physiologic condition prior to the BSI and on the day of BSI were assessed using the APACHE II score .\n",
      "{4: 'APACHE score'}\n",
      "Rule 4: APACHE score\n",
      "\n",
      "\n",
      "\n",
      "Ordinarily , survival analysis assumes that events occur when they are observed .\n",
      "{4: 'survival analysis'}\n",
      "Rule 4: survival analysis\n",
      "\n",
      "\n",
      "\n",
      "The serotypes , subtypes , LPS , class 5 and cross-reactive specificity of Mabs are defined by their reactivity with whole cells or native outer membrane proteins of the strains by immunoblot analysis .\n",
      "{4: 'immunoblot analysis'}\n",
      "Rule 4: immunoblot analysis\n",
      "\n",
      "\n",
      "\n",
      "The determination of the most appropriate screening methods and subtype analysis depends on the immediate requirements of an investigation .\n",
      "{4: 'subtype analysis'}\n",
      "Rule 4: subtype analysis\n",
      "\n",
      "\n",
      "\n",
      "For each participant , the time-series statistical model included convolution with the canonical hemodynamic response function and a high frequency signal filtering .\n",
      "{2: 'time-series statistical model', 4: 'time-series model'}\n",
      "Rule 2: time-series statistical model\n",
      "\n",
      "\n",
      "\n",
      "Single-nucleotide polymorphisms of the inter-alpha-trypsin inhibitor family heavy chain-related protein gene were analyzed using a fluorescence-adapted SSCP method .\n",
      "{2: 'fluorescence-adapted SSCP method', 4: 'SSCP method'}\n",
      "Rule 2: fluorescence-adapted SSCP method\n",
      "\n",
      "\n",
      "\n",
      "Haplotypes for the 3 SNPs were inferred using a maximum likelihood approach and their association with the rank of the various mean blood pressure measurements in the AIB Phase II study group and their association with hypertension in the CVD group was determined using \" haplo .\n",
      "{4: 'maximum likelihood approach'}\n",
      "Rule 4: maximum likelihood approach\n",
      "\n",
      "\n",
      "\n",
      "Several authors have compared traditional methods and the DNA cards method for collection of DNA samples indicating some advantages of the blood spots and DNA cards method for multicenter studies .\n",
      "{4: 'DNA cards method'}\n",
      "Rule 4: DNA cards method\n",
      "\n",
      "\n",
      "\n",
      "Genomic DNA was extracted from the whole blood and the SNPs rs2243193 , rs2981572 , and rs1150253 were analyzed by the tetra-primer ARMS-PCR method as described previously .\n",
      "{2: 'tetra-primer ARMS-PCR method', 4: 'ARMS-PCR method'}\n",
      "Rule 2: tetra-primer ARMS-PCR method\n",
      "\n",
      "\n",
      "\n",
      "The SG method has been widely used to measure individual preferences in conditions of uncertainty .\n",
      "{4: 'SG method'}\n",
      "Rule 4: SG method\n",
      "\n",
      "\n",
      "\n",
      "Inter-rater reliability for selected methodological quality score , success and features present or not , was calculated and reported as a kappa statistic .\n",
      "{2: 'selected methodological quality score', 4: 'quality score'}\n",
      "Rule 2: selected methodological quality score\n",
      "\n",
      "\n",
      "\n",
      "Inter-rater reliability for selected methodological quality score , success and features present or not , was calculated and reported as a kappa statistic .\n",
      "{4: 'kappa statistic'}\n",
      "Rule 4: kappa statistic\n",
      "\n",
      "\n",
      "\n",
      "Six methods of imputation were compared : 1 ) random selection , 2 ) preceding question , 3 ) question mean , 4 ) individual mean 5 ) single regression and 6 ) a multiple imputation algorithm .\n",
      "{2: 'multiple imputation algorithm', 4: 'imputation algorithm'}\n",
      "Rule 2: multiple imputation algorithm\n",
      "\n",
      "\n",
      "\n",
      "Because we had already created a dataset of 151 systematic reviews assessed using 37 completed items for each review , we were able to conduct a factor analysis as the first step in the creation of the new tool .\n",
      "{4: 'factor analysis'}\n",
      "Rule 4: factor analysis\n",
      "\n",
      "\n",
      "\n",
      "A treatment combining lysozyme with triton X-100 was found to be an effective permeabilization method of the mycobacterial envelope .\n",
      "{2: 'effective permeabilization method', 4: 'permeabilization method'}\n",
      "Rule 2: effective permeabilization method\n",
      "\n",
      "\n",
      "\n",
      "The sequences were analysed using the maximum parsimony method , which is an evolutionary model that searches for the simplest tree that can be constructed using the fewest inferred changes between characters .\n",
      "{4: 'maximum parsimony method'}\n",
      "Rule 4: maximum parsimony method\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These results suggest that measurements of bacterial multiplication using the PXO99GFP strain can replace the conventional colony counting method to screen for susceptible and resistant hosts .\n",
      "{2: 'conventional colony counting method', 4: 'colony counting method'}\n",
      "Rule 2: conventional colony counting method\n",
      "\n",
      "\n",
      "\n",
      "The sequences of the aspC , clpX , fadD , icdA , lysP , mdh and uidA genes used for the MLST analysis have been deposited in the GenBank data base under accession numbers GQ130379 to GQ131022 .\n",
      "{4: 'MLST analysis'}\n",
      "Rule 4: MLST analysis\n",
      "\n",
      "\n",
      "\n",
      "The data were analysed by the Scatchard method using the LIGAND program of Munson and Rodbard .\n",
      "{4: 'Scatchard method'}\n",
      "Rule 4: Scatchard method\n",
      "\n",
      "\n",
      "\n",
      "A systematic approach to teaching tai chi has been developed by Dr Paul Lam ; it is known as the Stepwise Progressive Teaching Method .\n",
      "{2: 'Stepwise Progressive Teaching Method', 4: 'Teaching Method'}\n",
      "Rule 2: Stepwise Progressive Teaching Method\n",
      "\n",
      "\n",
      "\n",
      "It is based on automated epifluorescence microscopy and image analysis of cells in a microtiter plate format .\n",
      "{4: 'image analysis'}\n",
      "Rule 4: image analysis\n",
      "\n",
      "\n",
      "\n",
      "Tadesse et al. could successfully improve specificity of the identification of DNA regulatory motifs by fitting a linear regression model to microarray data in yeast .\n",
      "{2: 'linear regression model', 4: 'regression model'}\n",
      "Rule 2: linear regression model\n",
      "\n",
      "\n",
      "\n",
      "Double labeling analysis of a selection of these genes with known markers of DRG neuron sub-types revealed expression in sub-populations of DRG neurons in the adult mouse from birth to adulthood .\n",
      "{2: 'Double labeling analysis', 4: 'labeling analysis'}\n",
      "Rule 2: Double labeling analysis\n",
      "\n",
      "\n",
      "\n",
      "A bidding algorithm similar to that described by Matthew 's et al was used to assist participants determine their willingness-to-pay threshold for each treatment option before they accepted losing the tooth and living with the edentulous space for the rest of their life .\n",
      "{2: 'bidding algorithm similar algorithm', 4: 'bidding algorithm'}\n",
      "Rule 2: bidding algorithm similar algorithm\n",
      "\n",
      "\n",
      "\n",
      "We are using the Framework method of analysis .\n",
      "{4: 'Framework method'}\n",
      "Rule 4: Framework method\n",
      "\n",
      "\n",
      "\n",
      "The components analysis was based on correlation matrices rather than covariance matrices as the variables were on different scales of measurement .\n",
      "{4: 'components analysis'}\n",
      "Rule 4: components analysis\n",
      "\n",
      "\n",
      "\n",
      "At the end of the interview , each clinician independently summarized his or her list of diagnoses and scored the Clinical Global Impression severity scale ; finally , they met and concluded with a consensus list of diagnoses and a CGIs score .\n",
      "{4: 'CGIs score'}\n",
      "Rule 4: CGIs score\n",
      "\n",
      "\n",
      "\n",
      "The second optimisation method investigated in this paper is to choose the cutpoint associated with the point on the ROC curve closest to the upper left corner .\n",
      "{2: 'second optimisation method', 4: 'optimisation method'}\n",
      "Rule 2: second optimisation method\n",
      "\n",
      "\n",
      "\n",
      "We chose the Delphi method , a technique used for reaching consensus in a group of experts or across expert groups .\n",
      "{4: 'Delphi method'}\n",
      "Rule 4: Delphi method\n",
      "\n",
      "\n",
      "\n",
      "Automated voxel-based morphometry method was used in order to minimize operational biases when comparing the Neuroanatomical differences between patients with PTSD and the control subjects , .\n",
      "{2: 'Automated voxel-based morphometry method', 4: 'morphometry method'}\n",
      "Rule 2: Automated voxel-based morphometry method\n",
      "\n",
      "\n",
      "\n",
      "The Socratic teaching method was employed throughout to promote open discussion within the groups .\n",
      "{2: 'Socratic teaching method', 4: 'teaching method'}\n",
      "Rule 2: Socratic teaching method\n",
      "\n",
      "\n",
      "\n",
      "However , birth certificate records are widely available , very accurate in terms of delivery method and birth weight and represent the standard measure for research on birth outcomes .\n",
      "{4: 'delivery method'}\n",
      "Rule 4: delivery method\n",
      "\n",
      "\n",
      "\n",
      "The SP method , when openly employed , can furthermore be a useful support for regular feedback and identification of further training needs .\n",
      "{4: 'SP method'}\n",
      "Rule 4: SP method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'We', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP', 'head': 3, 'deprel': 'nsubj', 'misc': 'start_char=0|end_char=2', 'children': []}\n",
      "{'id': 2, 'text': 'then', 'lemma': 'then', 'upos': 'ADV', 'xpos': 'RB', 'head': 3, 'deprel': 'advmod', 'misc': 'start_char=3|end_char=7', 'children': []}\n",
      "{'id': 3, 'text': 'looked', 'lemma': 'look', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=8|end_char=14', 'children': [1, 2, 6, 7, 8, 18]}\n",
      "{'id': 4, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 6, 'deprel': 'case', 'misc': 'start_char=15|end_char=18', 'children': []}\n",
      "{'id': 5, 'text': 'space-time', 'lemma': 'space-time', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 6, 'deprel': 'amod', 'misc': 'start_char=19|end_char=29', 'children': []}\n",
      "{'id': 6, 'text': 'clusters', 'lemma': 'cluster', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 3, 'deprel': 'obl', 'misc': 'start_char=30|end_char=38', 'children': [4, 5]}\n",
      "{'id': 7, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=39|end_char=40', 'children': []}\n",
      "{'id': 8, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 3, 'deprel': 'advcl', 'misc': 'start_char=41|end_char=46', 'children': [12]}\n",
      "{'id': 9, 'text': 'Kulldorff', 'lemma': 'kulldorff', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'nmod:poss', 'misc': 'start_char=47|end_char=56', 'children': []}\n",
      "{'id': 10, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 12, 'deprel': 'case', 'misc': 'start_char=57|end_char=59', 'children': []}\n",
      "{'id': 11, 'text': 'scan', 'lemma': 'scan', 'upos': 'NOUN', 'xpos': 'NN', 'head': 12, 'deprel': 'compound', 'misc': 'start_char=60|end_char=64', 'children': []}\n",
      "{'id': 12, 'text': 'statistic', 'lemma': 'statistic', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'obj', 'misc': 'start_char=65|end_char=74', 'children': [9, 10, 11, 13]}\n",
      "{'id': 13, 'text': 'implemented', 'lemma': 'implement', 'upos': 'VERB', 'xpos': 'VBN', 'head': 12, 'deprel': 'acl', 'misc': 'start_char=75|end_char=86', 'children': [17]}\n",
      "{'id': 14, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 17, 'deprel': 'case', 'misc': 'start_char=87|end_char=89', 'children': []}\n",
      "{'id': 15, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 17, 'deprel': 'det', 'misc': 'start_char=90|end_char=93', 'children': []}\n",
      "{'id': 16, 'text': 'Satscan', 'lemma': 'satscan', 'upos': 'NOUN', 'xpos': 'NN', 'head': 17, 'deprel': 'compound', 'misc': 'start_char=94|end_char=101', 'children': []}\n",
      "{'id': 17, 'text': 'program', 'lemma': 'program', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'obl', 'misc': 'start_char=102|end_char=109', 'children': [14, 15, 16]}\n",
      "{'id': 18, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=110|end_char=111', 'children': []}\n",
      "We then looked for space-time clusters , using Kulldorff 's scan statistic implemented in the Satscan program .\n",
      "{4: 'scan statistic', 5: \"Kulldorff 's scan statistic\"}\n",
      "Rule 5: Kulldorff 's scan statistic\n",
      "\n",
      "\n",
      "\n",
      "We adopted the fixed effects linear regression model to control for unobserved heterogeneity among patient-hospital groups .\n",
      "{2: 'linear regression model', 4: 'regression model'}\n",
      "Rule 2: linear regression model\n",
      "\n",
      "\n",
      "\n",
      "Optimal combinations of biomarkers were investigated by performing best subsets analysis in both cases .\n",
      "{2: 'best subsets analysis', 4: 'subsets analysis'}\n",
      "Rule 2: best subsets analysis\n",
      "\n",
      "\n",
      "\n",
      "The DSSP algorithm is based on the detection of hydrogen-bonds defined by an electrostatic criterion .\n",
      "{4: 'DSSP algorithm'}\n",
      "Rule 4: DSSP algorithm\n",
      "\n",
      "\n",
      "\n",
      "Using a PSI-BLAST method , a target protein sequence is first aligned with orthologous sequences .\n",
      "{4: 'PSI-BLAST method'}\n",
      "Rule 4: PSI-BLAST method\n",
      "\n",
      "\n",
      "\n",
      "X-ray sequencing method , based on electron density , is another method to determine the protein sequence .\n",
      "{4: 'X-ray sequencing method'}\n",
      "Rule 4: X-ray sequencing method\n",
      "\n",
      "\n",
      "\n",
      "We investigate the effectiveness of a graph-theoretic clique finding approach to solve this problem .\n",
      "{2: 'graph-theoretic clique finding approach', 4: 'clique finding approach'}\n",
      "Rule 2: graph-theoretic clique finding approach\n",
      "\n",
      "\n",
      "\n",
      "This increased specificity is achieved by incorporating the quantitative aspects of the Sequest cross correlation into the spectral counting method .\n",
      "{2: 'spectral counting method', 4: 'counting method'}\n",
      "Rule 2: spectral counting method\n",
      "\n",
      "\n",
      "\n",
      "Therefore , the modeling of systems with inherent combinatorial complexity is very difficult , or even impossible using the conventional modeling approach .\n",
      "{2: 'conventional modeling approach', 4: 'modeling approach'}\n",
      "Rule 2: conventional modeling approach\n",
      "\n",
      "\n",
      "\n",
      "Even if one disregards the results obtained with these two serotypes , the overall sensitivity of the NMKL methods is less than with both the MSRV method and the Selecta culturing method .\n",
      "{4: 'MSRV method'}\n",
      "Rule 4: MSRV method\n",
      "\n",
      "\n",
      "\n",
      "To implement ILGC algorithm , there are number of missing entries in the original datasets which we fill in .\n",
      "{4: 'ILGC algorithm'}\n",
      "Rule 4: ILGC algorithm\n",
      "\n",
      "\n",
      "\n",
      "We report an assay that permits the ubiquitination analysis of a specific protein .\n",
      "{4: 'ubiquitination analysis'}\n",
      "Rule 4: ubiquitination analysis\n",
      "\n",
      "\n",
      "\n",
      "This greatly simplifies the data analysis .\n",
      "{4: 'data analysis'}\n",
      "Rule 4: data analysis\n",
      "\n",
      "\n",
      "\n",
      "Its detection requires a different analysis technique , allowing for averaging signal 's energy irrelevant of the phase2 .\n",
      "{2: 'different analysis technique', 4: 'analysis technique'}\n",
      "Rule 2: different analysis technique\n",
      "\n",
      "\n",
      "\n",
      "In an attempt to enhance the active contours method a cubic spline interpolation technique was used in to identify an initial contour based on four user-defined points .\n",
      "{2: 'cubic spline interpolation technique', 4: 'spline interpolation technique'}\n",
      "Rule 2: cubic spline interpolation technique\n",
      "\n",
      "\n",
      "\n",
      "In order to gain confidence in the mesh size of each AAA model , the number of elements was incrementally increased and the peak wall stress computed .\n",
      "{4: 'AAA model'}\n",
      "Rule 4: AAA model\n",
      "\n",
      "\n",
      "\n",
      "This system used digital video analysis and position information from infrared beam breaking to assess sleep and wake behaviours in mice .\n",
      "{2: 'digital video analysis', 4: 'video analysis'}\n",
      "Rule 2: digital video analysis\n",
      "\n",
      "\n",
      "\n",
      "Incidence rate ratios and corresponding 95 percent confidence intervals for endometrial cancer were estimated in the age-adjusted and multivariate case-cohort analyses with categorized and continuous alcohol and cigarette smoking variables , using the Cox proportional hazards model .\n",
      "{2: 'Cox proportional hazards model', 4: 'Cox proportional hazards model'}\n",
      "Rule 2: Cox proportional hazards model\n",
      "\n",
      "\n",
      "\n",
      "Cells were harvested after five days of treatment and analyzed by the crystal violet method as reported .\n",
      "{2: 'crystal violet method', 4: 'violet method'}\n",
      "Rule 2: crystal violet method\n",
      "\n",
      "\n",
      "\n",
      "Thus , FRCC-DEP can be altered , making this carbon valuation method robust to site-specific management actions , providing incentive in terms of increased carbon market value for landowners to engage in high severity fire risk reduction measures .\n",
      "{2: 'carbon valuation method robust method', 4: 'carbon valuation method'}\n",
      "Rule 2: carbon valuation method robust method\n",
      "\n",
      "\n",
      "\n",
      "Recently , Milkiewicz and Haas demonstrated the feasibility of the laser capture microdissection method in the study of capillary-specific gene expression from heterogeneous tissue such as skeletal muscle .\n",
      "{4: 'microdissection method'}\n",
      "Rule 4: microdissection method\n",
      "\n",
      "\n",
      "\n",
      "In order to take into account changes occurring in antihypertensive therapy , the time-course for first introducing new / increased antihypertensive medication was estimated using the Kaplan-Meier method , and treatment groups compared using Log rank tests .\n",
      "{4: 'Kaplan-Meier method'}\n",
      "Rule 4: Kaplan-Meier method\n",
      "\n",
      "\n",
      "\n",
      "In SSR analysis , Panax quinquefolius showed different allele patterns compared with those of Panax ginseng .\n",
      "{4: 'SSR analysis'}\n",
      "Rule 4: SSR analysis\n",
      "\n",
      "\n",
      "\n",
      "Method validation data indicate that the developed HPLC method as described in this paper is reliable , reproducible and accurate for the determination of BMA in processed aconite roots and their products .\n",
      "{2: 'developed HPLC method', 4: 'HPLC method'}\n",
      "Rule 2: developed HPLC method\n",
      "\n",
      "\n",
      "\n",
      "Here again , ocular sonography could be of interest for the early detection of raised ICP , and perhaps for the decision to initiate a more aggressive monitoring strategy .\n",
      "{2: 'aggressive monitoring strategy', 4: 'monitoring strategy'}\n",
      "Rule 2: aggressive monitoring strategy\n",
      "\n",
      "\n",
      "\n",
      "As with the super syringe technique , however , this technique is time consuming , and its use is limited in clinical practice .\n",
      "{2: 'super syringe technique', 4: 'syringe technique'}\n",
      "Rule 2: super syringe technique\n",
      "\n",
      "\n",
      "\n",
      "The waveguide model of the hearing aid earmold system and results of experiments are discussed in details in the following parts of this paper .\n",
      "{4: 'waveguide model'}\n",
      "Rule 4: waveguide model\n",
      "\n",
      "\n",
      "\n",
      "Numerical integration methods must be considered , but these methods are computationally demanding and have not yet been incorporated in widely available software for structural equation analysis .\n",
      "{2: 'structural equation analysis', 4: 'equation analysis'}\n",
      "Rule 2: structural equation analysis\n",
      "\n",
      "\n",
      "\n",
      "Center researchers have built upon this work by examining bacterial assemblages associated with 18 Pseudo-nitzschia strains , representing 6 species , using a DNA fingerprinting technique called ARISA .\n",
      "{4: 'DNA fingerprinting technique'}\n",
      "Rule 4: DNA fingerprinting technique\n",
      "\n",
      "\n",
      "\n",
      "The example presented in this paper includes questionnaire design , data entry , and data management that attempt to maximize the advantages of this data collection method .\n",
      "{4: 'data collection method'}\n",
      "Rule 4: data collection method\n",
      "\n",
      "\n",
      "\n",
      "Zhang and Horvath proposed a weighted gene co-expression network approach .\n",
      "{2: 'weighted gene co-expression network approach', 4: 'gene co-expression network approach'}\n",
      "Rule 2: weighted gene co-expression network approach\n",
      "\n",
      "\n",
      "\n",
      "All data were filtered such that only those probes were retained for analysis that had good quality data in each replicate array within each independent experiment : 20,586 probes for Sco-Chip2-v1 array ; 43,056 probes for Sco-Chip2 ; and 43,263 probes for the Sco-Chip2-v2 gene expression analysis .\n",
      "{4: 'Sco-Chip2-v2 gene expression analysis'}\n",
      "Rule 4: Sco-Chip2-v2 gene expression analysis\n",
      "\n",
      "\n",
      "\n",
      "The IHGSC started from a clone-based physical map of the genome , while Celera used the whole-genome shotgun method to produce the sequence .\n",
      "{2: 'whole-genome shotgun method', 4: 'shotgun method'}\n",
      "Rule 2: whole-genome shotgun method\n",
      "\n",
      "\n",
      "\n",
      "To overcome these problems , we investigated the potential impact of the association-rule discovery technique .\n",
      "{2: 'association-rule discovery technique', 4: 'discovery technique'}\n",
      "Rule 2: association-rule discovery technique\n",
      "\n",
      "\n",
      "\n",
      "The authors tackled the problem of low tag frequency by carrying out a ' virtual ' subtraction approach to identify the subset of genes expressed exclusively in the limb libraries .\n",
      "{2: 'virtual subtraction approach', 4: 'subtraction approach'}\n",
      "Rule 2: virtual subtraction approach\n",
      "\n",
      "\n",
      "\n",
      "Principal component analysis , as described in Materials and methods , was carried out to reduce the complexity of the data and then to relate individual animals to specific phenotypic groups .\n",
      "{2: 'Principal component analysis', 4: 'component analysis'}\n",
      "Rule 2: Principal component analysis\n",
      "\n",
      "\n",
      "\n",
      "The k-NN method was comparably effective to other methods tested .\n",
      "{4: 'k-NN method'}\n",
      "Rule 4: k-NN method\n",
      "\n",
      "\n",
      "\n",
      "A major challenge in designing any automated data processing method is thinking of and anticipating all possible situations that may arise .\n",
      "{2: 'automated data processing method', 4: 'data processing method'}\n",
      "Rule 2: automated data processing method\n",
      "\n",
      "\n",
      "\n",
      "PolyA+ RNA was extracted from the T4 fraction from individual 3 and used to generate cDNA mini-libraries using the ORESTES method .\n",
      "{4: 'ORESTES method'}\n",
      "Rule 4: ORESTES method\n",
      "\n",
      "\n",
      "\n",
      "A wrapper-type feature selection algorithm was used for training 33 SVMs with radial bias function kernels using each of the 33 sets of profiles .\n",
      "{2: 'wrapper-type feature selection algorithm', 4: 'feature selection algorithm'}\n",
      "Rule 2: wrapper-type feature selection algorithm\n",
      "\n",
      "\n",
      "\n",
      "The Longest common substring score method finds the longest common substring of motifs that occurs in both sequences .\n",
      "{2: 'common substring score method', 4: 'substring score method'}\n",
      "Rule 2: common substring score method\n",
      "\n",
      "\n",
      "\n",
      "In step , the dimensionality of the item bank was examined using item response theory based full information factor analysis .\n",
      "{2: 'full information factor analysis', 4: 'information factor analysis'}\n",
      "Rule 2: full information factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Both factor analysis and reliability analysis were performed for the long and the short version of the HLQ .\n",
      "{4: 'factor analysis'}\n",
      "Rule 4: factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Such clustering precludes a traditional Hausman specification test to evaluate the random effects model assumption that Cov = 0 .\n",
      "{2: 'traditional Hausman specification test', 4: 'Hausman specification test'}\n",
      "Rule 2: traditional Hausman specification test\n",
      "\n",
      "\n",
      "\n",
      "Two matrix-based prediction algorithms for Cw*0401 were reported , but a sequence independent approach is still lacking .\n",
      "{2: 'sequence independent approach', 4: 'sequence approach'}\n",
      "Rule 2: sequence independent approach\n",
      "\n",
      "\n",
      "\n",
      "The resulting individual relationship score varied from 0 , indicating no relationship , and 18 , indicating a contracted relationship with high impact on WATI related activities .\n",
      "{2: 'resulting individual relationship score', 4: 'relationship score'}\n",
      "Rule 2: resulting individual relationship score\n",
      "\n",
      "\n",
      "\n",
      "As above reported , higher cut-off values improve the specificity of the HC2 test .\n",
      "{4: 'HC2 test'}\n",
      "Rule 4: HC2 test\n",
      "\n",
      "\n",
      "\n",
      "Optical mapping could be considered the latest physical mapping method developed in the late 1990s .\n",
      "{2: 'latest physical mapping method', 4: 'mapping method'}\n",
      "Rule 2: latest physical mapping method\n",
      "\n",
      "\n",
      "\n",
      "The network analysis has produced new information previously unavailable at a national scale in New Zealand .\n",
      "{4: 'network analysis'}\n",
      "Rule 4: network analysis\n",
      "\n",
      "\n",
      "\n",
      "The SaTScan method has been applied much more broadly and more frequently than the Spatial filtering approach .\n",
      "{4: 'SaTScan method'}\n",
      "Rule 4: SaTScan method\n",
      "\n",
      "\n",
      "\n",
      "The SaTScan method has been applied much more broadly and more frequently than the Spatial filtering approach .\n",
      "{2: 'Spatial filtering approach', 4: 'filtering approach'}\n",
      "Rule 2: Spatial filtering approach\n",
      "\n",
      "\n",
      "\n",
      "Multiple independent statistical tests indicated precipitation as the single most important independent ecological parameter in the niche model for human monkeypox disease .\n",
      "{4: 'niche model'}\n",
      "Rule 4: niche model\n",
      "\n",
      "\n",
      "\n",
      "The variance propagation algorithm computes the mean values and variances of the variable of interest under processes and environmental parameters that fluctuate transiently in a random way .\n",
      "{4: 'variance propagation algorithm'}\n",
      "Rule 4: variance propagation algorithm\n",
      "\n",
      "\n",
      "\n",
      "Finally , with such a large amount of organic solvent involved in making the micelles , the reverse micelle method is difficult to scale-up .\n",
      "{2: 'reverse micelle method', 4: 'micelle method'}\n",
      "Rule 2: reverse micelle method\n",
      "\n",
      "\n",
      "\n",
      "The advantage of adapting a cosinor model to proportional hazards model is its ability to model right censored data .\n",
      "{4: 'cosinor model'}\n",
      "Rule 4: cosinor model\n",
      "\n",
      "\n",
      "\n",
      "The advantage of adapting a cosinor model to proportional hazards model is its ability to model right censored data .\n",
      "{2: 'proportional hazards model', 4: 'hazards model'}\n",
      "Rule 2: proportional hazards model\n",
      "\n",
      "\n",
      "\n",
      "To quote Hollis and Campbell again , “To fully appreciate the potential influence of missing responses , some form of sensitivity analysis is recommended , examining the effect of different strategies on the conclusions.”\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "We have developed a new on-chip cultivation system capable of cultivating cells in a controlled environment using agarose microstructures and a photo-thermal etching method .\n",
      "{2: 'photo-thermal etching method', 4: 'etching method'}\n",
      "Rule 2: photo-thermal etching method\n",
      "\n",
      "\n",
      "\n",
      "The agreement between test and retest was evaluated with 95 % limits of agreement method .\n",
      "{4: 'agreement method'}\n",
      "Rule 4: agreement method\n",
      "\n",
      "\n",
      "\n",
      "The objectives of this study were : 1 ) to gather information concerning the periodicity of walking cycles and to set a threshold between pseudo-periodic and aperiodic walking ; 2 ) to describe the effects of a limited walking pathway on gait pseudo-periodicity ; 3 ) to assess differences in the movements of the lower and of the upper part of the body ; 4 ) to assess the validity of the foot-floor contact method for determining the duration of the walking cycle .\n",
      "{2: 'foot-floor contact method', 4: 'contact method'}\n",
      "Rule 2: foot-floor contact method\n",
      "\n",
      "\n",
      "\n",
      "More recently , surgeons tried to refine this placement strategy with microelectrode recording within the target area .\n",
      "{4: 'placement strategy'}\n",
      "Rule 4: placement strategy\n",
      "\n",
      "\n",
      "\n",
      "Statistical differences were assessed using an ANOVA and Dunnett Post Hoc test was employed for multiple comparison tests at a level of 95 % .\n",
      "{4: 'Post Hoc test'}\n",
      "Rule 4: Post Hoc test\n",
      "\n",
      "\n",
      "\n",
      "Other methods which have been utilized to produce a homologous sequence include cloning , reference strand conformational analysis , Pyrosequencing™ and denaturing high-performance liquid chromatography .\n",
      "{2: 'reference strand conformational analysis', 4: 'reference strand analysis'}\n",
      "Rule 2: reference strand conformational analysis\n",
      "\n",
      "\n",
      "\n",
      "It is important to add that 100 % accuracy is only achieved in identifying new materials by this method provided that a set of at least 20 % control samples are \" trained \" by this ADR spectroscopic method and the logic control relationships are mathematically defined from this result for the Expert Systems Analysis Method which is used to identify the unknown samples .\n",
      "{2: 'ADR spectroscopic method', 4: 'ADR method'}\n",
      "Rule 2: ADR spectroscopic method\n",
      "\n",
      "\n",
      "\n",
      "It is important to add that 100 % accuracy is only achieved in identifying new materials by this method provided that a set of at least 20 % control samples are \" trained \" by this ADR spectroscopic method and the logic control relationships are mathematically defined from this result for the Expert Systems Analysis Method which is used to identify the unknown samples .\n",
      "{4: 'Expert Systems Analysis Method'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 4: Expert Systems Analysis Method\n",
      "\n",
      "\n",
      "\n",
      "This optimal cut-off value , for this study , was determined by using the receiver operating characteristic curve analysis .\n",
      "{2: 'receiver operating characteristic curve analysis', 4: 'receiver operating characteristic curve analysis'}\n",
      "Rule 2: receiver operating characteristic curve analysis\n",
      "\n",
      "\n",
      "\n",
      "The restriction enzyme-mediated inverse PCR method described here incorporates unique restriction enzyme sites at the 5'-ends of inverse tail-to-tail primers .\n",
      "{2: 'restriction enzyme-mediated inverse PCR method', 4: 'restriction enzyme-mediated inverse PCR method'}\n",
      "Rule 2: restriction enzyme-mediated inverse PCR method\n",
      "\n",
      "\n",
      "\n",
      "The overlapping primer method was reported to delete up to 7 bp and had a 40 % mutagenesis efficiency in deleting 411 bp from the ~7.4 kb template in this study .\n",
      "{2: 'overlapping primer method', 4: 'primer method'}\n",
      "Rule 2: overlapping primer method\n",
      "\n",
      "\n",
      "\n",
      "The mortar and pestle was identical to those used by women in the village for grinding millet and was purchased from a local market in Niamey , to avoid appropriating a mortar and pestle currently used for food preparation .\n",
      "{4: 'food preparation'}\n",
      "Rule 4: food preparation\n",
      "\n",
      "\n",
      "\n",
      "The TaqMan method appeared unaffected when using the same samples .\n",
      "{4: 'TaqMan method'}\n",
      "Rule 4: TaqMan method\n",
      "\n",
      "\n",
      "\n",
      "When the results using the TaqMan method were compared with the Snounou nested PCR reference they were shown to be highly concordant , κ = 0.925 .\n",
      "{4: 'TaqMan method'}\n",
      "Rule 4: TaqMan method\n",
      "\n",
      "\n",
      "\n",
      "Its simplicity , high yield , and wide applicability make the TAP method a very useful procedure for protein purification and proteome exploration .\n",
      "{4: 'TAP method'}\n",
      "Rule 4: TAP method\n",
      "\n",
      "\n",
      "\n",
      "A recent paper introduced a high throughput screening strategy , termed substrate-induced gene-expression screening .\n",
      "{2: 'high throughput screening strategy', 4: 'throughput screening strategy'}\n",
      "Rule 2: high throughput screening strategy\n",
      "\n",
      "\n",
      "\n",
      "Moreover , this screening method can detect genes with completely novel DNA sequences , which may have functions distinct from known biocatalysts .\n",
      "{4: 'screening method'}\n",
      "Rule 4: screening method\n",
      "\n",
      "\n",
      "\n",
      "These include the label free emPAI technique ; the label based ICAT , iTRAQ and metabolic labelling as well as the gel-based differential in gel electrophoresis .\n",
      "{2: 'label free emPAI technique', 4: 'label free emPAI technique'}\n",
      "Rule 2: label free emPAI technique\n",
      "\n",
      "\n",
      "\n",
      "StaRT PCR also compared well with the TaqMan quantitative real time PCR method in transcript quantification efficacy , thereby suggesting its use as an accurate , inexpensive , hybridization-independent alternative .\n",
      "{2: 'TaqMan quantitative real time PCR method', 4: 'TaqMan quantitative real time PCR method'}\n",
      "Rule 2: TaqMan quantitative real time PCR method\n",
      "\n",
      "\n",
      "\n",
      "The typical computational analysis , following Eisen et al , clusters the data obtained and then tries to characterize each cluster 's gene set using known gene functions and promoter analysis .\n",
      "{4: 'promoter analysis'}\n",
      "Rule 4: promoter analysis\n",
      "\n",
      "\n",
      "\n",
      "Due to the lack of a crystal structure analysis , biochemical methods have to be applied in order to investigate the details of this receptor-ligand interaction .\n",
      "{2: 'crystal structure analysis', 4: 'structure analysis'}\n",
      "Rule 2: crystal structure analysis\n",
      "\n",
      "\n",
      "\n",
      "We have applied this method to clone the genomic sequence containing the CAG / CTG repeat and its upstream intronic sequence present in spinocerebellar ataxia type 3 or Machado-Joseph disease by a modified DIRECT method .\n",
      "{2: 'modified DIRECT method', 4: 'DIRECT method'}\n",
      "Rule 2: modified DIRECT method\n",
      "\n",
      "\n",
      "\n",
      "Identification of differentially expressed 5'-end mRNA variants by an improved RACE technique .\n",
      "{2: 'improved RACE technique', 4: 'RACE technique'}\n",
      "Rule 2: improved RACE technique\n",
      "\n",
      "\n",
      "\n",
      "As neither dietary assessment method is known to provide completely accurate data and strong association between methods does not imply agreement between methods , agreement was assessed using the Bland-Altman method .\n",
      "{2: 'dietary assessment method', 4: 'assessment method'}\n",
      "Rule 2: dietary assessment method\n",
      "\n",
      "\n",
      "\n",
      "The hexagonal binning technique was applied on the original data by creating larger units to reduce the dimensionality .\n",
      "{2: 'hexagonal binning technique', 4: 'binning technique'}\n",
      "Rule 2: hexagonal binning technique\n",
      "\n",
      "\n",
      "\n",
      "Beer et al. utilized an ad hoc method that fit a series of univariate Cox proportional hazards models and took a linear combination of the resulting coefficients .\n",
      "{4: 'ad hoc method'}\n",
      "Rule 4: ad hoc method\n",
      "\n",
      "\n",
      "\n",
      "Should such unlikely distortions emerge , our fast transform management method allows the volume to be partitioned at any point and structures tracked across the parts .\n",
      "{2: 'fast transform management method', 4: 'management method'}\n",
      "Rule 2: fast transform management method\n",
      "\n",
      "\n",
      "\n",
      "We call this the RANDOM method , illustrated in Figure 6C .\n",
      "{4: 'RANDOM method'}\n",
      "Rule 4: RANDOM method\n",
      "\n",
      "\n",
      "\n",
      "A sequential sampling technique based on the sequential probability ratio test can be used for directly inferring SNP heterozygous rates .\n",
      "{2: 'sequential sampling technique', 4: 'sampling technique'}\n",
      "Rule 2: sequential sampling technique\n",
      "\n",
      "\n",
      "\n",
      "Paralogous verification method is based on the observation that if two proteins interact , their paralogs most likely interact .\n",
      "{2: 'Paralogous verification method', 4: 'verification method'}\n",
      "Rule 2: Paralogous verification method\n",
      "\n",
      "\n",
      "\n",
      "Using these datasets and a supervised classification approach , we evaluated several algorithms for the prediction of high-occupancy MYC binding sites .\n",
      "{2: 'supervised classification approach', 4: 'classification approach'}\n",
      "Rule 2: supervised classification approach\n",
      "\n",
      "\n",
      "\n",
      "We however consider this particular pattern generation technique better suited as a conceptual model to address a developmental paradigm and limitation of current statistical techniques , rather than a guide for directly verifiable experiments .\n",
      "{2: 'particular pattern generation technique', 4: 'pattern generation technique'}\n",
      "Rule 2: particular pattern generation technique\n",
      "\n",
      "\n",
      "\n",
      "Once we established that the HSR model accounts for wild-type expression , we could analyze its dynamics to determine what is responsible for converting the smooth Bcd spatial distribution into the sharp Hb pattern .\n",
      "{4: 'HSR model'}\n",
      "Rule 4: HSR model\n",
      "\n",
      "\n",
      "\n",
      "Two parameters need to be provided for the program - the atomic van der Waals radii and Voronoi plane positioning method .\n",
      "{4: 'Voronoi plane positioning method'}\n",
      "Rule 4: Voronoi plane positioning method\n",
      "\n",
      "\n",
      "\n",
      "The structural cluster analysis was carried out using the method described by Daura and coworkers with a cutoff of 0.25 nm .\n",
      "{2: 'structural cluster analysis', 4: 'cluster analysis'}\n",
      "Rule 2: structural cluster analysis\n",
      "\n",
      "\n",
      "\n",
      "At a given locus , we compute the posterior expected number of substitutions on each branch of the 17 species tree using the CONS model as prior distribution .\n",
      "{4: 'CONS model'}\n",
      "Rule 4: CONS model\n",
      "\n",
      "\n",
      "\n",
      "Second , we assess significance of the same data using an alternative , coalescent-based simulation approach implemented by J .\n",
      "{2: 'alternative coalescent-based simulation approach', 4: 'simulation approach'}\n",
      "Rule 2: alternative coalescent-based simulation approach\n",
      "\n",
      "\n",
      "\n",
      "Using the above power estimates , for each genotyped SNP or SNP tagged at r2 = 1 , we assigned it a power value according to its minor allele frequency for each disease model and study design .\n",
      "{4: 'disease model'}\n",
      "Rule 4: disease model\n",
      "\n",
      "\n",
      "\n",
      "We then used the ABC method , which generates posterior distributions of the parameters of interest deduced from parameter values of simulations satisfying the D ξ criterion , with ξ chosen so that only 5,000 of 250,000 simulations are retained .\n",
      "{4: 'ABC method'}\n",
      "Rule 4: ABC method\n",
      "\n",
      "\n",
      "\n",
      "Recognising the current problem with the publication of false positive findings in genetic association studies we estimated the probability that the association with disease risk found in the meta-analysis of GLI1 SNP rs2228226 represents a true association by adopting the FPRP approach described by Wacholder .\n",
      "{4: 'FPRP approach'}\n",
      "Rule 4: FPRP approach\n",
      "\n",
      "\n",
      "\n",
      "FAFLP analysis as well as ERIC based molecular typing revealed considerable genetic similarity of MIP with MAIC .\n",
      "{4: 'FAFLP analysis'}\n",
      "Rule 4: FAFLP analysis\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The genome-wide admixture mapping analysis was only performed in African-Americans since the SNP set of Smith et al. was specifically selected for the African-American population .\n",
      "{2: 'genome-wide admixture mapping analysis', 4: 'admixture mapping analysis'}\n",
      "Rule 2: genome-wide admixture mapping analysis\n",
      "\n",
      "\n",
      "\n",
      "Due to the nature of the sequencing method , these sequences are distributed randomly across the entire genome .\n",
      "{4: 'sequencing method'}\n",
      "Rule 4: sequencing method\n",
      "\n",
      "\n",
      "\n",
      "In this method , the data are assumed to be derived from a Brownian motion model of evolution and the n samples are converted to n−1 differences between adjacent nodes in the tree , with the variance of the differences computed according to the branch lengths of the tree .\n",
      "{2: 'Brownian motion model', 4: 'motion model'}\n",
      "Rule 2: Brownian motion model\n",
      "\n",
      "\n",
      "\n",
      "In short , the ANOVA model decomposes the probe signals for a given probe set into log = m+Pj+Ai+PAij+ei+eij , where yij is the hybridization signal of the jth probe of the ith sample , m is the average signal , Pj is the average effect of the jth probe , Ai is the average effect of the allele carried by the ith sample at a given genome position , PAij is the interaction effect between probe and allele type , ei is an error term per sample and eij is a probe-specific error term per sample .\n",
      "{4: 'ANOVA model'}\n",
      "Rule 4: ANOVA model\n",
      "\n",
      "\n",
      "\n",
      "To that end , the current study utilizes an innovative testing strategy known as Serological Testing Algorithm for Recent HIV Seroconversion .\n",
      "{2: 'innovative testing strategy', 4: 'testing strategy'}\n",
      "Rule 2: innovative testing strategy\n",
      "\n",
      "\n",
      "\n",
      "eQTL analysis was applied to mouse tissues from an F2 cohort derived from a strain intercross yielding thousands of eQTLs , which were distributed non-randomly over the genome yielding hotspots that each contained hundreds of eQTLs .\n",
      "{4: 'eQTL analysis'}\n",
      "Rule 4: eQTL analysis\n",
      "\n",
      "\n",
      "\n",
      "5 μl of each DNA extract and blank were removed from the ancient lab for DNA quantification prior to and after the library preparation .\n",
      "{4: 'DNA quantification'}\n",
      "Rule 4: DNA quantification\n",
      "\n",
      "\n",
      "\n",
      "5 μl of each DNA extract and blank were removed from the ancient lab for DNA quantification prior to and after the library preparation .\n",
      "{4: 'library preparation'}\n",
      "Rule 4: library preparation\n",
      "\n",
      "\n",
      "\n",
      "Cardiobalistic artifacts were also removed using the FMRIB plugin , in two stages : a. Detection of QRS events is performed on the ECG channel using combined adaptive thresholding , followed by a correction algorithm , which aligns all events and corrects for false positives and negatives .\n",
      "{4: 'correction algorithm'}\n",
      "Rule 4: correction algorithm\n",
      "\n",
      "\n",
      "\n",
      "Certainly , the CSIDOP method is not perfect , and it is limited in predicting functions for proteins with a priori knowledge of interactions .\n",
      "{4: 'CSIDOP method'}\n",
      "Rule 4: CSIDOP method\n",
      "\n",
      "\n",
      "\n",
      "Given the potential ubiquity and significance of bacterial memory , we propose that quantifying history dependent behavior in microbes could be an important piece of the puzzle of bacterial regulation , survival strategy , and evolution .\n",
      "{4: 'survival strategy'}\n",
      "Rule 4: survival strategy\n",
      "\n",
      "\n",
      "\n",
      "The resulting periodogram Iw is compared a periodogram of a randomly permutated Wr using Kolmogorov-Smirnov goodness of fit test .\n",
      "{4: 'fit test'}\n",
      "Rule 4: fit test\n",
      "\n",
      "\n",
      "\n",
      "Period analysis was performed by creating a sliding spectrogram of acquired data to visualize dynamics of all frequencies across time .\n",
      "{4: 'Period analysis'}\n",
      "Rule 4: Period analysis\n",
      "\n",
      "\n",
      "\n",
      "DNA was extracted by the proteinase K / phenol-chloroform method , following standard procedures .\n",
      "{2: 'proteinase K / phenol-chloroform method', 4: 'proteinase K method'}\n",
      "Rule 2: proteinase K / phenol-chloroform method\n",
      "\n",
      "\n",
      "\n",
      "To measure -catechin , 1 g soil was collected in sterile Eppendorf tubes , amended with 1 ml of 100 % methanol , briefly mixed by vigorous vortexing , pelleted by centrifugation for 10 min at 13000 rpm , and the supernatant was placed into vials for HPLC analysis .\n",
      "{4: 'HPLC analysis'}\n",
      "Rule 4: HPLC analysis\n",
      "\n",
      "\n",
      "\n",
      "We applied the KNOWN GENES method to both regions 6q26 and 10q26.3 , obtaining 15 and 10 genes , respectively , after filtering out those candidates that did not overlap with either known or hypothetical genes .\n",
      "{4: 'KNOWN GENES method'}\n",
      "Rule 4: KNOWN GENES method\n",
      "\n",
      "\n",
      "\n",
      "For a detailed review of the CSP technique with respect to the application in BCI see .\n",
      "{4: 'CSP technique'}\n",
      "Rule 4: CSP technique\n",
      "\n",
      "\n",
      "\n",
      "A detailed description of this robust estimation approach for obtaining optimal parameter estimates from species concentration dynamics during muscle ischemia and recovery is presented in Ref .\n",
      "{2: 'robust estimation approach', 4: 'estimation approach'}\n",
      "Rule 2: robust estimation approach\n",
      "\n",
      "\n",
      "\n",
      "To test this prediction , I used the Bayesian coalescence approach implemented in MIGRATE 2.1.3 to estimate the effective number of migrants exchanged per generation between the two populations using both the microsatellite and mtDNA sequence data .\n",
      "{2: 'Bayesian coalescence approach', 4: 'coalescence approach'}\n",
      "Rule 2: Bayesian coalescence approach\n",
      "\n",
      "\n",
      "\n",
      "Deamidated proteins were detected in each lysate preparation by an in vitro assay using recombinant PCMT .\n",
      "{4: 'lysate preparation'}\n",
      "Rule 4: lysate preparation\n",
      "\n",
      "\n",
      "\n",
      "Recently , a Brainbow transgenic strategy has been developed , in which Cre / lox recombination was utilized to create a stochastic choice of expression among three different fluorescence proteins .\n",
      "{2: 'Brainbow transgenic strategy', 4: 'Brainbow strategy'}\n",
      "Rule 2: Brainbow transgenic strategy\n",
      "\n",
      "\n",
      "\n",
      "To test for different fold-changes , we first take the difference between the probe sets on the same chip after data pre-processing and then fit the ANOVA model used above for differential expression to the differences .\n",
      "{4: 'ANOVA model'}\n",
      "Rule 4: ANOVA model\n",
      "\n",
      "\n",
      "\n",
      "Yuan et al. employed a Hidden Markov Model to characterize positioned or delocalized nucleosomes .\n",
      "{2: 'Hidden Markov Model', 4: 'Markov Model'}\n",
      "Rule 2: Hidden Markov Model\n",
      "\n",
      "\n",
      "\n",
      "The third dataset is a track obtained from one of the three female elephant seals from Dataset I , but in this case her track was estimated using the geolocation method .\n",
      "{4: 'geolocation method'}\n",
      "Rule 4: geolocation method\n",
      "\n",
      "\n",
      "\n",
      "The z-score for each microRNA was used to compute a Fisher exact test based on the counts of positive and negative z-scores in upregulated or nonregulated mRNAs .\n",
      "{2: 'Fisher exact test', 4: 'Fisher test'}\n",
      "Rule 2: Fisher exact test\n",
      "\n",
      "\n",
      "\n",
      "Microarray analysis was employed to identify global gene expression changes of EHEC O157∶H7 grown in the presence of epithelial cells , relative to the same organism grown in the absence of epithelial cells .\n",
      "{4: 'Microarray analysis'}\n",
      "Rule 4: Microarray analysis\n",
      "\n",
      "\n",
      "\n",
      "In the present paper , we presented a new linkage mapping method within a finite population under random mating , without pedigree records .\n",
      "{2: 'new linkage mapping method', 4: 'linkage mapping method'}\n",
      "Rule 2: new linkage mapping method\n",
      "\n",
      "\n",
      "\n",
      "Despite the incomplete and unbalanced nature of available datasets , this method performed very well because the PPI dataset used for training this method is very comprehensive , the negative PPI dataset contains the same domain space as the positive dataset providing the basis for an effective comparison , and the scoring algorithm includes a novel combination of orthogonal scoring features that could map the interacting propensity of two domains in many dimensions .\n",
      "{4: 'scoring algorithm'}\n",
      "Rule 4: scoring algorithm\n",
      "\n",
      "\n",
      "\n",
      "The Box-Jenkins method was used to establish a mathematical model of the motor as the best linear fit between the input and output signals .\n",
      "{4: 'Box-Jenkins method'}\n",
      "Rule 4: Box-Jenkins method\n",
      "\n",
      "\n",
      "\n",
      "Our database includes a SNP prioritization score based on the genomic information network method introduced by S .\n",
      "{4: 'SNP prioritization score'}\n",
      "Rule 4: SNP prioritization score\n",
      "\n",
      "\n",
      "\n",
      "Our database includes a SNP prioritization score based on the genomic information network method introduced by S .\n",
      "{2: 'genomic information network method', 4: 'information network method'}\n",
      "Rule 2: genomic information network method\n",
      "\n",
      "\n",
      "\n",
      "Genes with a large number of mouse associations are prioritized more highly , and those with a relatively low number receive little increase in the prioritization score relative to arbitrary genes .\n",
      "{4: 'prioritization score'}\n",
      "Rule 4: prioritization score\n",
      "\n",
      "\n",
      "\n",
      "We use the yellow agouti mouse model of epigenetic variegation to demonstrate this method .\n",
      "{2: 'yellow agouti mouse model', 4: 'agouti mouse model'}\n",
      "Rule 2: yellow agouti mouse model\n",
      "\n",
      "\n",
      "\n",
      "For SPM normalization , we used a template featuring symmetrical left-right hemispheres .\n",
      "{4: 'SPM normalization'}\n",
      "Rule 4: SPM normalization\n",
      "\n",
      "\n",
      "\n",
      "Measurement of the G factor , which relates the increase in sensitized acceptor emission to the loss of donor fluorescence , is critical for calculating FRET efficiency using the three-filter cube method .\n",
      "{2: 'three-filter cube method', 4: 'cube method'}\n",
      "Rule 2: three-filter cube method\n",
      "\n",
      "\n",
      "\n",
      "Associations between immune responses elicited by scSIV and log-transformed , post-challenge viral RNA loads in plasma at peak and at set-point were examined by linear regression analysis .\n",
      "{2: 'linear regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: linear regression analysis\n",
      "\n",
      "\n",
      "\n",
      "With the EC invasion assay the IC50 of native PlcHR was 10 ng / ml , but 100 ng / ml of a heated PlcHR preparation showed no inhibition in the EC invasion assay .\n",
      "{2: 'heated PlcHR preparation', 4: 'PlcHR preparation'}\n",
      "Rule 2: heated PlcHR preparation\n",
      "\n",
      "\n",
      "\n",
      "Three replicate determinations with the same coal and pyrite composition were performed to estimate the uncertainty of the APF method .\n",
      "{4: 'APF method'}\n",
      "Rule 4: APF method\n",
      "\n",
      "\n",
      "\n",
      "The method can identify individuals with coronary endothelial dysfunction and MVF score correlates well with flow-mediated dilation and reflects the vascular function of both conduit arteries and the microvasculature .\n",
      "{4: 'MVF score'}\n",
      "Rule 4: MVF score\n",
      "\n",
      "\n",
      "\n",
      "Large macromolecular complexes can be studied by EM using ‘single particle’ analysis ; the particles are embedded in ice formed by rapid freezing and images are taken using a weak dose of electrons .\n",
      "{2: '‘single particle’ analysis', 4: 'particle’ analysis'}\n",
      "Rule 2: ‘single particle’ analysis\n",
      "\n",
      "\n",
      "\n",
      "This transformation method was further modified by Clough and Bent who demonstrated that the method was just as effective without vacuum infiltration .\n",
      "{4: 'transformation method'}\n",
      "Rule 4: transformation method\n",
      "\n",
      "\n",
      "\n",
      "We calculated the response rate using the Council of American Survey Research Organizations method employed for the Behavioral Risk Factor Surveillance System .\n",
      "{4: 'American Survey Research Organizations method'}\n",
      "Rule 4: American Survey Research Organizations method\n",
      "\n",
      "\n",
      "\n",
      "We created the maps by using adaptive spatial filtering that was adapted from a fixed filter method .\n",
      "{2: 'fixed filter method', 4: 'filter method'}\n",
      "Rule 2: fixed filter method\n",
      "\n",
      "\n",
      "\n",
      "Cytosolic and nuclear fractions of WI38 cells , empty vector transfected WI38 and hTERT WI38 cells were submitted to a 2D-DIGE analysis .\n",
      "{4: '2D-DIGE analysis'}\n",
      "Rule 4: 2D-DIGE analysis\n",
      "\n",
      "\n",
      "\n",
      "In addition , mouth exposure to tar can also be estimated using the filter method .\n",
      "{4: 'filter method'}\n",
      "Rule 4: filter method\n",
      "\n",
      "\n",
      "\n",
      "Of the participants who performed the methacholine test , only 1567 were included in the reference sample after applying the following exclusion criteria : a ) current or former smoking : ; b ) a prior diagnosis of asthma or report of symptoms related to asthma or bronchitis ; c ) atopy : defined by the presence of at least one positive reaction to the eight inhalant allergens tested in a skin prick test ; d ) recent respiratory infection .\n",
      "{4: 'methacholine test'}\n",
      "Rule 4: methacholine test\n",
      "\n",
      "\n",
      "\n",
      "Of the participants who performed the methacholine test , only 1567 were included in the reference sample after applying the following exclusion criteria : a ) current or former smoking : ; b ) a prior diagnosis of asthma or report of symptoms related to asthma or bronchitis ; c ) atopy : defined by the presence of at least one positive reaction to the eight inhalant allergens tested in a skin prick test ; d ) recent respiratory infection .\n",
      "{4: 'skin prick test'}\n",
      "Rule 4: skin prick test\n",
      "\n",
      "\n",
      "\n",
      "If the missing data patterns differ between treatment arms , the summary test statistic approach may be invalid .\n",
      "{2: 'summary test statistic approach', 4: 'summary test approach'}\n",
      "Rule 2: summary test statistic approach\n",
      "\n",
      "\n",
      "\n",
      "AFLP scoring is standardly done by registration of presence and absence of bands , i.e. , in a dominant fashion .\n",
      "{4: 'AFLP scoring'}\n",
      "Rule 4: AFLP scoring\n",
      "\n",
      "\n",
      "\n",
      "Black box algorithms , such as POLYCLASS , MARS , or the D / S / A algorithm are examples of data adaptive methods which can be implemented to determine a candidate estimator .\n",
      "{4: 'A algorithm'}\n",
      "Rule 4: A algorithm\n",
      "\n",
      "\n",
      "\n",
      "Western blot analysis shows the synthesis of major HCV structural proteins .\n",
      "{4: 'Western blot analysis'}\n",
      "Rule 4: Western blot analysis\n",
      "\n",
      "\n",
      "\n",
      "Other applications of Raman spectroscopy outside of cancer have included bone quality assessment for improved estimates of the risk of fracture , corneal hydration gradient analysis , rapid identification of bacterial and fungal infection , and even antibiotic susceptibility testing .\n",
      "{4: 'corneal hydration gradient analysis'}\n",
      "Rule 4: corneal hydration gradient analysis\n",
      "\n",
      "\n",
      "\n",
      "A simpler method , termed Virus Discovery cDNA AFLP , uses cell culture supernatants treated by DNase digestion in a modified cDNA Amplified Fragment Length Polymorphism analysis .\n",
      "{2: 'cDNA Amplified Fragment Length Polymorphism analysis', 4: 'cDNA Amplified Fragment Length Polymorphism analysis'}\n",
      "Rule 2: cDNA Amplified Fragment Length Polymorphism analysis\n",
      "\n",
      "\n",
      "\n",
      "Subtype analysis of influenza A is becoming increasingly prevalent in clinical microbiology laboratories , and is essential for public health surveillance of circulating strains , determination of annual vaccine mismatch and therapeutic decision making with regards to antiviral resistance .\n",
      "{4: 'Subtype analysis'}\n",
      "Rule 4: Subtype analysis\n",
      "\n",
      "\n",
      "\n",
      "This \" medial \" approach allows for early dissection and evaluation of the critical vascular structures .\n",
      "{2: 'medial approach', 4: 'approach'}\n",
      "Rule 2: medial approach\n",
      "\n",
      "\n",
      "\n",
      "Consequently , the total time required for antigen preparation and immunization exceeds three months .\n",
      "{4: 'antigen preparation'}\n",
      "Rule 4: antigen preparation\n",
      "\n",
      "\n",
      "\n",
      "The Principal Component Analysis technique was used to summarize and discover patterns of inter-correlations among the studied measures .\n",
      "{2: 'Principal Component Analysis technique', 4: 'Component Analysis technique'}\n",
      "Rule 2: Principal Component Analysis technique\n",
      "\n",
      "\n",
      "\n",
      "Anisotropy analysis is limited to a single number expressing the directionality of water diffusion at a single voxel with high values indicating all diffusion in one direction and low values indicating diffusion in all directions .\n",
      "{4: 'Anisotropy analysis'}\n",
      "Rule 4: Anisotropy analysis\n",
      "\n",
      "\n",
      "\n",
      "After stimulation and incubation for 2 days , the cultures contained more than 90 % CD3+ T cells as determined by flow cytometric analysis with a monoclonal antibody against CD3 .\n",
      "{2: 'flow cytometric analysis', 4: 'flow analysis'}\n",
      "Rule 2: flow cytometric analysis\n",
      "\n",
      "\n",
      "\n",
      "The areas of child health identified by the stakeholders can be further prioritised using the proposed criteria , which are based on the NSW Strategy for Population Health Surveillance .\n",
      "{4: 'NSW Strategy'}\n",
      "Rule 4: NSW Strategy\n",
      "\n",
      "\n",
      "\n",
      "The results obtained with this combination of filters agreed well with those in the previous study where the SAM method was used with more sample replicates .\n",
      "{4: 'SAM method'}\n",
      "Rule 4: SAM method\n",
      "\n",
      "\n",
      "\n",
      "With this choice , the Gabor filter is very similar to the derivative of a Gaussian used in the Canny algorithm , and it is therefore not surprising that this choice gives good results for step edges .\n",
      "{4: 'Canny algorithm'}\n",
      "Rule 4: Canny algorithm\n",
      "\n",
      "\n",
      "\n",
      "For our first approach , we considered a string-based search algorithm in order to identify conserved nucleotides in the attC sequence .\n",
      "{2: 'string-based search algorithm', 4: 'search algorithm'}\n",
      "Rule 2: string-based search algorithm\n",
      "\n",
      "\n",
      "\n",
      "The Cd-hit algorithm n = 2 was used to calculate protein identity in 852 proteins comprising the entire TBpred training data set .\n",
      "{2: 'Cd-hit algorithm n algorithm', 4: 'Cd-hit algorithm'}\n",
      "Rule 2: Cd-hit algorithm n algorithm\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Peddada', 'lemma': 'peddada', 'upos': 'NOUN', 'xpos': 'NN', 'head': 3, 'deprel': 'nmod:poss', 'misc': 'start_char=0|end_char=7', 'children': []}\n",
      "{'id': 2, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 3, 'deprel': 'case', 'misc': 'start_char=8|end_char=10', 'children': []}\n",
      "{'id': 3, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'nsubj', 'misc': 'start_char=11|end_char=17', 'children': [1, 2]}\n",
      "{'id': 4, 'text': 'then', 'lemma': 'then', 'upos': 'ADV', 'xpos': 'RB', 'head': 5, 'deprel': 'advmod', 'misc': 'start_char=18|end_char=22', 'children': []}\n",
      "{'id': 5, 'text': 'assigns', 'lemma': 'assign', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 0, 'deprel': 'root', 'misc': 'start_char=23|end_char=30', 'children': [3, 4, 6, 24]}\n",
      "{'id': 6, 'text': 'genes', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 5, 'deprel': 'obj', 'misc': 'start_char=31|end_char=36', 'children': [9]}\n",
      "{'id': 7, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'TO', 'head': 9, 'deprel': 'case', 'misc': 'start_char=37|end_char=39', 'children': []}\n",
      "{'id': 8, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 9, 'deprel': 'det', 'misc': 'start_char=40|end_char=43', 'children': []}\n",
      "{'id': 9, 'text': 'cluster', 'lemma': 'cluster', 'upos': 'NOUN', 'xpos': 'NN', 'head': 6, 'deprel': 'nmod', 'misc': 'start_char=44|end_char=51', 'children': [7, 8, 10]}\n",
      "{'id': 10, 'text': 'represented', 'lemma': 'represent', 'upos': 'VERB', 'xpos': 'VBN', 'head': 9, 'deprel': 'acl', 'misc': 'start_char=52|end_char=63', 'children': [16]}\n",
      "{'id': 11, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 16, 'deprel': 'case', 'misc': 'start_char=64|end_char=66', 'children': []}\n",
      "{'id': 12, 'text': 'its', 'lemma': 'its', 'upos': 'PRON', 'xpos': 'PRP$', 'head': 16, 'deprel': 'nmod:poss', 'misc': 'start_char=67|end_char=70', 'children': []}\n",
      "{'id': 13, 'text': 'best', 'lemma': 'best', 'upos': 'ADV', 'xpos': 'RBS', 'head': 14, 'deprel': 'advmod', 'misc': 'start_char=71|end_char=75', 'children': []}\n",
      "{'id': 14, 'text': 'matched', 'lemma': 'match', 'upos': 'VERB', 'xpos': 'VBN', 'head': 16, 'deprel': 'amod', 'misc': 'start_char=76|end_char=83', 'children': [13]}\n",
      "{'id': 15, 'text': 'candidate', 'lemma': 'candidate', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'compound', 'misc': 'start_char=84|end_char=93', 'children': []}\n",
      "{'id': 16, 'text': 'profile', 'lemma': 'profile', 'upos': 'NOUN', 'xpos': 'NN', 'head': 10, 'deprel': 'obl', 'misc': 'start_char=94|end_char=101', 'children': [11, 12, 14, 15, 17]}\n",
      "{'id': 17, 'text': 'determined', 'lemma': 'determine', 'upos': 'VERB', 'xpos': 'VBN', 'head': 16, 'deprel': 'acl', 'misc': 'start_char=102|end_char=112', 'children': [23]}\n",
      "{'id': 18, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 23, 'deprel': 'case', 'misc': 'start_char=113|end_char=115', 'children': []}\n",
      "{'id': 19, 'text': 'some', 'lemma': 'some', 'upos': 'DET', 'xpos': 'DT', 'head': 23, 'deprel': 'det', 'misc': 'start_char=116|end_char=120', 'children': []}\n",
      "{'id': 20, 'text': 'order-restricted', 'lemma': 'order-restricted', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 23, 'deprel': 'amod', 'misc': 'start_char=121|end_char=137', 'children': []}\n",
      "{'id': 21, 'text': 'statistical', 'lemma': 'statistical', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 23, 'deprel': 'amod', 'misc': 'start_char=138|end_char=149', 'children': []}\n",
      "{'id': 22, 'text': 'inference', 'lemma': 'inference', 'upos': 'NOUN', 'xpos': 'NN', 'head': 23, 'deprel': 'compound', 'misc': 'start_char=150|end_char=159', 'children': []}\n",
      "{'id': 23, 'text': 'procedure', 'lemma': 'procedure', 'upos': 'NOUN', 'xpos': 'NN', 'head': 17, 'deprel': 'obl', 'misc': 'start_char=160|end_char=169', 'children': [18, 19, 20, 21, 22]}\n",
      "{'id': 24, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 5, 'deprel': 'punct', 'misc': 'start_char=170|end_char=171', 'children': []}\n",
      "Peddada 's method then assigns genes to the cluster represented by its best matched candidate profile determined by some order-restricted statistical inference procedure .\n",
      "{5: \"Peddada 's method\"}\n",
      "Rule 5: Peddada 's method\n",
      "\n",
      "\n",
      "\n",
      "Figures 1 , 2 and 3 show the prediction accuracy values and their confidence intervals obtained for each splitting technique respectively .\n",
      "{4: 'splitting technique'}\n",
      "Rule 4: splitting technique\n",
      "\n",
      "\n",
      "\n",
      "We propose a two-stage strategy to develop an optimal model : feature selection using correlation analysis , mutual information , and SVM-based recursive feature elimination , and AO prediction using standard and profiled SVM formulations .\n",
      "{4: 'correlation analysis'}\n",
      "Rule 4: correlation analysis\n",
      "\n",
      "\n",
      "\n",
      "Since the SAO algorithm is less sensitive to the choice of the initial gene combination , we present only the results obtained with this algorithm .\n",
      "{4: 'SAO algorithm'}\n",
      "Rule 4: SAO algorithm\n",
      "\n",
      "\n",
      "\n",
      "Total scores were calculated by summing the raw score obtained from the shifted dot product of the sequence profile vectors and the shifted dot product of the secondary structure probability vectors .\n",
      "{4: 'raw score'}\n",
      "Rule 4: raw score\n",
      "\n",
      "\n",
      "\n",
      "This includes a rank-based visualization method that is more robust to noise , a difference display method to aid assessments of cluster quality and detection of outliers , and a projection of high dimensional data into a three dimensional space in order to examine relationships between clusters .\n",
      "{2: 'rank-based visualization method', 4: 'visualization method'}\n",
      "Rule 2: rank-based visualization method\n",
      "\n",
      "\n",
      "\n",
      "Further , residues of hairpin bends , even when separated by a single residue score low when included in quadruplets .\n",
      "{2: 'single residue score low score', 4: 'residue score'}\n",
      "Rule 2: single residue score low score\n",
      "\n",
      "\n",
      "\n",
      "A more intricate Hierarchical Bayes model based on the beta-uniform concept allowing for different parameter values in different intervals appears in .\n",
      "{2: 'intricate Hierarchical Bayes model', 4: 'Bayes model'}\n",
      "Rule 2: intricate Hierarchical Bayes model\n",
      "\n",
      "\n",
      "\n",
      "Fan et al. generalized the SLIM method to account for across-array information , resulting in an aggregated SLIM , so that replication within an array is no longer required .\n",
      "{4: 'SLIM method'}\n",
      "Rule 4: SLIM method\n",
      "\n",
      "\n",
      "\n",
      "The Dynamite compiler allows automated implementation of alignment algorithms from a description of the alignment model .\n",
      "{4: 'alignment model'}\n",
      "Rule 4: alignment model\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 2, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'results', 'lemma': 'result', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 16, 'deprel': 'nsubj', 'misc': 'start_char=4|end_char=11', 'children': [1, 5]}\n",
      "{'id': 3, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 5, 'deprel': 'case', 'misc': 'start_char=12|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'our', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP$', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=15|end_char=18', 'children': []}\n",
      "{'id': 5, 'text': 'comparison', 'lemma': 'comparison', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=19|end_char=29', 'children': [3, 4, 7]}\n",
      "{'id': 6, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 7, 'deprel': 'case', 'misc': 'start_char=30|end_char=37', 'children': []}\n",
      "{'id': 7, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=38|end_char=45', 'children': [6, 10]}\n",
      "{'id': 8, 'text': 'which', 'lemma': 'which', 'upos': 'PRON', 'xpos': 'WDT', 'head': 10, 'deprel': 'nsubj:pass', 'misc': 'start_char=46|end_char=51', 'children': []}\n",
      "{'id': 9, 'text': 'are', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBP', 'head': 10, 'deprel': 'aux:pass', 'misc': 'start_char=52|end_char=55', 'children': []}\n",
      "{'id': 10, 'text': 'designed', 'lemma': 'design', 'upos': 'VERB', 'xpos': 'VBN', 'head': 7, 'deprel': 'acl:relcl', 'misc': 'start_char=56|end_char=64', 'children': [8, 9, 12]}\n",
      "{'id': 11, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 12, 'deprel': 'mark', 'misc': 'start_char=65|end_char=67', 'children': []}\n",
      "{'id': 12, 'text': 'normalize', 'lemma': 'normalize', 'upos': 'VERB', 'xpos': 'VB', 'head': 10, 'deprel': 'xcomp', 'misc': 'start_char=68|end_char=77', 'children': [11, 15]}\n",
      "{'id': 13, 'text': 'boutique', 'lemma': 'boutique', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'compound', 'misc': 'start_char=78|end_char=86', 'children': []}\n",
      "{'id': 14, 'text': 'microarray', 'lemma': 'microarray', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'compound', 'misc': 'start_char=87|end_char=97', 'children': []}\n",
      "{'id': 15, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=98|end_char=102', 'children': [13, 14]}\n",
      "{'id': 16, 'text': 'show', 'lemma': 'show', 'upos': 'VERB', 'xpos': 'VBP', 'head': 0, 'deprel': 'root', 'misc': 'start_char=103|end_char=107', 'children': [2, 26, 54]}\n",
      "{'id': 17, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 26, 'deprel': 'mark', 'misc': 'start_char=108|end_char=112', 'children': []}\n",
      "{'id': 18, 'text': 'Zipf', 'lemma': 'zipf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'nmod:poss', 'misc': 'start_char=113|end_char=117', 'children': []}\n",
      "{'id': 19, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 21, 'deprel': 'case', 'misc': 'start_char=118|end_char=120', 'children': []}\n",
      "{'id': 20, 'text': 'law', 'lemma': 'law', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'compound', 'misc': 'start_char=121|end_char=124', 'children': []}\n",
      "{'id': 21, 'text': 'normalization', 'lemma': 'normalization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'nsubj', 'misc': 'start_char=125|end_char=138', 'children': [18, 19, 20, 22]}\n",
      "{'id': 22, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 21, 'deprel': 'acl', 'misc': 'start_char=139|end_char=144', 'children': [25]}\n",
      "{'id': 23, 'text': 'internal', 'lemma': 'internal', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 25, 'deprel': 'amod', 'misc': 'start_char=145|end_char=153', 'children': []}\n",
      "{'id': 24, 'text': 'control', 'lemma': 'control', 'upos': 'NOUN', 'xpos': 'NN', 'head': 25, 'deprel': 'compound', 'misc': 'start_char=154|end_char=161', 'children': []}\n",
      "{'id': 25, 'text': 'spots', 'lemma': 'spot', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=162|end_char=167', 'children': [23, 24]}\n",
      "{'id': 26, 'text': 'results', 'lemma': 'result', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 16, 'deprel': 'ccomp', 'misc': 'start_char=168|end_char=175', 'children': [17, 21, 33, 35]}\n",
      "{'id': 27, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 33, 'deprel': 'case', 'misc': 'start_char=176|end_char=178', 'children': []}\n",
      "{'id': 28, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 33, 'deprel': 'det', 'misc': 'start_char=179|end_char=180', 'children': []}\n",
      "{'id': 29, 'text': 'relatively', 'lemma': 'relatively', 'upos': 'ADV', 'xpos': 'RB', 'head': 31, 'deprel': 'advmod', 'misc': 'start_char=181|end_char=191', 'children': []}\n",
      "{'id': 30, 'text': 'well', 'lemma': 'well', 'upos': 'ADV', 'xpos': 'RB', 'head': 31, 'deprel': 'advmod', 'misc': 'start_char=192|end_char=196', 'children': []}\n",
      "{'id': 31, 'text': 'normalized', 'lemma': 'normalize', 'upos': 'VERB', 'xpos': 'VBN', 'head': 33, 'deprel': 'amod', 'misc': 'start_char=197|end_char=207', 'children': [29, 30]}\n",
      "{'id': 32, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 33, 'deprel': 'compound', 'misc': 'start_char=208|end_char=212', 'children': []}\n",
      "{'id': 33, 'text': 'set', 'lemma': 'set', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'obl', 'misc': 'start_char=213|end_char=216', 'children': [27, 28, 31, 32]}\n",
      "{'id': 34, 'text': 'when', 'lemma': 'when', 'upos': 'ADV', 'xpos': 'WRB', 'head': 35, 'deprel': 'advmod', 'misc': 'start_char=217|end_char=221', 'children': []}\n",
      "{'id': 35, 'text': 'compared', 'lemma': 'compare', 'upos': 'VERB', 'xpos': 'VBN', 'head': 26, 'deprel': 'advcl', 'misc': 'start_char=222|end_char=230', 'children': [34, 40, 41, 50]}\n",
      "{'id': 36, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'TO', 'head': 40, 'deprel': 'case', 'misc': 'start_char=231|end_char=233', 'children': []}\n",
      "{'id': 37, 'text': 'Zipf', 'lemma': 'zipf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'nmod:poss', 'misc': 'start_char=234|end_char=238', 'children': [38]}\n",
      "{'id': 38, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 37, 'deprel': 'case', 'misc': 'start_char=239|end_char=241', 'children': []}\n",
      "{'id': 39, 'text': 'law', 'lemma': 'law', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'compound', 'misc': 'start_char=242|end_char=245', 'children': []}\n",
      "{'id': 40, 'text': 'normalization', 'lemma': 'normalization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 35, 'deprel': 'obl', 'misc': 'start_char=246|end_char=259', 'children': [36, 37, 39]}\n",
      "{'id': 41, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 35, 'deprel': 'xcomp', 'misc': 'start_char=260|end_char=265', 'children': [44]}\n",
      "{'id': 42, 'text': 'selected', 'lemma': 'select', 'upos': 'VERB', 'xpos': 'VBN', 'head': 44, 'deprel': 'amod', 'misc': 'start_char=266|end_char=274', 'children': []}\n",
      "{'id': 43, 'text': 'housekeeping', 'lemma': 'housekeeping', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 44, 'deprel': 'amod', 'misc': 'start_char=275|end_char=287', 'children': []}\n",
      "{'id': 44, 'text': 'genes', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 41, 'deprel': 'obj', 'misc': 'start_char=288|end_char=293', 'children': [42, 43, 49]}\n",
      "{'id': 45, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 49, 'deprel': 'cc', 'misc': 'start_char=294|end_char=297', 'children': []}\n",
      "{'id': 46, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 49, 'deprel': 'det', 'misc': 'start_char=298|end_char=301', 'children': []}\n",
      "{'id': 47, 'text': 'modified', 'lemma': 'modify', 'upos': 'VERB', 'xpos': 'VBN', 'head': 49, 'deprel': 'amod', 'misc': 'start_char=302|end_char=310', 'children': []}\n",
      "{'id': 48, 'text': 'loess', 'lemma': 'loess', 'upos': 'NOUN', 'xpos': 'NN', 'head': 49, 'deprel': 'compound', 'misc': 'start_char=311|end_char=316', 'children': []}\n",
      "{'id': 49, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 44, 'deprel': 'conj', 'misc': 'start_char=317|end_char=323', 'children': [45, 46, 47, 48]}\n",
      "{'id': 50, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 35, 'deprel': 'xcomp', 'misc': 'start_char=324|end_char=329', 'children': [53]}\n",
      "{'id': 51, 'text': 'selected', 'lemma': 'select', 'upos': 'VERB', 'xpos': 'VBN', 'head': 53, 'deprel': 'amod', 'misc': 'start_char=330|end_char=338', 'children': []}\n",
      "{'id': 52, 'text': 'housekeeping', 'lemma': 'housekeeping', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 53, 'deprel': 'amod', 'misc': 'start_char=339|end_char=351', 'children': []}\n",
      "{'id': 53, 'text': 'genes', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 50, 'deprel': 'obj', 'misc': 'start_char=352|end_char=357', 'children': [51, 52]}\n",
      "{'id': 54, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=358|end_char=359', 'children': []}\n",
      "The results of our comparison between methods which are designed to normalize boutique microarray data show that Zipf 's law normalization using internal control spots results in a relatively well normalized data set when compared to Zipf 's law normalization using selected housekeeping genes and the modified loess method using selected housekeeping genes .\n",
      "{4: 'law normalization', 5: \"Zipf 's law normalization\"}\n",
      "Rule 5: Zipf 's law normalization\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 2, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'results', 'lemma': 'result', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 16, 'deprel': 'nsubj', 'misc': 'start_char=4|end_char=11', 'children': [1, 5]}\n",
      "{'id': 3, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 5, 'deprel': 'case', 'misc': 'start_char=12|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'our', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP$', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=15|end_char=18', 'children': []}\n",
      "{'id': 5, 'text': 'comparison', 'lemma': 'comparison', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=19|end_char=29', 'children': [3, 4, 7]}\n",
      "{'id': 6, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 7, 'deprel': 'case', 'misc': 'start_char=30|end_char=37', 'children': []}\n",
      "{'id': 7, 'text': 'methods', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=38|end_char=45', 'children': [6, 10]}\n",
      "{'id': 8, 'text': 'which', 'lemma': 'which', 'upos': 'PRON', 'xpos': 'WDT', 'head': 10, 'deprel': 'nsubj:pass', 'misc': 'start_char=46|end_char=51', 'children': []}\n",
      "{'id': 9, 'text': 'are', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBP', 'head': 10, 'deprel': 'aux:pass', 'misc': 'start_char=52|end_char=55', 'children': []}\n",
      "{'id': 10, 'text': 'designed', 'lemma': 'design', 'upos': 'VERB', 'xpos': 'VBN', 'head': 7, 'deprel': 'acl:relcl', 'misc': 'start_char=56|end_char=64', 'children': [8, 9, 12]}\n",
      "{'id': 11, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 12, 'deprel': 'mark', 'misc': 'start_char=65|end_char=67', 'children': []}\n",
      "{'id': 12, 'text': 'normalize', 'lemma': 'normalize', 'upos': 'VERB', 'xpos': 'VB', 'head': 10, 'deprel': 'xcomp', 'misc': 'start_char=68|end_char=77', 'children': [11, 15]}\n",
      "{'id': 13, 'text': 'boutique', 'lemma': 'boutique', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'compound', 'misc': 'start_char=78|end_char=86', 'children': []}\n",
      "{'id': 14, 'text': 'microarray', 'lemma': 'microarray', 'upos': 'NOUN', 'xpos': 'NN', 'head': 15, 'deprel': 'compound', 'misc': 'start_char=87|end_char=97', 'children': []}\n",
      "{'id': 15, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 12, 'deprel': 'obj', 'misc': 'start_char=98|end_char=102', 'children': [13, 14]}\n",
      "{'id': 16, 'text': 'show', 'lemma': 'show', 'upos': 'VERB', 'xpos': 'VBP', 'head': 0, 'deprel': 'root', 'misc': 'start_char=103|end_char=107', 'children': [2, 26, 54]}\n",
      "{'id': 17, 'text': 'that', 'lemma': 'that', 'upos': 'SCONJ', 'xpos': 'IN', 'head': 26, 'deprel': 'mark', 'misc': 'start_char=108|end_char=112', 'children': []}\n",
      "{'id': 18, 'text': 'Zipf', 'lemma': 'zipf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'nmod:poss', 'misc': 'start_char=113|end_char=117', 'children': []}\n",
      "{'id': 19, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 21, 'deprel': 'case', 'misc': 'start_char=118|end_char=120', 'children': []}\n",
      "{'id': 20, 'text': 'law', 'lemma': 'law', 'upos': 'NOUN', 'xpos': 'NN', 'head': 21, 'deprel': 'compound', 'misc': 'start_char=121|end_char=124', 'children': []}\n",
      "{'id': 21, 'text': 'normalization', 'lemma': 'normalization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'nsubj', 'misc': 'start_char=125|end_char=138', 'children': [18, 19, 20, 22]}\n",
      "{'id': 22, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 21, 'deprel': 'acl', 'misc': 'start_char=139|end_char=144', 'children': [25]}\n",
      "{'id': 23, 'text': 'internal', 'lemma': 'internal', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 25, 'deprel': 'amod', 'misc': 'start_char=145|end_char=153', 'children': []}\n",
      "{'id': 24, 'text': 'control', 'lemma': 'control', 'upos': 'NOUN', 'xpos': 'NN', 'head': 25, 'deprel': 'compound', 'misc': 'start_char=154|end_char=161', 'children': []}\n",
      "{'id': 25, 'text': 'spots', 'lemma': 'spot', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 22, 'deprel': 'obj', 'misc': 'start_char=162|end_char=167', 'children': [23, 24]}\n",
      "{'id': 26, 'text': 'results', 'lemma': 'result', 'upos': 'VERB', 'xpos': 'VBZ', 'head': 16, 'deprel': 'ccomp', 'misc': 'start_char=168|end_char=175', 'children': [17, 21, 33, 35]}\n",
      "{'id': 27, 'text': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'head': 33, 'deprel': 'case', 'misc': 'start_char=176|end_char=178', 'children': []}\n",
      "{'id': 28, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 33, 'deprel': 'det', 'misc': 'start_char=179|end_char=180', 'children': []}\n",
      "{'id': 29, 'text': 'relatively', 'lemma': 'relatively', 'upos': 'ADV', 'xpos': 'RB', 'head': 31, 'deprel': 'advmod', 'misc': 'start_char=181|end_char=191', 'children': []}\n",
      "{'id': 30, 'text': 'well', 'lemma': 'well', 'upos': 'ADV', 'xpos': 'RB', 'head': 31, 'deprel': 'advmod', 'misc': 'start_char=192|end_char=196', 'children': []}\n",
      "{'id': 31, 'text': 'normalized', 'lemma': 'normalize', 'upos': 'VERB', 'xpos': 'VBN', 'head': 33, 'deprel': 'amod', 'misc': 'start_char=197|end_char=207', 'children': [29, 30]}\n",
      "{'id': 32, 'text': 'data', 'lemma': 'datum', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 33, 'deprel': 'compound', 'misc': 'start_char=208|end_char=212', 'children': []}\n",
      "{'id': 33, 'text': 'set', 'lemma': 'set', 'upos': 'NOUN', 'xpos': 'NN', 'head': 26, 'deprel': 'obl', 'misc': 'start_char=213|end_char=216', 'children': [27, 28, 31, 32]}\n",
      "{'id': 34, 'text': 'when', 'lemma': 'when', 'upos': 'ADV', 'xpos': 'WRB', 'head': 35, 'deprel': 'advmod', 'misc': 'start_char=217|end_char=221', 'children': []}\n",
      "{'id': 35, 'text': 'compared', 'lemma': 'compare', 'upos': 'VERB', 'xpos': 'VBN', 'head': 26, 'deprel': 'advcl', 'misc': 'start_char=222|end_char=230', 'children': [34, 40, 41, 50]}\n",
      "{'id': 36, 'text': 'to', 'lemma': 'to', 'upos': 'ADP', 'xpos': 'TO', 'head': 40, 'deprel': 'case', 'misc': 'start_char=231|end_char=233', 'children': []}\n",
      "{'id': 37, 'text': 'Zipf', 'lemma': 'zipf', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'nmod:poss', 'misc': 'start_char=234|end_char=238', 'children': [38]}\n",
      "{'id': 38, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 37, 'deprel': 'case', 'misc': 'start_char=239|end_char=241', 'children': []}\n",
      "{'id': 39, 'text': 'law', 'lemma': 'law', 'upos': 'NOUN', 'xpos': 'NN', 'head': 40, 'deprel': 'compound', 'misc': 'start_char=242|end_char=245', 'children': []}\n",
      "{'id': 40, 'text': 'normalization', 'lemma': 'normalization', 'upos': 'NOUN', 'xpos': 'NN', 'head': 35, 'deprel': 'obl', 'misc': 'start_char=246|end_char=259', 'children': [36, 37, 39]}\n",
      "{'id': 41, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 35, 'deprel': 'xcomp', 'misc': 'start_char=260|end_char=265', 'children': [44]}\n",
      "{'id': 42, 'text': 'selected', 'lemma': 'select', 'upos': 'VERB', 'xpos': 'VBN', 'head': 44, 'deprel': 'amod', 'misc': 'start_char=266|end_char=274', 'children': []}\n",
      "{'id': 43, 'text': 'housekeeping', 'lemma': 'housekeeping', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 44, 'deprel': 'amod', 'misc': 'start_char=275|end_char=287', 'children': []}\n",
      "{'id': 44, 'text': 'genes', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 41, 'deprel': 'obj', 'misc': 'start_char=288|end_char=293', 'children': [42, 43, 49]}\n",
      "{'id': 45, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 49, 'deprel': 'cc', 'misc': 'start_char=294|end_char=297', 'children': []}\n",
      "{'id': 46, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 49, 'deprel': 'det', 'misc': 'start_char=298|end_char=301', 'children': []}\n",
      "{'id': 47, 'text': 'modified', 'lemma': 'modify', 'upos': 'VERB', 'xpos': 'VBN', 'head': 49, 'deprel': 'amod', 'misc': 'start_char=302|end_char=310', 'children': []}\n",
      "{'id': 48, 'text': 'loess', 'lemma': 'loess', 'upos': 'NOUN', 'xpos': 'NN', 'head': 49, 'deprel': 'compound', 'misc': 'start_char=311|end_char=316', 'children': []}\n",
      "{'id': 49, 'text': 'method', 'lemma': 'method', 'upos': 'NOUN', 'xpos': 'NN', 'head': 44, 'deprel': 'conj', 'misc': 'start_char=317|end_char=323', 'children': [45, 46, 47, 48]}\n",
      "{'id': 50, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 35, 'deprel': 'xcomp', 'misc': 'start_char=324|end_char=329', 'children': [53]}\n",
      "{'id': 51, 'text': 'selected', 'lemma': 'select', 'upos': 'VERB', 'xpos': 'VBN', 'head': 53, 'deprel': 'amod', 'misc': 'start_char=330|end_char=338', 'children': []}\n",
      "{'id': 52, 'text': 'housekeeping', 'lemma': 'housekeeping', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 53, 'deprel': 'amod', 'misc': 'start_char=339|end_char=351', 'children': []}\n",
      "{'id': 53, 'text': 'genes', 'lemma': 'gene', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 50, 'deprel': 'obj', 'misc': 'start_char=352|end_char=357', 'children': [51, 52]}\n",
      "{'id': 54, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=358|end_char=359', 'children': []}\n",
      "The results of our comparison between methods which are designed to normalize boutique microarray data show that Zipf 's law normalization using internal control spots results in a relatively well normalized data set when compared to Zipf 's law normalization using selected housekeeping genes and the modified loess method using selected housekeeping genes .\n",
      "{4: 'law normalization', 5: \"Zipf 's law normalization\"}\n",
      "Rule 5: Zipf 's law normalization\n",
      "\n",
      "\n",
      "\n",
      "The results of our comparison between methods which are designed to normalize boutique microarray data show that Zipf 's law normalization using internal control spots results in a relatively well normalized data set when compared to Zipf 's law normalization using selected housekeeping genes and the modified loess method using selected housekeeping genes .\n",
      "{2: 'modified loess method', 4: 'loess method'}\n",
      "Rule 2: modified loess method\n",
      "\n",
      "\n",
      "\n",
      "First , the extreme diversity of the sediment viral community may reflect the higher diversity of the microbial communities found in sediments using automated rRNA intergenic spacer analysis in comparison with seawater .\n",
      "{2: 'automated rRNA intergenic spacer analysis', 4: 'rRNA intergenic spacer analysis'}\n",
      "Rule 2: automated rRNA intergenic spacer analysis\n",
      "\n",
      "\n",
      "\n",
      "The LOD score requires specification of the disease frequency and penetrance values and therefore falls into the category of parametric scoring functions .\n",
      "{4: 'LOD score'}\n",
      "Rule 4: LOD score\n",
      "\n",
      "\n",
      "\n",
      "We also applied the naive KNN method based on all combinations of data sources and compared it to the RB-KNN methods .\n",
      "{2: 'naive KNN method', 4: 'KNN method'}\n",
      "Rule 2: naive KNN method\n",
      "\n",
      "\n",
      "\n",
      "The approach is based on the association rules discovery technique and it is included in the Engene software package , freely available upon request .\n",
      "{4: 'rules discovery technique'}\n",
      "Rule 4: rules discovery technique\n",
      "\n",
      "\n",
      "\n",
      "One goal of global eQTL analysis is to identify loci controlling the expression variation of gene networks associated with various biological functions .\n",
      "{2: 'global eQTL analysis', 4: 'eQTL analysis'}\n",
      "Rule 2: global eQTL analysis\n",
      "\n",
      "\n",
      "\n",
      "ROC analysis displays the relationship between the proportion of true positives and false positives resulting from each possible decision threshold value in a two-class classification problem .\n",
      "{4: 'ROC analysis'}\n",
      "Rule 4: ROC analysis\n",
      "\n",
      "\n",
      "\n",
      "This data set has been used in when this classification approach was reported .\n",
      "{4: 'classification approach'}\n",
      "Rule 4: classification approach\n",
      "\n",
      "\n",
      "\n",
      "It consists of a support vector machine component as well as a novel phrase-based clustering algorithm .\n",
      "{2: 'novel phrase-based clustering algorithm', 4: 'clustering algorithm'}\n",
      "Rule 2: novel phrase-based clustering algorithm\n",
      "\n",
      "\n",
      "\n",
      "The SS-score was added to the profile-profile method Prob-score 's score .\n",
      "{2: 'profile-profile method score', 4: 'method score'}\n",
      "Rule 2: profile-profile method score\n",
      "\n",
      "\n",
      "\n",
      "Microarrays were evaluated using four different probe set summaries : 1 ) single chip ; and 2 ) chip comparison algorithm of Affymetrix ' Microarray Suite 5.0 ; 3 ) Robust Multi-Array Analysis developed by Irizarry et al. ; and 4 ) Model Based Expression Index of Li and Wong .\n",
      "{4: 'chip comparison algorithm'}\n",
      "Rule 4: chip comparison algorithm\n",
      "\n",
      "\n",
      "\n",
      "At the genomic scale , we showed that in all three datasets the correlation regime between genes selected by statistical significance analysis follow a similar behavior , which is compatible with the emergence of coherence in the gene expression dynamics following cell perturbation .\n",
      "{2: 'statistical significance analysis', 4: 'significance analysis'}\n",
      "Rule 2: statistical significance analysis\n",
      "\n",
      "\n",
      "\n",
      "The activity of the compound was confirmed by FACS analysis where an accumulation of cells in G1 phase of cell cycle was observed , associated with a reduction in DNA duplication as measured by a decrease in BrdU incorporation .\n",
      "{4: 'FACS analysis'}\n",
      "Rule 4: FACS analysis\n",
      "\n",
      "\n",
      "\n",
      "The method can successfully distinguish known drug targets from putative non drug targets at an accuracy of 84 % in 10-fold cross-validation test .\n",
      "{2: '10-fold cross-validation test', 4: 'cross-validation test'}\n",
      "Rule 2: 10-fold cross-validation test\n",
      "\n",
      "\n",
      "\n",
      "Following success by either expansion method , q is updated and domain expansion is performed again .\n",
      "{4: 'expansion method'}\n",
      "Rule 4: expansion method\n",
      "\n",
      "\n",
      "\n",
      "The fold recognition approach relies on secondary structure element alignments , using the DomSSEA method , in order to find domain boundaries in more distant homologs .\n",
      "{2: 'fold recognition approach', 4: 'recognition approach'}\n",
      "Rule 2: fold recognition approach\n",
      "\n",
      "\n",
      "\n",
      "The fold recognition approach relies on secondary structure element alignments , using the DomSSEA method , in order to find domain boundaries in more distant homologs .\n",
      "{4: 'DomSSEA method'}\n",
      "Rule 4: DomSSEA method\n",
      "\n",
      "\n",
      "\n",
      "The study of multiple distinct mutations can be addressed by formal methods , such as statistical diversity analysis based on information theory .\n",
      "{2: 'statistical diversity analysis', 4: 'diversity analysis'}\n",
      "Rule 2: statistical diversity analysis\n",
      "\n",
      "\n",
      "\n",
      "After inspection of normalized data , the cubic spline method was discarded since the data produced was not correctly normalized between the arrays , thus requiring further manipulation on data that we decided not to apply .\n",
      "{2: 'cubic spline method', 4: 'spline method'}\n",
      "Rule 2: cubic spline method\n",
      "\n",
      "\n",
      "\n",
      "When the significance of the summary statistic is measured by permuting class labels , the method preserves gene-gene correlations and when applicable , would give similar result to the presented method .\n",
      "{4: 'summary statistic'}\n",
      "Rule 4: summary statistic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "We have developed an algorithm that uses the coordinates of all the exact matches or high similarity local alignments , clusters them with respect to the main diagonal in the dot plot using a weighted linear regression technique , and identifies the starting and ending coordinates of the region of interest .\n",
      "{2: 'weighted linear regression technique', 4: 'regression technique'}\n",
      "Rule 2: weighted linear regression technique\n",
      "\n",
      "\n",
      "\n",
      "Note that one can not use all 31 predictor time points in this classical regression approach , since then the number of predictors would be larger than the sample size which is not possible .\n",
      "{2: 'classical regression approach', 4: 'regression approach'}\n",
      "Rule 2: classical regression approach\n",
      "\n",
      "\n",
      "\n",
      "The top three hits for each reference gene against each comparison genome are stored in the database including details such as a gene identifier , alignment start and end , and BLAST scores such as e-value , percent identity and bit score .\n",
      "{4: 'bit score'}\n",
      "Rule 4: bit score\n",
      "\n",
      "\n",
      "\n",
      "Here we present the design and implementation of a novel and robust online phenotype discovery method with broad applicability that can be used in diverse experimental contexts , especially high-throughput RNAi screens .\n",
      "{2: 'novel and robust online phenotype discovery method', 4: 'online phenotype discovery method'}\n",
      "Rule 2: novel and robust online phenotype discovery method\n",
      "\n",
      "\n",
      "\n",
      "Using the selected features , a decision tree method can achieve 82.6 % overall accuracy with 0.607 Matthews Correlation Coefficient in cross-validation .\n",
      "{4: 'decision tree method'}\n",
      "Rule 4: decision tree method\n",
      "\n",
      "\n",
      "\n",
      "Since the Brier score is not based on any specific model assumptions , the predictive accuracy of various model families and estimation techniques can be measured on the same scale .\n",
      "{4: 'Brier score'}\n",
      "Rule 4: Brier score\n",
      "\n",
      "\n",
      "\n",
      "We propose an alternative baseline correction method based on a penalized smoothing model .\n",
      "{2: 'alternative baseline correction method', 4: 'baseline correction method'}\n",
      "Rule 2: alternative baseline correction method\n",
      "\n",
      "\n",
      "\n",
      "We propose an alternative baseline correction method based on a penalized smoothing model .\n",
      "{2: 'penalized smoothing model', 4: 'smoothing model'}\n",
      "Rule 2: penalized smoothing model\n",
      "\n",
      "\n",
      "\n",
      "This enhanced method uses the dependency graph technique of the next reaction method to only update the propensity functions which are affected by the firing of a reaction .\n",
      "{4: 'dependency graph technique'}\n",
      "Rule 4: dependency graph technique\n",
      "\n",
      "\n",
      "\n",
      "We used the surname and all initials method of author name construction .\n",
      "{4: 'initials method'}\n",
      "Rule 4: initials method\n",
      "\n",
      "\n",
      "\n",
      "The rFDP is defined to be the difference between the FDP score of a gene pair and its expected FDP score as given by a Poisson distribution .\n",
      "{4: 'FDP score'}\n",
      "Rule 4: FDP score\n",
      "\n",
      "\n",
      "\n",
      "Here , we present DISCLOSE , an exploratory application that benchmarks clustering methods using functional annotations and a de novo motif discovery algorithm .\n",
      "{2: 'de novo motif discovery algorithm', 4: 'motif discovery algorithm'}\n",
      "Rule 2: de novo motif discovery algorithm\n",
      "\n",
      "\n",
      "\n",
      "In principle , correctly built protein families are highly preferable to mere sorted lists of pairwise matches for performing phylogenetic profiling , but there may be no way to know in advance how to set the granularity of the protein clustering method correctly to solve a particular biological problem .\n",
      "{4: 'protein clustering method'}\n",
      "Rule 4: protein clustering method\n",
      "\n",
      "\n",
      "\n",
      "A straight forward approach for the isolation of differentially expressed genes was achieved by the \" Suppression Subtractive Hybridization \" method .\n",
      "{2: 'Suppression Subtractive Hybridization method', 4: 'Suppression Subtractive Hybridization method'}\n",
      "Rule 2: Suppression Subtractive Hybridization method\n",
      "\n",
      "\n",
      "\n",
      "The mismatch-specific endonuclease method for beta-thalassemia mutations detection is merely as a model for other disease genes for which large scale , high-throughput mutation scanning .\n",
      "{2: 'mismatch-specific endonuclease method', 4: 'endonuclease method'}\n",
      "Rule 2: mismatch-specific endonuclease method\n",
      "\n",
      "\n",
      "\n",
      "However , neither the original RM method provide enough data to calculate the duration of all cell cycle phases , consequently the duration of the whole cycle , and GF of a tumour .\n",
      "{2: 'original RM method', 4: 'RM method'}\n",
      "Rule 2: original RM method\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'The', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 2, 'deprel': 'det', 'misc': 'start_char=0|end_char=3', 'children': []}\n",
      "{'id': 2, 'text': 'ratio', 'lemma': 'ratio', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'nsubj:pass', 'misc': 'start_char=4|end_char=9', 'children': [1, 5]}\n",
      "{'id': 3, 'text': 'between', 'lemma': 'between', 'upos': 'ADP', 'xpos': 'IN', 'head': 5, 'deprel': 'case', 'misc': 'start_char=10|end_char=17', 'children': []}\n",
      "{'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 5, 'deprel': 'det', 'misc': 'start_char=18|end_char=21', 'children': []}\n",
      "{'id': 5, 'text': 'area', 'lemma': 'area', 'upos': 'NOUN', 'xpos': 'NN', 'head': 2, 'deprel': 'nmod', 'misc': 'start_char=22|end_char=26', 'children': [3, 4, 6]}\n",
      "{'id': 6, 'text': 'occupied', 'lemma': 'occupy', 'upos': 'VERB', 'xpos': 'VBN', 'head': 5, 'deprel': 'acl', 'misc': 'start_char=27|end_char=35', 'children': [8]}\n",
      "{'id': 7, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 8, 'deprel': 'case', 'misc': 'start_char=36|end_char=38', 'children': []}\n",
      "{'id': 8, 'text': 'lymphatics', 'lemma': 'lymphatic', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 6, 'deprel': 'obl', 'misc': 'start_char=39|end_char=49', 'children': [7, 13]}\n",
      "{'id': 9, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 13, 'deprel': 'cc', 'misc': 'start_char=50|end_char=53', 'children': []}\n",
      "{'id': 10, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 13, 'deprel': 'det', 'misc': 'start_char=54|end_char=57', 'children': []}\n",
      "{'id': 11, 'text': 'total', 'lemma': 'total', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 13, 'deprel': 'amod', 'misc': 'start_char=58|end_char=63', 'children': []}\n",
      "{'id': 12, 'text': 'tissue', 'lemma': 'tissue', 'upos': 'NOUN', 'xpos': 'NN', 'head': 13, 'deprel': 'compound', 'misc': 'start_char=64|end_char=70', 'children': []}\n",
      "{'id': 13, 'text': 'area', 'lemma': 'area', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'conj', 'misc': 'start_char=71|end_char=75', 'children': [9, 10, 11, 12]}\n",
      "{'id': 14, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 16, 'deprel': 'aux:pass', 'misc': 'start_char=76|end_char=79', 'children': []}\n",
      "{'id': 15, 'text': 'then', 'lemma': 'then', 'upos': 'ADV', 'xpos': 'RB', 'head': 16, 'deprel': 'advmod', 'misc': 'start_char=80|end_char=84', 'children': []}\n",
      "{'id': 16, 'text': 'determined', 'lemma': 'determine', 'upos': 'VERB', 'xpos': 'VBN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=85|end_char=95', 'children': [2, 14, 15, 19, 24, 32]}\n",
      "{'id': 17, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 19, 'deprel': 'case', 'misc': 'start_char=96|end_char=99', 'children': []}\n",
      "{'id': 18, 'text': 'each', 'lemma': 'each', 'upos': 'DET', 'xpos': 'DT', 'head': 19, 'deprel': 'det', 'misc': 'start_char=100|end_char=104', 'children': []}\n",
      "{'id': 19, 'text': 'section', 'lemma': 'section', 'upos': 'NOUN', 'xpos': 'NN', 'head': 16, 'deprel': 'obl', 'misc': 'start_char=105|end_char=112', 'children': [17, 18]}\n",
      "{'id': 20, 'text': 'and', 'lemma': 'and', 'upos': 'CONJ', 'xpos': 'CC', 'head': 24, 'deprel': 'cc', 'misc': 'start_char=113|end_char=116', 'children': []}\n",
      "{'id': 21, 'text': 'statistical', 'lemma': 'statistical', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 22, 'deprel': 'amod', 'misc': 'start_char=117|end_char=128', 'children': []}\n",
      "{'id': 22, 'text': 'analysis', 'lemma': 'analysis', 'upos': 'NOUN', 'xpos': 'NN', 'head': 24, 'deprel': 'nsubj:pass', 'misc': 'start_char=129|end_char=137', 'children': [21]}\n",
      "{'id': 23, 'text': 'was', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBD', 'head': 24, 'deprel': 'aux:pass', 'misc': 'start_char=138|end_char=141', 'children': []}\n",
      "{'id': 24, 'text': 'performed', 'lemma': 'perform', 'upos': 'VERB', 'xpos': 'VBN', 'head': 16, 'deprel': 'conj', 'misc': 'start_char=142|end_char=151', 'children': [20, 22, 23, 25]}\n",
      "{'id': 25, 'text': 'using', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBG', 'head': 24, 'deprel': 'xcomp', 'misc': 'start_char=152|end_char=157', 'children': [31]}\n",
      "{'id': 26, 'text': 'a', 'lemma': 'a', 'upos': 'DET', 'xpos': 'DT', 'head': 31, 'deprel': 'det', 'misc': 'start_char=158|end_char=159', 'children': []}\n",
      "{'id': 27, 'text': 'Wilcoxon', 'lemma': 'wilcoxon', 'upos': 'NOUN', 'xpos': 'NN', 'head': 31, 'deprel': 'nmod:poss', 'misc': 'start_char=160|end_char=168', 'children': []}\n",
      "{'id': 28, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 31, 'deprel': 'case', 'misc': 'start_char=169|end_char=171', 'children': []}\n",
      "{'id': 29, 'text': 'rank', 'lemma': 'rank', 'upos': 'NOUN', 'xpos': 'NN', 'head': 31, 'deprel': 'compound', 'misc': 'start_char=172|end_char=176', 'children': []}\n",
      "{'id': 30, 'text': 'sum', 'lemma': 'sum', 'upos': 'NOUN', 'xpos': 'NN', 'head': 31, 'deprel': 'compound', 'misc': 'start_char=177|end_char=180', 'children': []}\n",
      "{'id': 31, 'text': 'test', 'lemma': 'test', 'upos': 'NOUN', 'xpos': 'NN', 'head': 25, 'deprel': 'obj', 'misc': 'start_char=181|end_char=185', 'children': [26, 27, 28, 29, 30]}\n",
      "{'id': 32, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 16, 'deprel': 'punct', 'misc': 'start_char=186|end_char=187', 'children': []}\n",
      "The ratio between the area occupied by lymphatics and the total tissue area was then determined for each section and statistical analysis was performed using a Wilcoxon 's rank sum test .\n",
      "{4: 'rank sum test', 5: \"Wilcoxon 's rank sum test\"}\n",
      "Rule 5: Wilcoxon 's rank sum test\n",
      "\n",
      "\n",
      "\n",
      "The repeated PCR product would be cloned into the PMD-18-T vector and amplified in E. Coli top10 for further sequencing analysis , if the two variations occurred in a sample .\n",
      "{2: 'further sequencing analysis', 4: 'sequencing analysis'}\n",
      "Rule 2: further sequencing analysis\n",
      "\n",
      "\n",
      "\n",
      "Thus , 97 % of all mutations in this cohort that we could find routinely following our established protocols could be analysed with the Roche Amplicor Cystic Fibrosis test .\n",
      "{2: 'Roche Amplicor Cystic Fibrosis test', 4: 'Roche Amplicor Cystic Fibrosis test'}\n",
      "Rule 2: Roche Amplicor Cystic Fibrosis test\n",
      "\n",
      "\n",
      "\n",
      "The key element in the TIUKO method is the targeting of multi-potential , undifferentiated cells .\n",
      "{4: 'TIUKO method'}\n",
      "Rule 4: TIUKO method\n",
      "\n",
      "\n",
      "\n",
      "While highly efficient , this preparation has some inherent limitations that restrict its use for transfection studies and cell fate analysis .\n",
      "{4: 'cell fate analysis'}\n",
      "Rule 4: cell fate analysis\n",
      "\n",
      "\n",
      "\n",
      "To prevent type I error as much as possible in the multiple use of regression analysis , a Bonferroni correction was applied through the division by the number of plantar regions .\n",
      "{4: 'regression analysis'}\n",
      "Rule 4: regression analysis\n",
      "\n",
      "\n",
      "\n",
      "Allelic richness , a measure of allelic variation that takes into account differences in sample sizes among populations , was estimated with the rarefaction method .\n",
      "{4: 'rarefaction method'}\n",
      "Rule 4: rarefaction method\n",
      "\n",
      "\n",
      "\n",
      "The ' context-bound learning method ' is a bottom-up , adult learning , experiential approach that relies on clinicians themselves evaluating the importance of the issue and then reflecting on authentic case scenarios .\n",
      "{2: 'context-bound learning method', 4: 'learning method'}\n",
      "Rule 2: context-bound learning method\n",
      "\n",
      "\n",
      "\n",
      "To enter the map , the position for the SNPs had to exceed a LOD score of two with the Flips Option set to two .\n",
      "{4: 'LOD score'}\n",
      "Rule 4: LOD score\n",
      "\n",
      "\n",
      "\n",
      "A new TaqMan allelic discrimination genotype method was successfully applied to genomic DNA samples derived from blood , buccal swabs , snap frozen tissue and paraffin blocks .\n",
      "{2: 'new TaqMan allelic discrimination genotype method', 4: 'TaqMan allelic discrimination genotype method'}\n",
      "Rule 2: new TaqMan allelic discrimination genotype method\n",
      "\n",
      "\n",
      "\n",
      "The original transmission disequilibrium test was proposed to test genetic linkage in the presence of association between a candidate marker and disease phenotype by comparing , among heterozygous parents , the total number of a specific allele transmitted to the affected offspring with what would be expected under the null hypothesis .\n",
      "{2: 'original transmission disequilibrium test', 4: 'transmission disequilibrium test'}\n",
      "Rule 2: original transmission disequilibrium test\n",
      "\n",
      "\n",
      "\n",
      "This may affect the false positive rate for the association test , compared to case-control design based on independent samples .\n",
      "{4: 'association test'}\n",
      "Rule 4: association test\n",
      "\n",
      "\n",
      "\n",
      "For the haplotype analysis , identification of the minimal set of SNPs that could account for the genotypic diversity was made by systematic enumeration in each block .\n",
      "{4: 'haplotype analysis'}\n",
      "Rule 4: haplotype analysis\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As in our previous investigation , logistic regression analysis was used to test for the main effects of each marker locus .\n",
      "{2: 'logistic regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: logistic regression analysis\n",
      "\n",
      "\n",
      "\n",
      "The LRT test statistic was calculated as twice the difference between the likelihoods of the model fitting the QTL and without fitting the QTL .\n",
      "{4: 'LRT test statistic'}\n",
      "Rule 4: LRT test statistic\n",
      "\n",
      "\n",
      "\n",
      "The method is developed for the allelic association analysis of pooled DNA samples , but it can be easily generalized to the analysis of individually genotyped samples .\n",
      "{2: 'allelic association analysis', 4: 'association analysis'}\n",
      "Rule 2: allelic association analysis\n",
      "\n",
      "\n",
      "\n",
      "Comparison of microarray gene level signals with real-time PCR data suggests that the Globin PNAs-Affymetrix method produces the most accurate microarray results , although , all methods produce data that correlate well with the RT-PCR measurements .\n",
      "{2: 'Globin PNAs-Affymetrix method', 4: 'Globin method'}\n",
      "Rule 2: Globin PNAs-Affymetrix method\n",
      "\n",
      "\n",
      "\n",
      "We here describe a technique , called modified methylation-specific digital karyotyping based on methylation-specific digital karyotyping with a novel sequencing approach .\n",
      "{2: 'novel sequencing approach', 4: 'sequencing approach'}\n",
      "Rule 2: novel sequencing approach\n",
      "\n",
      "\n",
      "\n",
      "This is achieved by evaluating a set of positive and negative controls by receiver operating characteristic analysis .\n",
      "{2: 'receiver operating characteristic analysis', 4: 'receiver operating analysis'}\n",
      "Rule 2: receiver operating characteristic analysis\n",
      "\n",
      "\n",
      "\n",
      "Using a simple integration method called simple summation , we calculated the sum of the probabilistic output q to obtain the probability of each class , when the selected class subset l included the class .\n",
      "{2: 'simple integration method', 4: 'integration method'}\n",
      "Rule 2: simple integration method\n",
      "\n",
      "\n",
      "\n",
      "This demonstrates that octamer analysis can detect long functional units as clusters of octamers .\n",
      "{4: 'octamer analysis'}\n",
      "Rule 4: octamer analysis\n",
      "\n",
      "\n",
      "\n",
      "When combined with a suggested normalization method involving the logit transformation , Lemon et al. called the resulting method the Logit-t .\n",
      "{2: 'suggested normalization method', 4: 'normalization method'}\n",
      "Rule 2: suggested normalization method\n",
      "\n",
      "\n",
      "\n",
      "These specimens , which had high average plate CT values were excluded from the final study analysis due to unsatisfactory RT-PCR data .\n",
      "{2: 'final study analysis', 4: 'study analysis'}\n",
      "Rule 2: final study analysis\n",
      "\n",
      "\n",
      "\n",
      "An initial guess for site parameters was obtained from Mobs and maximum likelihood parameters were obtained using a simplex algorithm .\n",
      "{4: 'simplex algorithm'}\n",
      "Rule 4: simplex algorithm\n",
      "\n",
      "\n",
      "\n",
      "To evaluate differences in gene expression a relative quantification method was chosen where the expression of the target gene is standardized by a non-regulated reference gene ; consequently , three replicates of each sample and endogenous control were amplified .\n",
      "{2: 'relative quantification method', 4: 'quantification method'}\n",
      "Rule 2: relative quantification method\n",
      "\n",
      "\n",
      "\n",
      "This filtering method discards approximately half of the total amount of probesets .\n",
      "{4: 'filtering method'}\n",
      "Rule 4: filtering method\n",
      "\n",
      "\n",
      "\n",
      "We then used a \" slide and fold \" method to construct RNA structures in 5 ' and 3 ' UTRs .\n",
      "{4: 'method'}\n",
      "Rule 4: method\n",
      "\n",
      "\n",
      "\n",
      "A GENSCAN gene model prediction algorithm was used to predict introns and exons , and the resulting predictions were searched against the Uniref50 database .\n",
      "{4: 'GENSCAN gene model prediction algorithm'}\n",
      "Rule 4: GENSCAN gene model prediction algorithm\n",
      "\n",
      "\n",
      "\n",
      "However , our MS data acquisition strategy consisted in recording MS spectra resulting from 800 laser shots , thus improving signal-to-noise ratio and sensitivity , as well as quantification precision .\n",
      "{4: 'MS data acquisition strategy'}\n",
      "Rule 4: MS data acquisition strategy\n",
      "\n",
      "\n",
      "\n",
      "One critical , but often overlooked , assumption , of the Bonferroni correction method , is the assumption that all the tests are independent .\n",
      "{4: 'Bonferroni correction method'}\n",
      "Rule 4: Bonferroni correction method\n",
      "\n",
      "\n",
      "\n",
      "To obtain p-values , observed values of WKS were compared with randomly sampled WKS statistics based on the product of randomly sampled weights , from a uniform distribution within the empirical range of calculated weights for all genes , and randomly sampled KS statistics , sampled from the theoretical distribution of the KS statistic .\n",
      "{4: 'KS statistic'}\n",
      "Rule 4: KS statistic\n",
      "\n",
      "\n",
      "\n",
      "Given the nature of the BCa method , the resulting confidence interval need not be symmetric .\n",
      "{4: 'BCa method'}\n",
      "Rule 4: BCa method\n",
      "\n",
      "\n",
      "\n",
      "We employed a modified nominal group technique .\n",
      "{2: 'modified nominal group technique', 4: 'group technique'}\n",
      "Rule 2: modified nominal group technique\n",
      "\n",
      "\n",
      "\n",
      "Indeed , RT-PCR is advantageous for cytokine transcript analysis because it can be used to quickly monitor the simultaneous expression of an array of cytokines from a single sample and requires only small quantities of template material .\n",
      "{4: 'cytokine transcript analysis'}\n",
      "Rule 4: cytokine transcript analysis\n",
      "\n",
      "\n",
      "\n",
      "Extrachromosomal switch circles were detected by a nested PCR strategy as previously described by others .\n",
      "{2: 'nested PCR strategy', 4: 'PCR strategy'}\n",
      "Rule 2: nested PCR strategy\n",
      "\n",
      "\n",
      "\n",
      "Heterogeneous VISA strain Mu3 was used as control in population analysis profile method .\n",
      "{4: 'population analysis profile method'}\n",
      "Rule 4: population analysis profile method\n",
      "\n",
      "\n",
      "\n",
      "The entire test thus requires a total of 5 days from inoculation to assay of infection , making this a relatively rapid and efficient animal model .\n",
      "{2: 'rapid and efficient animal model', 4: 'animal model'}\n",
      "Rule 2: rapid and efficient animal model\n",
      "\n",
      "\n",
      "\n",
      "Throughout the data analysis the occurrence of key findings are noted by using simple counts .\n",
      "{4: 'data analysis'}\n",
      "Rule 4: data analysis\n",
      "\n",
      "\n",
      "\n",
      "To test condition 3 we fit a logistic regression model with both relationship style and the specialty choice factors that met condition 2 , with the outcome being a match in a non-primary care versus primary care specialty .\n",
      "{2: 'logistic regression model', 4: 'regression model'}\n",
      "Rule 2: logistic regression model\n",
      "\n",
      "\n",
      "\n",
      "The SNaPshot method has , however , previously been shown to be a sensitive and reproducible method for the detection of heteroplasmic mutations in different tissues but since no heteroplasmic mutations were detected in the present study , and as no heteroplasmic positive controls were available for testing , we can not at this stage , comment on how well suited our method is for the detection of heteroplasmic mutations .\n",
      "{4: 'SNaPshot method'}\n",
      "Rule 4: SNaPshot method\n",
      "\n",
      "\n",
      "\n",
      "In this study , we describe an application of the fluorescent labeling of PCR fragments using a fluorescent-adapted primer for SSCP analysis as a novel method .\n",
      "{4: 'SSCP analysis'}\n",
      "Rule 4: SSCP analysis\n",
      "\n",
      "\n",
      "\n",
      "This improved RSP method was applied to genotype 92 human samples collected from The Johns Hopkins Hospital .\n",
      "{2: 'improved RSP method', 4: 'RSP method'}\n",
      "Rule 2: improved RSP method\n",
      "\n",
      "\n",
      "\n",
      "Confirmation of the validation of the mutation detection method was based on the use of known positive DNA controls for the three polymorphisms provided by McGill University .\n",
      "{4: 'mutation detection method'}\n",
      "Rule 4: mutation detection method\n",
      "\n",
      "\n",
      "\n",
      "Multiple hypothesis testing was controlled using the false discovery rate approach proposed by Benjamini and Hochberg .\n",
      "{2: 'false discovery rate approach', 4: 'discovery rate approach'}\n",
      "Rule 2: false discovery rate approach\n",
      "\n",
      "\n",
      "\n",
      "If P1 ≤ α / k , test 1 is significant , and now P2 is examined .\n",
      "{4: 'α test'}\n",
      "Rule 4: α test\n",
      "\n",
      "\n",
      "\n",
      "Mainly on the basis of the sensitivity at the recommended testing threshold , but also taking account of wide applicability and ease of data collection and data entry , we conclude that the Penn II model is best suited for use in our clinic population .\n",
      "{4: 'Penn model'}\n",
      "Rule 4: Penn model\n",
      "\n",
      "\n",
      "\n",
      "This is the first time , to our knowledge , that the disutility of perioperative morbidity has been measured directly using the SG method .\n",
      "{4: 'SG method'}\n",
      "Rule 4: SG method\n",
      "\n",
      "\n",
      "\n",
      "For each of the 10 ANNs , we performed a sensitivity analysis that determines the influence of each input variable on the output of the ANN , the prediction score .\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "A Markov model is a mathematical representation of patients in a series of health states .\n",
      "{4: 'Markov model'}\n",
      "Rule 4: Markov model\n",
      "\n",
      "\n",
      "\n",
      "One approach sometimes used to adjust AFs for other known risk factors considers adjusted odds ratio estimates from multivariable logistic regression analysis in Levin 's formula .\n",
      "{2: 'multivariable logistic regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: multivariable logistic regression analysis\n",
      "\n",
      "\n",
      "\n",
      "We have developed a GBS CC genotyping method based upon four MLST database-derived SNPs that resolve the major eBURST-defined clonal complexes .\n",
      "{4: 'GBS CC genotyping method'}\n",
      "Rule 4: GBS CC genotyping method\n",
      "\n",
      "\n",
      "\n",
      "In addition , bimolecular fluorescence complementation analysis using split-FP systems has been successfully applied to determine protein-protein interactions in planta as well as in animals .\n",
      "{2: 'bimolecular fluorescence complementation analysis', 4: 'fluorescence complementation analysis'}\n",
      "Rule 2: bimolecular fluorescence complementation analysis\n",
      "\n",
      "\n",
      "\n",
      "PFGE analysis also grouped the latter two isolates into distinct clusters , pulse-types 6 and 5 respectively .\n",
      "{4: 'PFGE analysis'}\n",
      "Rule 4: PFGE analysis\n",
      "\n",
      "\n",
      "\n",
      "False negative results were defined as samples giving a negative result with PCR and a positive result with the NMKL-71 method .\n",
      "{4: 'NMKL-71 method'}\n",
      "Rule 4: NMKL-71 method\n",
      "\n",
      "\n",
      "\n",
      "There are several methods available for mutagenesis : 1 ) to isolate single strand template DNA and then create the mutation with one complementary primer ; 2 ) design two sets of PCR primers that overlap the mutation site , amplify the template by two PCR reactions and then clone the two PCR fragments and the vector by three piece ligation ; 3 ) Site-directed mutagenesis using the QuikChange method .\n",
      "{4: 'QuikChange method'}\n",
      "Rule 4: QuikChange method\n",
      "\n",
      "\n",
      "\n",
      "Both genes are recommended as reference genes for relative gene quantification in gene profiling studies either as single gene or preferably in combination .\n",
      "{2: 'relative gene quantification', 4: 'gene quantification'}\n",
      "Rule 2: relative gene quantification\n",
      "\n",
      "\n",
      "\n",
      "To minimize the possibility of certain subjects extreme values and effects , source waveforms were standardized using the vector scaling method proposed by McCarthy and Wood .\n",
      "{4: 'vector scaling method'}\n",
      "Rule 4: vector scaling method\n",
      "\n",
      "\n",
      "\n",
      "Schmidt et al. developed a simulation algorithm for the computation of all possible isotopomers .\n",
      "{4: 'simulation algorithm'}\n",
      "Rule 4: simulation algorithm\n",
      "\n",
      "\n",
      "\n",
      "The computer finds the endpoint of the test by a Modified Binary Search method ; if response is correct , on the next presentation the colour difference between letter and background is halved .\n",
      "{2: 'Modified Binary Search method', 4: 'Search method'}\n",
      "Rule 2: Modified Binary Search method\n",
      "\n",
      "\n",
      "\n",
      "In addition , a randomized controlled trial , found that hand excavation without local anaesthesia gave the least discomfort , and conventional cavity preparation with LA , the most .\n",
      "{2: 'conventional cavity preparation', 4: 'cavity preparation'}\n",
      "Rule 2: conventional cavity preparation\n",
      "\n",
      "\n",
      "\n",
      "Principal components analysis was carried out on the anthropometric measurements from both parents and their babies at birth .\n",
      "{2: 'Principal components analysis', 4: 'components analysis'}\n",
      "Rule 2: Principal components analysis\n",
      "\n",
      "\n",
      "\n",
      "Measurement of the band intensities by image analysis results in a calculated value of 27 ± 5 copies of Hps per haploid genome , for the 2.4 kb Bgl II fragment , assuming a haploid genome size of 1.212 pg DNA .\n",
      "{4: 'image analysis'}\n",
      "Rule 4: image analysis\n",
      "\n",
      "\n",
      "\n",
      "In order to determine the effects of rhizotoxic treatments on gene expression in Arabidopsis using this microarray approach , it is necessary to minimize the effects of other factors on gene expression during the course of the experiment .\n",
      "{4: 'microarray approach'}\n",
      "Rule 4: microarray approach\n",
      "\n",
      "\n",
      "\n",
      "Table 4Discriminant Function Analysis Results .\n",
      "{2: 'Table 4Discriminant Function Analysis', 4: 'Table 4Discriminant Function Analysis'}\n",
      "Rule 2: Table 4Discriminant Function Analysis\n",
      "\n",
      "\n",
      "\n",
      "Table 4Discriminant Function Analysis Results .\n",
      "{2: 'Table 4Discriminant Function Analysis', 4: 'Table 4Discriminant Function Analysis'}\n",
      "Rule 2: Table 4Discriminant Function Analysis\n",
      "\n",
      "\n",
      "\n",
      "For random effects analysis , a contrast image between tasks and control was generated for each participant and used for intersubject comparisons .\n",
      "{2: 'random effects analysis', 4: 'effects analysis'}\n",
      "Rule 2: random effects analysis\n",
      "\n",
      "\n",
      "\n",
      "{'id': 1, 'text': 'Apart', 'lemma': 'apart', 'upos': 'ADV', 'xpos': 'RB', 'head': 8, 'deprel': 'advmod', 'misc': 'start_char=0|end_char=5', 'children': []}\n",
      "{'id': 2, 'text': 'from', 'lemma': 'from', 'upos': 'ADP', 'xpos': 'IN', 'head': 5, 'deprel': 'case', 'misc': 'start_char=6|end_char=10', 'children': []}\n",
      "{'id': 3, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'head': 5, 'deprel': 'det', 'misc': 'start_char=11|end_char=14', 'children': []}\n",
      "{'id': 4, 'text': 'WHONET', 'lemma': 'whonet', 'upos': 'NOUN', 'xpos': 'NN', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=15|end_char=21', 'children': []}\n",
      "{'id': 5, 'text': 'software', 'lemma': 'software', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'obl', 'misc': 'start_char=22|end_char=30', 'children': [2, 3, 4]}\n",
      "{'id': 6, 'text': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'head': 8, 'deprel': 'punct', 'misc': 'start_char=31|end_char=32', 'children': []}\n",
      "{'id': 7, 'text': 'we', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP', 'head': 8, 'deprel': 'nsubj', 'misc': 'start_char=33|end_char=35', 'children': []}\n",
      "{'id': 8, 'text': 'used', 'lemma': 'use', 'upos': 'VERB', 'xpos': 'VBD', 'head': 0, 'deprel': 'root', 'misc': 'start_char=36|end_char=40', 'children': [1, 5, 6, 7, 9, 14, 23]}\n",
      "{'id': 9, 'text': 'Stata', 'lemma': 'stata', 'upos': 'NOUN', 'xpos': 'NN', 'head': 8, 'deprel': 'obj', 'misc': 'start_char=41|end_char=46', 'children': [10, 12]}\n",
      "{'id': 10, 'text': '8.0', 'lemma': '8.0', 'upos': 'NUM', 'xpos': 'CD', 'head': 9, 'deprel': 'nummod', 'misc': 'start_char=47|end_char=50', 'children': []}\n",
      "{'id': 11, 'text': 'for', 'lemma': 'for', 'upos': 'ADP', 'xpos': 'IN', 'head': 12, 'deprel': 'case', 'misc': 'start_char=51|end_char=54', 'children': []}\n",
      "{'id': 12, 'text': 'Macintosh', 'lemma': 'macintosh', 'upos': 'NOUN', 'xpos': 'NN', 'head': 9, 'deprel': 'nmod', 'misc': 'start_char=55|end_char=64', 'children': [11]}\n",
      "{'id': 13, 'text': 'to', 'lemma': 'to', 'upos': 'PART', 'xpos': 'TO', 'head': 14, 'deprel': 'mark', 'misc': 'start_char=65|end_char=67', 'children': []}\n",
      "{'id': 14, 'text': 'evaluate', 'lemma': 'evaluate', 'upos': 'VERB', 'xpos': 'VB', 'head': 8, 'deprel': 'advcl', 'misc': 'start_char=68|end_char=76', 'children': [13, 15]}\n",
      "{'id': 15, 'text': 'differences', 'lemma': 'difference', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 14, 'deprel': 'obj', 'misc': 'start_char=77|end_char=88', 'children': [17]}\n",
      "{'id': 16, 'text': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'head': 17, 'deprel': 'case', 'misc': 'start_char=89|end_char=91', 'children': []}\n",
      "{'id': 17, 'text': 'proportions', 'lemma': 'proportion', 'upos': 'NOUN', 'xpos': 'NNS', 'head': 15, 'deprel': 'nmod', 'misc': 'start_char=92|end_char=103', 'children': [16, 22]}\n",
      "{'id': 18, 'text': 'by', 'lemma': 'by', 'upos': 'ADP', 'xpos': 'IN', 'head': 22, 'deprel': 'case', 'misc': 'start_char=104|end_char=106', 'children': []}\n",
      "{'id': 19, 'text': 'Fisher', 'lemma': 'fisher', 'upos': 'NOUN', 'xpos': 'NN', 'head': 22, 'deprel': 'nmod:poss', 'misc': 'start_char=107|end_char=113', 'children': [20]}\n",
      "{'id': 20, 'text': \"'s\", 'lemma': \"'s\", 'upos': 'PART', 'xpos': 'POS', 'head': 19, 'deprel': 'case', 'misc': 'start_char=114|end_char=116', 'children': []}\n",
      "{'id': 21, 'text': 'exact', 'lemma': 'exact', 'upos': 'ADJ', 'xpos': 'JJ', 'head': 22, 'deprel': 'amod', 'misc': 'start_char=117|end_char=122', 'children': []}\n",
      "{'id': 22, 'text': 'test', 'lemma': 'test', 'upos': 'NOUN', 'xpos': 'NN', 'head': 17, 'deprel': 'nmod', 'misc': 'start_char=123|end_char=127', 'children': [18, 19, 21]}\n",
      "{'id': 23, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 8, 'deprel': 'punct', 'misc': 'start_char=128|end_char=129', 'children': []}\n",
      "Apart from the WHONET software , we used Stata 8.0 for Macintosh to evaluate differences of proportions by Fisher 's exact test .\n",
      "{5: \"Fisher 's exact test\"}\n",
      "Rule 5: Fisher 's exact test\n",
      "\n",
      "\n",
      "\n",
      "As a result of using verbal autopsy method , adult deaths from unspecified and unknown causes decreased from 54 % to 23 % in urban and from 41 % to 26 % in rural areas in Tamilnadu .\n",
      "{2: 'verbal autopsy method', 4: 'autopsy method'}\n",
      "Rule 2: verbal autopsy method\n",
      "\n",
      "\n",
      "\n",
      "All the mothers in the merged data were grouped socio-economically into quintiles on the basis of wealth assessment , using principal component factor analysis .\n",
      "{2: 'principal component factor analysis', 4: 'component factor analysis'}\n",
      "Rule 2: principal component factor analysis\n",
      "\n",
      "\n",
      "\n",
      "While conventional factor analysis is used in scale development and tries to group items or variables , Q method tries to group subjects .\n",
      "{2: 'conventional factor analysis', 4: 'factor analysis'}\n",
      "Rule 2: conventional factor analysis\n",
      "\n",
      "\n",
      "\n",
      "While conventional factor analysis is used in scale development and tries to group items or variables , Q method tries to group subjects .\n",
      "{4: 'Q method'}\n",
      "Rule 4: Q method\n",
      "\n",
      "\n",
      "\n",
      "Similar to the IUPred , the FlexRP method computes a probabilistic score that ranges between 0 and 1 and uses a threshold that equals 0.5 .\n",
      "{4: 'FlexRP method'}\n",
      "Rule 4: FlexRP method\n",
      "\n",
      "\n",
      "\n",
      "More recently , the cellular Potts model has become a popular vehicle to simulate cell shape changes .\n",
      "{2: 'cellular Potts model', 4: 'Potts model'}\n",
      "Rule 2: cellular Potts model\n",
      "\n",
      "\n",
      "\n",
      "Initial fitting does not have to be as accurate as in the L-Q method , but the rate at which the solution converges to a minimum in the L-M method strongly depends on the character of the function and its use is recommended in the \" final \" stage of the process in order to optimize the solution .\n",
      "{4: 'L-Q method'}\n",
      "Rule 4: L-Q method\n",
      "\n",
      "\n",
      "\n",
      "Initial fitting does not have to be as accurate as in the L-Q method , but the rate at which the solution converges to a minimum in the L-M method strongly depends on the character of the function and its use is recommended in the \" final \" stage of the process in order to optimize the solution .\n",
      "{4: 'L-M method'}\n",
      "Rule 4: L-M method\n",
      "\n",
      "\n",
      "\n",
      "Methods that can detect and further analyze more micrometastatic cells than the current IC technique are required .\n",
      "{2: 'current IC technique', 4: 'IC technique'}\n",
      "Rule 2: current IC technique\n",
      "\n",
      "\n",
      "\n",
      "VO2 max test also provides objective data , which is helpful in formulating appropriate exercise prescription .\n",
      "{4: 'VO2 max test'}\n",
      "Rule 4: VO2 max test\n",
      "\n",
      "\n",
      "\n",
      "Three measurements were taken at 1-minute intervals , and the mean of the three values were used for data analysis .\n",
      "{4: 'data analysis'}\n",
      "Rule 4: data analysis\n",
      "\n",
      "\n",
      "\n",
      "By offline analysis with QCA we calculated the average LD distal to the tip of the Doppler wire .\n",
      "{4: 'offline analysis'}\n",
      "Rule 4: offline analysis\n",
      "\n",
      "\n",
      "\n",
      "SSR analysis has been applied in authentication of ginseng .\n",
      "{4: 'SSR analysis'}\n",
      "Rule 4: SSR analysis\n",
      "\n",
      "\n",
      "\n",
      "Forty cycles were performed and then followed by melting curve analysis to verify the correctness of the amplification .\n",
      "{2: 'melting curve analysis', 4: 'curve analysis'}\n",
      "Rule 2: melting curve analysis\n",
      "\n",
      "\n",
      "\n",
      "Costs from productivity loss at paid work were calculated according to the friction cost method .\n",
      "{4: 'friction cost method'}\n",
      "Rule 4: friction cost method\n",
      "\n",
      "\n",
      "\n",
      "The fluid challenge technique we used is standardized , but it included various amounts of either colloid or crystalloid as recommended clinically .\n",
      "{4: 'fluid challenge technique'}\n",
      "Rule 4: fluid challenge technique\n",
      "\n",
      "\n",
      "\n",
      "These differences have been well evidenced by Imanaka et al using a test lung model .\n",
      "{2: 'test lung model', 4: 'lung model'}\n",
      "Rule 2: test lung model\n",
      "\n",
      "\n",
      "\n",
      "The occlusion technique allows V-P curves to be constructed in the volume-controlled mode of ventilation , by changing respiratory frequency in order to obtain various VTs and by using the end-inspiratory button of the ventilator to identify the corresponding plateau pressure .\n",
      "{4: 'occlusion technique'}\n",
      "Rule 4: occlusion technique\n",
      "\n",
      "\n",
      "\n",
      "The lithium dilution method requires central or peripheral intravenous infusion of lithium salt solution , followed by arterial sampling to measure stroke volume and cardiac output .\n",
      "{4: 'lithium dilution method'}\n",
      "Rule 4: lithium dilution method\n",
      "\n",
      "\n",
      "\n",
      "There were no differences between men and women to a tilt table test except for differences in heart rate response .\n",
      "{4: 'tilt table test'}\n",
      "Rule 4: tilt table test\n",
      "\n",
      "\n",
      "\n",
      "If these values are missing completely at random , a complete case analysis including the PCB variable would yield consistent estimation , but power may be lost .\n",
      "{2: 'complete case analysis', 4: 'case analysis'}\n",
      "Rule 2: complete case analysis\n",
      "\n",
      "\n",
      "\n",
      "TPH were analyzed using EPA method 418.1 .\n",
      "{4: 'EPA method'}\n",
      "Rule 4: EPA method\n",
      "\n",
      "\n",
      "\n",
      "Genotyping procedures were validated by randomly selecting 5 % of the samples and subjecting them to repeat analysis .\n",
      "{4: 'repeat analysis'}\n",
      "Rule 4: repeat analysis\n",
      "\n",
      "\n",
      "\n",
      "PM10 was then treated as a time varying covariate in the survival analysis .\n",
      "{4: 'survival analysis'}\n",
      "Rule 4: survival analysis\n",
      "\n",
      "\n",
      "\n",
      "This point effectively represents a 0 % EPP cutoff , which we believe is appropriate and accurate for a strict divergent genes analysis .\n",
      "{2: 'strict divergent genes analysis', 4: 'genes analysis'}\n",
      "Rule 2: strict divergent genes analysis\n",
      "\n",
      "\n",
      "\n",
      "However , in mammals , expression data are principally based on whole tissue analysis and are still very incomplete .\n",
      "{2: 'whole tissue analysis', 4: 'tissue analysis'}\n",
      "Rule 2: whole tissue analysis\n",
      "\n",
      "\n",
      "\n",
      "Yang et al. outlined a composite normalization strategy in which adjustment was a weighted average of the lowess fit to the MSP probes and a lowess fit to the gene probes .\n",
      "{2: 'composite normalization strategy', 4: 'normalization strategy'}\n",
      "Rule 2: composite normalization strategy\n",
      "\n",
      "\n",
      "\n",
      "As discussed above , one shortcoming of the ROC analysis is the presence of CNPs in the autosomes .\n",
      "{4: 'ROC analysis'}\n",
      "Rule 4: ROC analysis\n",
      "\n",
      "\n",
      "\n",
      "Each node is assigned an initial cycling score that is determined from expression data using a method from de Lichtenberg and coworkers .\n",
      "{2: 'initial cycling score', 4: 'cycling score'}\n",
      "Rule 2: initial cycling score\n",
      "\n",
      "\n",
      "\n",
      "The Common fraction score method calculates the fraction of motifs shared between each pair of sequences , ignoring the order in which the motifs occur in the sequence and the number of times each motif occurs .\n",
      "{2: 'Common fraction score method', 4: 'fraction score method'}\n",
      "Rule 2: Common fraction score method\n",
      "\n",
      "\n",
      "\n",
      "The main intention of this access method is to allow end-users to search for a specific piece of information , e.g. , to identify or confirm interaction partners for a given gene or protein .\n",
      "{4: 'access method'}\n",
      "Rule 4: access method\n",
      "\n",
      "\n",
      "\n",
      "The distribution of the propensity score was divided into deciles , and stratified random samples of 400 from the first through the eighth deciles were drawn from both the proxy-completed responses and the self-completed responses .\n",
      "{4: 'propensity score'}\n",
      "Rule 4: propensity score\n",
      "\n",
      "\n",
      "\n",
      "Full-information factor analysis also uses an extension of the model in equation 1 .\n",
      "{2: 'Full-information factor analysis', 4: 'factor analysis'}\n",
      "Rule 2: Full-information factor analysis\n",
      "\n",
      "\n",
      "\n",
      "Furthermore , a Kolmogornov-Smirnov test was carried out to examine whether the ability parameters were Normally distributed .\n",
      "{4: 'Kolmogornov-Smirnov test'}\n",
      "Rule 4: Kolmogornov-Smirnov test\n",
      "\n",
      "\n",
      "\n",
      "To determine the internal consistency of the questionnaire , reliability analysis was performed using Cronbach 's alpha .\n",
      "{4: 'reliability analysis'}\n",
      "Rule 4: reliability analysis\n",
      "\n",
      "\n",
      "\n",
      "However , as the response burden of this 20-item questionnaire is already low , and in order to be able to calculate the overall QOL score , we generally recommend using the instrument in its full length .\n",
      "{2: 'overall QOL score', 4: 'QOL score'}\n",
      "Rule 2: overall QOL score\n",
      "\n",
      "\n",
      "\n",
      "The reason for this is that , at high individual tool specificity parameters , most nonbinding peptides get an HBM score of zero , and therefore the ROC curve contains no points for specificities between 0 and approximately 0.85-0.90 .\n",
      "{4: 'HBM score'}\n",
      "Rule 4: HBM score\n",
      "\n",
      "\n",
      "\n",
      "Indeed , in a recent study we observed that 57 % of the HLA-A*0201 restricted vaccinia-derived epitopes identified did not conform with the A*0201 motif derived by pool sequencing analysis .\n",
      "{4: 'pool sequencing analysis'}\n",
      "Rule 4: pool sequencing analysis\n",
      "\n",
      "\n",
      "\n",
      "The HAPPY technique was developed in the late 1980s 5 .\n",
      "{4: 'HAPPY technique'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 4: HAPPY technique\n",
      "\n",
      "\n",
      "\n",
      "Furthermore , universal kriging is based on a polynomial trend surface model which is to be removed prior to estimation of the semivariogram from the residuals , i.e. δ .\n",
      "{2: 'polynomial trend surface model', 4: 'trend surface model'}\n",
      "Rule 2: polynomial trend surface model\n",
      "\n",
      "\n",
      "\n",
      "The P-value was obtained from a likelihood ratio test based on Monte Carlo simulation with 9,999 replicates .\n",
      "{4: 'likelihood ratio test'}\n",
      "Rule 4: likelihood ratio test\n",
      "\n",
      "\n",
      "\n",
      "A simple GIS based model , based on an assumed exponential decay distribution of patients around a general practice , can be used to predict a practice population-weighted area-based deprivation measure .\n",
      "{2: 'simple GIS based model', 4: 'GIS model'}\n",
      "Rule 2: simple GIS based model\n",
      "\n",
      "\n",
      "\n",
      "The zones were created via k-means clustering of the results of a geographically weighted regression analysis of pathogen distributions , as documented in a previous study .\n",
      "{2: 'weighted regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: weighted regression analysis\n",
      "\n",
      "\n",
      "\n",
      "As shown in Figure 3 , a variation of the centroid containment method is the distance boundary method .\n",
      "{2: 'centroid containment method', 4: 'containment method'}\n",
      "Rule 2: centroid containment method\n",
      "\n",
      "\n",
      "\n",
      "The surrogate data created by the AAFT algorithm had the same amplitude distribution as the original time series but had been appropriately re-ordered to represent a signal created by a linear Gaussian process .\n",
      "{4: 'AAFT algorithm'}\n",
      "Rule 4: AAFT algorithm\n",
      "\n",
      "\n",
      "\n",
      "Methods in the context of fixed grid approach , such as the front-tracking , surface tracking , and volume tracking method ) methods are capable of simulating very complex interface motion .\n",
      "{2: 'fixed grid approach', 4: 'grid approach'}\n",
      "Rule 2: fixed grid approach\n",
      "\n",
      "\n",
      "\n",
      "Synthesis of particles outside this range are not possible using the reverse micelle method .\n",
      "{2: 'reverse micelle method', 4: 'micelle method'}\n",
      "Rule 2: reverse micelle method\n",
      "\n",
      "\n",
      "\n",
      "As Hollis and Campbell note , “…no imputation method can give an unbiased estimate of the treatment effect unless the assumptions made about the missing data are valid.” A nonresponse follow-up study allows one not only to reduce the amount of missing data , but also to evaluate the missing data assumptions .\n",
      "{4: '“…no imputation method'}\n",
      "Rule 4: “…no imputation method\n",
      "\n",
      "\n",
      "\n",
      "We therefore set out to develop an RT-PCR based method to quantitate CD4 and CD8 mRNA in the hopes that this could be used to predict cell counts .\n",
      "{2: 'RT-PCR based method', 4: 'RT-PCR method'}\n",
      "Rule 2: RT-PCR based method\n",
      "\n",
      "\n",
      "\n",
      "The students were then introduced to their task , which was to apply the basic steps associated with the grounded theory approach in analysing the material provided to derive positive and negative attributes of operational research for influencing communicable disease policy and practice in southern Africa .\n",
      "{2: 'grounded theory approach', 4: 'theory approach'}\n",
      "Rule 2: grounded theory approach\n",
      "\n",
      "\n",
      "\n",
      "In a separate analysis , ITN use was analysed by individual , that is , by ' treatment-per-protocol ' logistic regression analysis , under the rationale that households typically had more than one bednet and because education uptake was highly individualised .\n",
      "{2: 'treatment-per-protocol logistic regression analysis', 4: 'treatment-per-protocol logistic regression analysis'}\n",
      "Rule 2: treatment-per-protocol logistic regression analysis\n",
      "\n",
      "\n",
      "\n",
      "A comparative study of five widely used PCR-based mutagenesis methods identified a modified inverse PCR method as particularly suitable for the deletion of large areas in malaria parasite genes .\n",
      "{2: 'modified inverse PCR method', 4: 'PCR method'}\n",
      "Rule 2: modified inverse PCR method\n",
      "\n",
      "\n",
      "\n",
      "Upon receiving informed consent a questionnaire was completed for each participant , blood slides prepared for microscopical examination and a venous blood samples was collected for further laboratory analysis .\n",
      "{2: 'further laboratory analysis', 4: 'laboratory analysis'}\n",
      "Rule 2: further laboratory analysis\n",
      "\n",
      "\n",
      "\n",
      "A previous report by Tulu et al in Debre Zeit has showed the presence of 2 % treatment failures in using seven days in vivo efficacy test .\n",
      "{2: 'days in vivo efficacy test', 4: 'efficacy test'}\n",
      "Rule 2: days in vivo efficacy test\n",
      "\n",
      "\n",
      "\n",
      "The assay method has to be easy to use , inexpensive , and applicable to a wide variety of both field and laboratory derived material .\n",
      "{4: 'assay method'}\n",
      "Rule 4: assay method\n",
      "\n",
      "\n",
      "\n",
      "The TAP method was initially developed in yeast but can be successfully adapted to various organisms .\n",
      "{4: 'TAP method'}\n",
      "Rule 4: TAP method\n",
      "\n",
      "\n",
      "\n",
      "A somewhat similar MALDI-MS approach was used to characterize stability of an expressed protein in the cell extracts i.e. under conditions close to those found in the cytoplasm .\n",
      "{2: 'similar MALDI-MS approach', 4: 'MALDI-MS approach'}\n",
      "Rule 2: similar MALDI-MS approach\n",
      "\n",
      "\n",
      "\n",
      "Two different immunostaining methods were applied : the peroxidase method for anti-CR immunostaining on 20 μm sections ; and immunoflurescent labeling for CR , human Bcl-2 , neuron-specific nuclear antigen , doublecortinin , Ki67 , and β-tubulin on 40 μm sections .\n",
      "{4: 'peroxidase method'}\n",
      "Rule 4: peroxidase method\n",
      "\n",
      "\n",
      "\n",
      "Because of errors introduced by this conversion and technical limitations inherent to the genome-wide ChIP analysis , rather than focusing on the characterization of individual targets in network clusters , we identified significantly overrepresented gene properties in each network topology cluster .\n",
      "{2: 'genome-wide ChIP analysis', 4: 'ChIP analysis'}\n",
      "Rule 2: genome-wide ChIP analysis\n",
      "\n",
      "\n",
      "\n",
      "For instance , Kulp and Jagalur sought to infer the true causal genes using a Bayesian network model constructed from expression correlations detected within the eQTL profiles .\n",
      "{2: 'Bayesian network model', 4: 'network model'}\n",
      "Rule 2: Bayesian network model\n",
      "\n",
      "\n",
      "\n",
      "We report here an Alu- n PCR method for the cloning of STSs with n sequences .\n",
      "{4: 'Alu- n PCR method'}\n",
      "Rule 4: Alu- n PCR method\n",
      "\n",
      "\n",
      "\n",
      "We describe a simple electroelution method for purifying large , gel-fractionated DNA molecules that alleviates the need for melting of the agarose and subsequent enzymatic agarose digestion .\n",
      "{2: 'simple electroelution method', 4: 'electroelution method'}\n",
      "Rule 2: simple electroelution method\n",
      "\n",
      "\n",
      "\n",
      "To do so we developed two software packages , called RAGA and PRAGA , which use a genetic algorithm approach to optimize the alignments .\n",
      "{2: 'genetic algorithm approach', 4: 'algorithm approach'}\n",
      "Rule 2: genetic algorithm approach\n",
      "\n",
      "\n",
      "\n",
      "TAA of the serum was assessed by the linolenic acid test described previously .\n",
      "{2: 'linolenic acid test', 4: 'acid test'}\n",
      "Rule 2: linolenic acid test\n",
      "\n",
      "\n",
      "\n",
      "Total energy expenditure was predicted using the Institute of Medicine of the National Academies for overweight and obese adults formulae which utilises age , height , weight , gender and physical activity based on PAL score .\n",
      "{4: 'PAL score'}\n",
      "Rule 4: PAL score\n",
      "\n",
      "\n",
      "\n",
      "The Wilcoxon signed ranks test was used to test whether variables differed significantly between the two measurements .\n",
      "{4: 'ranks test'}\n",
      "Rule 4: ranks test\n",
      "\n",
      "\n",
      "\n",
      "Using these risk assessments a health economic strategy can be formulated for each country , based on acceptable levels of resource utilization , to determine at what level of risk it would be cost effective to intervene .\n",
      "{2: 'health economic strategy', 4: 'health strategy'}\n",
      "Rule 2: health economic strategy\n",
      "\n",
      "\n",
      "\n",
      "In this paper , we present a VP26 core domain model , as well as an approach for determining / evaluating optimal structural models with the constraints imposed by a medium-resolution cryoEM density map .\n",
      "{4: 'VP26 core domain model'}\n",
      "Rule 4: VP26 core domain model\n",
      "\n",
      "\n",
      "\n",
      "The hierarchical prediction algorithm allows us to quickly prune the conformational space and focus sampling on energetically favorable regions of conformation space .\n",
      "{2: 'hierarchical prediction algorithm', 4: 'prediction algorithm'}\n",
      "Rule 2: hierarchical prediction algorithm\n",
      "\n",
      "\n",
      "\n",
      "The HMM approach can also be used to infer LOH probabilities for paired normal and tumor samples , unifying the LOH analysis for paired tumor / normal and unpaired tumor samples .\n",
      "{4: 'HMM approach'}\n",
      "Rule 4: HMM approach\n",
      "\n",
      "\n",
      "\n",
      "The HMM approach can also be used to infer LOH probabilities for paired normal and tumor samples , unifying the LOH analysis for paired tumor / normal and unpaired tumor samples .\n",
      "{4: 'LOH analysis'}\n",
      "Rule 4: LOH analysis\n",
      "\n",
      "\n",
      "\n",
      "Table 2 utilizes a fixed sample size method that is easy to use , but may not be optimal when considering the number of subjects needed .\n",
      "{2: 'fixed sample size method', 4: 'sample size method'}\n",
      "Rule 2: fixed sample size method\n",
      "\n",
      "\n",
      "\n",
      "Traditionally , sensitivity analysis is performed locally around a single optimal model , or globally reporting a general sensitivity throughout the parameter space , to quantify how each parameter contributes to model output .\n",
      "{4: 'sensitivity analysis'}\n",
      "Rule 4: sensitivity analysis\n",
      "\n",
      "\n",
      "\n",
      "This feature extraction method has subsequently been used , as will be described here , to extract possible glycan features that may serve as biomarkers .\n",
      "{4: 'feature extraction method'}\n",
      "Rule 4: feature extraction method\n",
      "\n",
      "\n",
      "\n",
      "Thus , with the integration of 3D imaging techniques , e.g. confocal microscopy , our system can be conveniently extended to 3D analysis and parallel computing environment .\n",
      "{4: '3D analysis'}\n",
      "Rule 4: 3D analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "The terms contributing to the jump score are illustrated in Figure 12 .\n",
      "{4: 'jump score'}\n",
      "Rule 4: jump score\n",
      "\n",
      "\n",
      "\n",
      "The leave-one-out cross-validation analysis of ethnic group affiliation was performed using the GeneClass 2 software .\n",
      "{2: 'leave-one-out cross-validation analysis', 4: 'cross-validation analysis'}\n",
      "Rule 2: leave-one-out cross-validation analysis\n",
      "\n",
      "\n",
      "\n",
      "This amounted to 188,600,000 simulated case control calculations for each disease model examined .\n",
      "{4: 'disease model'}\n",
      "Rule 4: disease model\n",
      "\n",
      "\n",
      "\n",
      "Briefly , the systematic hybrid LOH method utilizes a set of 16 strains , each containing a conditional centromere construct on one of the 16 yeast chromosomes .\n",
      "{2: 'systematic hybrid LOH method', 4: 'hybrid LOH method'}\n",
      "Rule 2: systematic hybrid LOH method\n",
      "\n",
      "\n",
      "\n",
      "The AML trend test was not significant under either scenario .\n",
      "{4: 'AML trend test'}\n",
      "Rule 4: AML trend test\n",
      "\n",
      "\n",
      "\n",
      "The whole genome approach based on fitting multiple SNPs and using RJMCMC for model selection provides a posterior density of each SNP being associated with the phenotype .\n",
      "{2: 'whole genome approach', 4: 'genome approach'}\n",
      "Rule 2: whole genome approach\n",
      "\n",
      "\n",
      "\n",
      "We estimated parameters under the best-fitting IM model , by comparing our empirical data with 250,000 simulations of 20 independent regions under the A-WE model , using large flat prior distributions for separation time and migration rate parameters , except that the time of the oldest divergence was necessarily constrained by the time of the latest divergence .\n",
      "{2: 'best-fitting IM model', 4: 'IM model'}\n",
      "Rule 2: best-fitting IM model\n",
      "\n",
      "\n",
      "\n",
      "We estimated parameters under the best-fitting IM model , by comparing our empirical data with 250,000 simulations of 20 independent regions under the A-WE model , using large flat prior distributions for separation time and migration rate parameters , except that the time of the oldest divergence was necessarily constrained by the time of the latest divergence .\n",
      "{4: 'A-WE model'}\n",
      "Rule 4: A-WE model\n",
      "\n",
      "\n",
      "\n",
      "The likelihood ratio test was used to assess for effect modification .\n",
      "{4: 'likelihood ratio test'}\n",
      "Rule 4: likelihood ratio test\n",
      "\n",
      "\n",
      "\n",
      "A general overview of the initial stages of data analysis is provided by the model of grounded theory , which can be particularly useful in participant-observation studies .\n",
      "{4: 'data analysis'}\n",
      "Rule 4: data analysis\n",
      "\n",
      "\n",
      "\n",
      "We identified ESC issues in the GCGH initiative through a sequential process of document analysis , group discussions with investigators and program staff , and interviews with experts from the developing world .\n",
      "{4: 'document analysis'}\n",
      "Rule 4: document analysis\n",
      "\n",
      "\n",
      "\n",
      "Each assay was controlled internally with a spiked DNA preparation and validated by detection of three copies of SIV DNA .\n",
      "{2: 'spiked DNA preparation', 4: 'DNA preparation'}\n",
      "Rule 2: spiked DNA preparation\n",
      "\n",
      "\n",
      "\n",
      "A series of rarefaction and bootstrap analyses were conducted to determine that matrix correlation analysis and pairwise trait correlations were stable at these sample sizes .\n",
      "{4: 'matrix correlation analysis'}\n",
      "Rule 4: matrix correlation analysis\n",
      "\n",
      "\n",
      "\n",
      "All Len proteins bear at least some hallmarks of being lipoproteins , with LenA , LenB , LenC , LenD and LenF having high probabilities of being so according to analyses using the spirochete-specific lipoprotein algorithm SpLip .\n",
      "{2: 'spirochete-specific lipoprotein algorithm', 4: 'lipoprotein algorithm'}\n",
      "Rule 2: spirochete-specific lipoprotein algorithm\n",
      "\n",
      "\n",
      "\n",
      "The MHW method is extensively described in the Methods section and schematically depicted in Figure 2 .\n",
      "{4: 'MHW method'}\n",
      "Rule 4: MHW method\n",
      "\n",
      "\n",
      "\n",
      "These SNPs were entered in the hidden Markov model to estimate the marker locus specific ancestry in African-Americans based on EM algorithm using software ADMIXPROGRAM .\n",
      "{2: 'hidden Markov model', 4: 'Markov model'}\n",
      "Rule 2: hidden Markov model\n",
      "\n",
      "\n",
      "\n",
      "These SNPs were entered in the hidden Markov model to estimate the marker locus specific ancestry in African-Americans based on EM algorithm using software ADMIXPROGRAM .\n",
      "{4: 'EM algorithm'}\n",
      "Rule 4: EM algorithm\n",
      "\n",
      "\n",
      "\n",
      "In Table 1 , the range of within-hour variance explained by the 3 score estimates is given in the FA columns , where it can be seen that any of the 3 estimators explains more variance than the RA method in each of the compound classes and LD / DD conditions .\n",
      "{4: 'RA method'}\n",
      "Rule 4: RA method\n",
      "\n",
      "\n",
      "\n",
      "Hierarchical clustering based on complete linkage method and Pearson correlation as a similarity measure was applied to evaluate the effect of the different sources of variability .\n",
      "{2: 'complete linkage method', 4: 'linkage method'}\n",
      "Rule 2: complete linkage method\n",
      "\n",
      "\n",
      "\n",
      "We identified individual genes that exhibited statistically significant differential expression as a result of PDGF treatment in each null experiment using SAM method .\n",
      "{4: 'SAM method'}\n",
      "Rule 4: SAM method\n",
      "\n",
      "\n",
      "\n",
      "We found that a two step filtering approach could be applied to different biological replicates , and even different types of experiments , as long as the pool contained the same cohort of deletion strains .\n",
      "{4: 'step filtering approach'}\n",
      "Rule 4: step filtering approach\n",
      "\n",
      "\n",
      "\n",
      "In other words , partial correlation analysis can be also used to remove the effects of a set of variables .\n",
      "{2: 'partial correlation analysis', 4: 'correlation analysis'}\n",
      "Rule 2: partial correlation analysis\n",
      "\n",
      "\n",
      "\n",
      "This exploratory paper does not provide evidence that B. subtilis , or any other microbe , is intelligent or is playing an evolved , fitness-enhancing memory strategy .\n",
      "{2: 'evolved fitness-enhancing memory strategy', 4: 'memory strategy'}\n",
      "Rule 2: evolved fitness-enhancing memory strategy\n",
      "\n",
      "\n",
      "\n",
      "Under these conditions , we performed ten rounds of parameter estimation to reproduce the experimental data since the upstream model seemed to be more complex than the topological Raf-MEK-ERK model .\n",
      "{2: 'topological Raf-MEK-ERK model', 4: 'Raf-MEK-ERK model'}\n",
      "Rule 2: topological Raf-MEK-ERK model\n",
      "\n",
      "\n",
      "\n",
      "The OR and P values were calculated by multivariate logistic regression analysis with age , sex , comorbidity presence and infection source entered as covariates in the model , given the relevance of these potential confounding variables in interpreting the study results .\n",
      "{2: 'multivariate logistic regression analysis', 4: 'regression analysis'}\n",
      "Rule 2: multivariate logistic regression analysis\n",
      "\n",
      "\n",
      "\n",
      "For example , it has been found that the 0.002 mm fraction defined by the pipette method corresponds with a grain size of 0.008 mm by laser diffraction .\n",
      "{4: 'pipette method'}\n",
      "Rule 4: pipette method\n",
      "\n",
      "\n",
      "\n",
      "Time-series NIR fluorescence images were obtained after injecting ICG intravenously in a murine hindlimb ischemia model .\n",
      "{2: 'murine hindlimb ischemia model', 4: 'hindlimb ischemia model'}\n",
      "Rule 2: murine hindlimb ischemia model\n",
      "\n",
      "\n",
      "\n",
      "In addition , gene expression analysis was performed to identify virulence factors involved in EHEC disruption of the IFNγ-Jak1 , 2-STAT-1 signal transduction cascade .\n",
      "{4: 'gene expression analysis'}\n",
      "Rule 4: gene expression analysis\n",
      "\n",
      "\n",
      "\n",
      "In addition to our primary set of 910 genes , the mouse systems genetics method that identified 7,842 additional genes with potential biological relevance to addiction through mouse QTL and gene expression correlation analysis and the GIN prioritization scores reflect this quantitative assessment of biological relevance .\n",
      "{4: 'mouse systems genetics method'}\n",
      "Rule 4: mouse systems genetics method\n",
      "\n",
      "\n",
      "\n",
      "In order to determine the coverage of regions inferred to be undergoing recent adaptive selection , all SNPs detected by the LD decay test in the Perlegen and HapMap datasets were compared to the Illumina 1M and Affymetrix 6.0 SNPs .\n",
      "{4: 'LD decay test'}\n",
      "Rule 4: LD decay test\n",
      "\n",
      "\n",
      "\n",
      "We thereby assumed that P. vulgatissima was present in each stand every year but that they sometimes occurred at densities too low to be detected by our sampling method .\n",
      "{4: 'sampling method'}\n",
      "Rule 4: sampling method\n",
      "\n",
      "\n",
      "\n",
      "Statistical significance of differential gene expression was determined using the maximum likelihood method .\n",
      "{4: 'maximum likelihood method'}\n",
      "Rule 4: maximum likelihood method\n",
      "\n",
      "\n",
      "\n",
      "Flow cytometric analysis demonstrated a significantly higher frequency of tetramer-binding B cells in SLE patients compared to healthy controls .\n",
      "{2: 'Flow cytometric analysis', 4: 'Flow analysis'}\n",
      "Rule 2: Flow cytometric analysis\n",
      "\n",
      "\n",
      "\n",
      "Previously , we developed a genome-wide DNA methylation analysis called MIAMI using a microarray .\n",
      "{2: 'genome-wide DNA methylation analysis', 4: 'DNA methylation analysis'}\n",
      "Rule 2: genome-wide DNA methylation analysis\n",
      "\n",
      "\n",
      "\n",
      "FISH analysis of these foci with a probe recognizing rep DNA showed the presence of AAV DNA co-localizing with Rep proteins both in cells infected with HSV-1 or transfected with pTF3pol / pRF , thus confirming the identification of these foci as true AAV replication centers .\n",
      "{4: 'FISH analysis'}\n",
      "Rule 4: FISH analysis\n",
      "\n",
      "\n",
      "\n",
      "With this normalization method , the QPCR signal derived from the sequence of interest is divided by the signal derived from the positive sequence control , assuming that the chromatin structure at the control sequence does not differ between samples , and that consequently all signal variation is of technical origin .\n",
      "{4: 'normalization method'}\n",
      "Rule 4: normalization method\n",
      "\n",
      "\n",
      "\n",
      "A non-parametric estimation technique applying the concept of ‘sample coverage’ was used to estimate the total number of OR genes in each of the nine avian genomes investigated .\n",
      "{2: 'non-parametric estimation technique', 4: 'estimation technique'}\n",
      "Rule 2: non-parametric estimation technique\n",
      "\n",
      "\n",
      "\n",
      "To unravel protein candidates of clinical interest , proteome analysis appears as the reference technology for such investigations .\n",
      "{4: 'proteome analysis'}\n",
      "Rule 4: proteome analysis\n",
      "\n",
      "\n",
      "\n",
      "To date , two different approaches for the distinction between live and dead spermatozoa have been pursued ; the initiation of motility as sign of vitality by means of stimulants and the identification of live spermatozoa according to their membrane integrity by means of the hypo-osmotic swelling test .\n",
      "{2: 'hypo-osmotic swelling test', 4: 'swelling test'}\n",
      "Rule 2: hypo-osmotic swelling test\n",
      "\n",
      "\n",
      "\n",
      "The aim of this work was to use flow cytometric analysis in order to evaluate the atretic process in cultured GCs after treatment with zearalenones .\n",
      "{2: 'flow cytometric analysis', 4: 'flow analysis'}\n",
      "Rule 2: flow cytometric analysis\n",
      "\n",
      "\n",
      "\n",
      "Finally , the regression model was calculated only with the covariates that were found to have a significant effect on any of the first two steps .\n",
      "{4: 'regression model'}\n",
      "Rule 4: regression model\n",
      "\n",
      "\n",
      "\n",
      "A limiting dilution based method requiring significant proliferation of cells was devised , allowing unstable species to be diluted to extinction before proviral detection by PCR .\n",
      "{2: 'limiting dilution based method', 4: 'dilution method'}\n",
      "Rule 2: limiting dilution based method\n",
      "\n",
      "\n",
      "\n",
      "SSR markers RM42 and RM284 spanning the aroma gene region were selected to identify 40 recombinant lines for adding markers and for rapid screening of aroma by the smelling method after soaking seeds in KOH solution .\n",
      "{4: 'smelling method'}\n",
      "Rule 4: smelling method\n",
      "\n",
      "\n",
      "\n",
      "Annotated frames in each genome that were aligned but not matched by the annotation independent method were subjected to a BlastP search by the \" Blast 2 sequences \" service at NCBI .\n",
      "{2: 'annotation independent method', 4: 'annotation method'}\n",
      "Rule 2: annotation independent method\n",
      "\n",
      "\n",
      "\n",
      "Because viruses are present in low concentrations in environmental waters , it is necessary to concentrate water samples by several orders of magnitude prior to PCR analysis .\n",
      "{4: 'PCR analysis'}\n",
      "Rule 4: PCR analysis\n",
      "\n",
      "\n",
      "\n",
      "Synonymous substitution rates were estimated using a version of the MG94 codon substitution model .\n",
      "{4: 'MG94 codon substitution model'}\n",
      "Rule 4: MG94 codon substitution model\n",
      "\n",
      "\n",
      "\n",
      "{'rule_4': 680, 'rule_2': 629, 'rule_5': 29}\n",
      "Total number of sentences: 10974\n"
     ]
    }
   ],
   "source": [
    "rules_count = dict()\n",
    "iob_list = list()\n",
    "\n",
    "def checkRule(tok_list, parent):\n",
    "#     print(tok_list)\n",
    "    rule_1_words = list()\n",
    "    rule_2_words = list()\n",
    "    rule_3_words = list()\n",
    "    rule_4_words = list()\n",
    "    rule_5_words = list()\n",
    "    \n",
    "    children = parent['children']\n",
    "    \n",
    "    # You comment/uncomment any rule here and it won't be executed\n",
    "    rules = [\n",
    "#         'rule_1', \n",
    "        'rule_2', \n",
    "#         'rule_3',\n",
    "        'rule_4',\n",
    "        'rule_5'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Rule 1\n",
    "    # ==========================================================================================================================================================================================                    \n",
    "    if ('rule_1' in rules) and set((rule_1 := {id: tok_list[id]['deprel'] for id in children if tok_list[id]['deprel'] in ['compound', 'conj']}).values()) == set(['compound', 'conj']):\n",
    "        if ((len(rule_1.values()) > 0) and (all(x in [tok_list[id]['deprel'] for id in children] for x in rule_1.values()))):\n",
    "            rule_1_words = []\n",
    "            rule_1_words.append(str(tok_list[list(rule_1.keys())[list(rule_1.values()).index('compound')]]['text']) + \" \" + str(parent['text']))\n",
    "            for id in rule_1.keys():\n",
    "                if (tok_list[id]['deprel'] in ['conj']):\n",
    "                    rule_1_words.append(tok_list[id]['text'] + \" \" + parent['text'])    \n",
    "    \n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Rule 2\n",
    "    # ==========================================================================================================================================================================================                    \n",
    "    if ('rule_2' in rules) and set((rule_2 := {id: tok_list[id]['deprel'] for id in children if tok_list[id]['deprel'] in ['compound', 'amod']}).values()) == set(['compound', 'amod']):\n",
    "        if ((len(rule_2.values()) > 0) and (all(x in [tok_list[id]['deprel'] for id in children] for x in rule_2.values()))):\n",
    "            rule_2_words = []\n",
    "            word_string = \"\"\n",
    "            \n",
    "\n",
    "            for id in range(min(rule_2.keys()), max(rule_2.keys()) + 1):\n",
    "                if (tok_list[id]['text'] in ['=', ',', '\"', '\\'']):\n",
    "                    continue\n",
    "                word_string+=tok_list[id]['text'] + \" \"\n",
    "            word_string+=parent['text']\n",
    "            rule_2_words.append(word_string)\n",
    "    \n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Rule 3\n",
    "    # ==========================================================================================================================================================================================                    \n",
    "    if ('rule_3' in rules) and set((rule_3 := {id: tok_list[id]['deprel'] for id in children if tok_list[id]['deprel'] in ['amod']}).values()) == set(['amod']) and (parent['deprel'] == 'conj'):\n",
    "        if ((len(rule_3.values()) > 1) and (all(x in [tok_list[id]['deprel'] for id in children] for x in rule_3.values()))):\n",
    "            rule_3_words = []\n",
    "            word_string = \"\"\n",
    "            for id in rule_3.keys():\n",
    "                if (tok_list[id]['deprel']) in ['amod']:\n",
    "                    if (tok_list[id]['text'] in ['=']):\n",
    "                        continue\n",
    "                    word_string+=tok_list[id]['text'] + \" \"\n",
    "            word_string+=parent['text']\n",
    "            \n",
    "            for id in children:\n",
    "                if tok_list[id]['deprel'] == 'acl':\n",
    "                    new_tok = tok_list[id]\n",
    "                    word_string+= \" \" + new_tok['text']\n",
    "                    if len(new_tok['children']) > 0:\n",
    "                        newer_tok = tok_list[new_tok['children'][0]]\n",
    "                        for i in newer_tok['children']:\n",
    "                            newest_tok = tok_list[i]\n",
    "                            if newest_tok['deprel'] == 'case':\n",
    "                                word_string+=\" \" + newest_tok['text'] + \" \" + newer_tok['text']\n",
    "            \n",
    "            rule_3_words.append(word_string)\n",
    "\n",
    "            \n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Rule 4\n",
    "    # ==========================================================================================================================================================================================                    \n",
    "    if ('rule_4' in rules) and set((rule_4 := {id: tok_list[id]['deprel'] for id in children if tok_list[id]['deprel'] in ['compound']}).values()) == set(['compound']):\n",
    "        if ((len(rule_4.values()) > 0) and (all(x in [tok_list[id]['deprel'] for id in children] for x in rule_4.values()))):\n",
    "            rule_4_words = []\n",
    "            word_string = \"\"            \n",
    "            for id in range(min(rule_4.keys()), max(rule_4.keys()) + 1):\n",
    "                if (tok_list[id]['text'] in ['=', ',', '\"', '\\'']):\n",
    "                    continue\n",
    "                word_string+=tok_list[id]['text'] + \" \"\n",
    "            word_string+=parent['text']\n",
    "            rule_4_words.append(word_string)\n",
    "            \n",
    "\n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Rule 5\n",
    "    # ==========================================================================================================================================================================================    \n",
    "    if ('rule_5' in rules) and set((rule_5 := {id: tok_list[id]['deprel'] for id in children if tok_list[id]['deprel'] in ['nmod:poss']}).values()) == set(['nmod:poss']):\n",
    "        if ((len(rule_5.values()) > 0) and (all(x in [tok_list[id]['deprel'] for id in children] for x in rule_5.values()))):\n",
    "            if (len(rule_5.values()) == 1):\n",
    "                current_id = list(rule_5.keys())[0]\n",
    "                if (tok_list[current_id+1]['deprel'] == 'case') and (tok_list[current_id]['text'].istitle()) and (len(tok_list[current_id+1]['text'])>1):\n",
    "                    for key in tok_list.keys():\n",
    "                        print(tok_list[key])\n",
    "                    word_string = \"\"\n",
    "                    word_string+=tok_list[current_id]['text'] + \" \" + tok_list[current_id+1]['text']\n",
    "                    for i in range(current_id+2, parent['id']+1):\n",
    "                        if (tok_list[i]['text'] in ['=', ',', '\"', '\\'']):\n",
    "                            continue\n",
    "                        word_string+=\" \" + tok_list[i]['text']\n",
    "                    rule_5_words.append(word_string)\n",
    "                \n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Finding best rule and counting the distribution of triggered rules\n",
    "    # ==========================================================================================================================================================================================\n",
    "    words = [\n",
    "        rule_1_words,\n",
    "        rule_2_words,\n",
    "        rule_3_words,\n",
    "        rule_4_words,\n",
    "        rule_5_words\n",
    "    ]\n",
    "    \n",
    "    word_dict = {id+1: words[id][0] for id in range(len(words)) if len(words[id]) > 0 and (words[id][0] != [])}\n",
    "    \n",
    "    sentence = ' '.join([tok_list[key]['text'] for key in tok_list.keys()])\n",
    "        \n",
    "    if (len(word_dict.values()) > 0):\n",
    "        \n",
    "        print(sentence)\n",
    "        print(word_dict)\n",
    "        \n",
    "        value = max(word_dict.values(), key=len)\n",
    "        key = list(word_dict.keys())[list(word_dict.values()).index(value)]\n",
    "        \n",
    "        rule_name = 'rule_' + str(key)\n",
    "        \n",
    "        if rule_name in rules_count:\n",
    "            rules_count[rule_name] = rules_count[rule_name] + 1\n",
    "        else:\n",
    "            rules_count[rule_name] = 1\n",
    "        \n",
    "        print('Rule ' + str(key) + \": \", end='')\n",
    "        print(value)\n",
    "        \n",
    "        print('\\n\\n')\n",
    "        \n",
    "        return value, sentence\n",
    "    return None, sentence\n",
    "\n",
    "            \n",
    "def convertWord2WordDict(sentence):\n",
    "    return {word['id']:word for word in sentence}\n",
    "\n",
    "def getWordsFromDepTree(tok_list, parent = None):\n",
    "#     dependency_list = list(['acl'])\n",
    "    initial_word_list = list([\n",
    "        'method', \n",
    "        'analysis', \n",
    "        'algorithm', \n",
    "        'approach', \n",
    "        'model', \n",
    "        'preparation', \n",
    "        'strategy', \n",
    "        'technique', \n",
    "        'normalization', \n",
    "        'quantification',\n",
    "        'test', \n",
    "        'scoring', \n",
    "        'score', \n",
    "        'statistic'\n",
    "    ])\n",
    "#     initial_word_list = list(['statistic'])\n",
    "     \n",
    "    if parent == None:\n",
    "        for tok in tok_list.values():\n",
    "            if tok['deprel'] == 'root':\n",
    "                parent = tok\n",
    "                getWordsFromDepTree(tok_list, parent)\n",
    "    else:\n",
    "        for i in parent['children']:\n",
    "            tok = tok_list[i]\n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Uncomment if you don't want limits on suffix words\n",
    "#             checkRule(tok_list, tok)\n",
    "#             getWordsFromDepTree(tok_list, tok)\n",
    "    # ==========================================================================================================================================================================================\n",
    "    # Uncomment if you want limits on suffix words\n",
    "            if tok['text'].lower() in initial_word_list:\n",
    "                value, sentence = checkRule(tok_list, tok)\n",
    "                \n",
    "                sentence_list = sentence.split(\" \")\n",
    "                \n",
    "                inner_iob_list = [0] * len(sentence_list)\n",
    "                \n",
    "                xpos_list = [tok['xpos'] for tok in list(tok_list.values())]\n",
    "                    \n",
    "                if (value != None):\n",
    "                    word_list = value.split(\" \")\n",
    "                    \n",
    "                    for i in range(len(sentence_list)):\n",
    "                        if (sentence_list[i] == word_list[0]):\n",
    "                            number_of_matched = 0\n",
    "                            for j in range(len(word_list)):\n",
    "                                if (i+j < len(sentence_list)):\n",
    "                                    if (sentence_list[i+j] == word_list[j]):\n",
    "                                        number_of_matched+=1\n",
    "                            if (number_of_matched == len(word_list)):\n",
    "                                for j in range(len(word_list)):\n",
    "                                    inner_iob_list[i+j] = j+1\n",
    "#                     print(inner_iob_list)\n",
    "                    \n",
    "                    for index in range(0, len(inner_iob_list)):\n",
    "                        if inner_iob_list[index] == 0:\n",
    "                            inner_iob_list[index] = 'O'\n",
    "                        elif inner_iob_list[index] == 1:\n",
    "                            inner_iob_list[index] = 'B-method'\n",
    "                        else:\n",
    "                            inner_iob_list[index] = 'I-method'\n",
    "\n",
    "                    list_with_word_and_tag = list(zip(sentence_list, xpos_list, inner_iob_list))\n",
    "#                     print(list_with_word_and_tag)\n",
    "                    iob_list.append(list_with_word_and_tag)\n",
    "            else:\n",
    "                getWordsFromDepTree(tok_list, tok)\n",
    "                \n",
    "# ==============================================================================================================================================================================================\n",
    "\n",
    "for sentence in sentence_tok_list:\n",
    "    getWordsFromDepTree(convertWord2WordDict(sentence))\n",
    "print(rules_count)\n",
    "print(\"Total number of sentences: \" + str(len(sentence_tok_list)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeIOB2File(inputList, filename):\n",
    "    with open(filename, 'w+') as fout:\n",
    "        for i in inputList:\n",
    "            for j in i:\n",
    "                output = \"\"\n",
    "                if '.' in j[0]:\n",
    "                    output=str(j[0]) + '\\t' + str(j[1]) + '\\t' + str(j[2]) + '\\n\\n'\n",
    "                else:\n",
    "                    output=str(j[0]) + '\\t' + str(j[1]) + '\\t' + str(j[2]) + '\\n'\n",
    "                fout.write(output)\n",
    "                \n",
    "writeIOB2File(iob_list, \"complex_rules_iob_input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('complex_rules_iob_input.pkl', 'wb') as f:\n",
    "    pickle.dump(iob_list, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338\n"
     ]
    }
   ],
   "source": [
    "print(len(iob_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
